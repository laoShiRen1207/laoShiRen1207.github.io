<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.1.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"laoshiren1207.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="LaoShiRen1207">
<meta property="og:url" content="https://laoshiren1207.github.io/index.html">
<meta property="og:site_name" content="LaoShiRen1207">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Laoshiren">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://laoshiren1207.github.io/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>LaoShiRen1207</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">LaoShiRen1207</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">天下有太多难学的技术</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
        <li class="menu-item menu-item-schedule">

    <a href="/schedule/" rel="section"><i class="fa fa-fw fa-calendar"></i>日程表</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://laoshiren1207.github.io/2022/10/10/RabbitMq/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Laoshiren">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LaoShiRen1207">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/10/10/RabbitMq/" class="post-title-link" itemprop="url">消息队列 【RabbitMQ】</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-10-10 10:10:16" itemprop="dateCreated datePublished" datetime="2022-10-10T10:10:16+08:00">2022-10-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-04-13 15:01:38" itemprop="dateModified" datetime="2022-04-13T15:01:38+08:00">2022-04-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/MessageQueue/" itemprop="url" rel="index"><span itemprop="name">MessageQueue</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>消息队列可以理解为一种在TCP协议之上构建的一个简单的协议 <!--more--></p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2022/10/10/RabbitMq/">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://laoshiren1207.github.io/2022/04/04/Mybatis/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Laoshiren">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LaoShiRen1207">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/04/04/Mybatis/" class="post-title-link" itemprop="url">Mybatis 原理以及池化技术原理</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-04-04 02:02:28" itemprop="dateCreated datePublished" datetime="2022-04-04T02:02:28+08:00">2022-04-04</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-04-13 15:08:57" itemprop="dateModified" datetime="2022-04-13T15:08:57+08:00">2022-04-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Java/" itemprop="url" rel="index"><span itemprop="name">Java</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Java/Mybatis/" itemprop="url" rel="index"><span itemprop="name">Mybatis</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="MyBatis"><a href="#MyBatis" class="headerlink" title="MyBatis"></a>MyBatis</h1><h2 id="MybatisProxy"><a href="#MybatisProxy" class="headerlink" title="MybatisProxy"></a>MybatisProxy</h2><p>比较简单建议直接阅读源码</p>
<h2 id="池化"><a href="#池化" class="headerlink" title="池化"></a>池化</h2><p><img src="https://img-blog.csdnimg.cn/56679ec2cb9244f59485b432b5b72eac.png" alt="在这里插入图片描述"></p>
<p><a target="_blank" rel="noopener" href="https://img-blog.csdnimg.cn/56679ec2cb9244f59485b432b5b72eac.png">图片地址 MyBatis 池化</a></p>
<h2 id="MapperScan-原理"><a href="#MapperScan-原理" class="headerlink" title="MapperScan 原理"></a>MapperScan 原理</h2><p><img src="https://img-blog.csdnimg.cn/3a8cde3f431d4f68b645f0bfb4d3febb.png" alt="在这里插入图片描述"></p>
<p><a target="_blank" rel="noopener" href="https://img-blog.csdnimg.cn/3a8cde3f431d4f68b645f0bfb4d3febb.png">图片地址 MapperScan的原理</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://laoshiren1207.github.io/2022/03/31/SpringBoot/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Laoshiren">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LaoShiRen1207">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/03/31/SpringBoot/" class="post-title-link" itemprop="url">Spring IOC原理以及SpringBoot自动装配原理</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-03-31 04:02:28" itemprop="dateCreated datePublished" datetime="2022-03-31T04:02:28+08:00">2022-03-31</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-04-13 15:11:34" itemprop="dateModified" datetime="2022-04-13T15:11:34+08:00">2022-04-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Java/" itemprop="url" rel="index"><span itemprop="name">Java</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Java/Spring/" itemprop="url" rel="index"><span itemprop="name">Spring</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Spring"><a href="#Spring" class="headerlink" title="Spring"></a>Spring</h1><h2 id="IOC"><a href="#IOC" class="headerlink" title="IOC"></a>IOC</h2><p><img src="https://img-blog.csdnimg.cn/59ae660f06224aee903f5d70bd36918c.png" alt="在这里插入图片描述"></p>
<p><a target="_blank" rel="noopener" href="https://img-blog.csdnimg.cn/59ae660f06224aee903f5d70bd36918c.png">图片地址 IOC </a></p>
<h1 id="SpringBoot"><a href="#SpringBoot" class="headerlink" title="SpringBoot"></a>SpringBoot</h1><h2 id="run"><a href="#run" class="headerlink" title="run"></a>run</h2><p><img src="https://img-blog.csdnimg.cn/b6b74db253e54efba0b580ee828acb4d.png" alt="在这里插入图片描述"></p>
<p><a target="_blank" rel="noopener" href="https://img-blog.csdnimg.cn/b6b74db253e54efba0b580ee828acb4d.png">图片地址</a></p>
<h2 id="EnableAutoConfiguration"><a href="#EnableAutoConfiguration" class="headerlink" title="@EnableAutoConfiguration"></a>@EnableAutoConfiguration</h2><p><img src="https://img-blog.csdnimg.cn/d30a92435b6b4b679de4b96254ed644a.png" alt="在这里插入图片描述"></p>
<p><a target="_blank" rel="noopener" href="https://img-blog.csdnimg.cn/d30a92435b6b4b679de4b96254ed644a.png">图片地址</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://laoshiren1207.github.io/2022/03/24/JUC/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Laoshiren">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LaoShiRen1207">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/03/24/JUC/" class="post-title-link" itemprop="url">JUC</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-03-24 15:23:01" itemprop="dateCreated datePublished" datetime="2022-03-24T15:23:01+08:00">2022-03-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-04-13 15:25:19" itemprop="dateModified" datetime="2022-04-13T15:25:19+08:00">2022-04-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Java/" itemprop="url" rel="index"><span itemprop="name">Java</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Java/JUC/" itemprop="url" rel="index"><span itemprop="name">JUC</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>JUC向B站UP主[青空の霞光](https://space.bilibili.com/37737161)学习<!--more--></p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2022/03/24/JUC/">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://laoshiren1207.github.io/2022/03/18/mysql/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Laoshiren">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LaoShiRen1207">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/03/18/mysql/" class="post-title-link" itemprop="url">MySQL  从入门到入土</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-03-18 15:08:16" itemprop="dateCreated datePublished" datetime="2022-03-18T15:08:16+08:00">2022-03-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-04-13 15:26:19" itemprop="dateModified" datetime="2022-04-13T15:26:19+08:00">2022-04-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/" itemprop="url" rel="index"><span itemprop="name">数据库</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/" itemprop="url" rel="index"><span itemprop="name">MySQL</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>MySQL 学习 资料来自B站 黑马程序员<!--more--></p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2022/03/18/mysql/">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://laoshiren1207.github.io/2022/01/13/Hive/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Laoshiren">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LaoShiRen1207">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/01/13/Hive/" class="post-title-link" itemprop="url">Hive</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-01-13 20:14:20" itemprop="dateCreated datePublished" datetime="2022-01-13T20:14:20+08:00">2022-01-13</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-04-13 15:25:18" itemprop="dateModified" datetime="2022-04-13T15:25:18+08:00">2022-04-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/DataWareHouse/" itemprop="url" rel="index"><span itemprop="name">DataWareHouse</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <hr>
<h1 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h1><h2 id="Hive-基本概念"><a href="#Hive-基本概念" class="headerlink" title="Hive 基本概念"></a>Hive 基本概念</h2><h3 id="什么是-Hive"><a href="#什么是-Hive" class="headerlink" title="什么是 Hive"></a>什么是 Hive</h3><p>Hive：由 Facebook 开源用于解决海量结构化日志的数据统计。<br>Hive 是基于 Hadoop 的一个数据仓库工具，可以将结构化的数据文件映射为一张表，并提供类 SQL 查询功能。<br>本质是：将 HQL 转化成 MapReduce 程序</p>
<p><img src="https://img-blog.csdnimg.cn/0c1e0b275c014154b2cfbb1dc0ea0ae4.png" alt="在这里插入图片描述"></p>
<ol>
<li>Hive 处理的数据存储在 HDFS</li>
<li>Hive 分析数据底层的默认实现是 MapReduce</li>
<li>执行程序运行在 Yarn 上</li>
</ol>
<h3 id="Hive-的优缺点"><a href="#Hive-的优缺点" class="headerlink" title="Hive 的优缺点"></a>Hive 的优缺点</h3><p><strong>优点</strong></p>
<ol>
<li>操作接口采用类 SQL 语法，提供快速开发的能力（简单、容易上手）。</li>
<li>避免了去写 MapReduce，减少开发人员的学习成本。</li>
<li>Hive 的执行延迟比较高，因此 Hive 常用于数据分析，对实时性要求不高的场合。</li>
<li>Hive 优势在于处理大数据，对于处理小数据没有优势，因为 Hive 的执行延迟比较高。</li>
<li>Hive 支持用户自定义函数，用户可以根据自己的需求来实现自己的函数。</li>
</ol>
<p><strong>缺点</strong></p>
<ol>
<li>Hive 的 HQL 表达能力有限<ul>
<li>迭代式算法无法表达</li>
<li>数据挖掘方面不擅长</li>
</ul>
</li>
<li>Hive 的效率比较低<ul>
<li>Hive 自动生成的 MapReduce 作业，通常情况下不够智能化</li>
<li>Hive 调优比较困难，粒度较粗</li>
</ul>
</li>
</ol>
<h3 id="Hive-架构原理"><a href="#Hive-架构原理" class="headerlink" title="Hive 架构原理"></a>Hive 架构原理</h3><p><img src="https://img-blog.csdnimg.cn/a122087055af4514bc0c0ca24c7e14ce.png" alt="在这里插入图片描述"></p>
<h4 id="1．用户接口：Client"><a href="#1．用户接口：Client" class="headerlink" title="1．用户接口：Client"></a>1．用户接口：Client</h4><p>CLI（hive shell）、JDBC&#x2F;ODBC(java 访问 hive)、WEBUI（浏览器访问 hive）</p>
<h4 id="2．元数据：Metastore"><a href="#2．元数据：Metastore" class="headerlink" title="2．元数据：Metastore"></a>2．元数据：Metastore</h4><p>元数据包括：表名、表所属的数据库（默认是 default）、表的拥有者、列&#x2F;分区字段、表的类型（是否是外部表）、表的数据所在目录等；<em>默认存储在自带的 derby 数据库中，推荐使用 MySQL 存储 Metastore</em></p>
<h4 id="3．驱动器：Driver"><a href="#3．驱动器：Driver" class="headerlink" title="3．驱动器：Driver"></a>3．驱动器：Driver</h4><ul>
<li>解析器（SQL Parser）：将 SQL 字符串转换成抽象语法树 AST，这一步一般都用第三方工具库完成，比如 antlr；对 AST 进行语法分析，比如表是否存在、字段是否存在、SQL 语义是否有误。</li>
<li>编译器（Physical Plan）：将 AST 编译生成逻辑执行计划。</li>
<li>优化器（Query Optimizer）：对逻辑执行计划进行优化。</li>
<li>执行器（Execution）：把逻辑执行计划转换成可以运行的物理计划。对于 Hive 来说，就是 MR&#x2F;Spark。</li>
</ul>
<p>一条 HQL 交给 Hive 会先去 mysql  获取元数据（包括 HDFS 的存储路径，Reduce 后的存放路径） 然后连接 HDFS，将 HQL 翻译成 MapReduce 。 </p>
<h2 id="Hive-安装"><a href="#Hive-安装" class="headerlink" title="Hive 安装"></a>Hive 安装</h2><p>1．<a target="_blank" rel="noopener" href="http://hive.apache.org/">Hive 官网地址 http://hive.apache.org/</a></p>
<p>2．<a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/Hive/GettingStarted">文档查看地址 https://cwiki.apache.org/confluence/display/Hive/GettingStarted</a></p>
<p>3．<a target="_blank" rel="noopener" href="http://archive.apache.org/dist/hive/">下载地址 http://archive.apache.org/dist/hive/</a></p>
<h3 id="安装hive"><a href="#安装hive" class="headerlink" title="安装hive"></a>安装hive</h3><ol>
<li><p>解压缩</p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf /opt/software/apache-hive-3.1.2-bin.tar.gz -C /home/module/</span><br><span class="line"></span><br><span class="line">mv /opt/module/apache-hive-3.1.2-bin/  /home/module/hive-3.1.2</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置环境变量</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile.d/my_hive_env.sh</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">HIVE_HOME</span></span><br><span class="line">export HIVE_HOME=/home/module/hive-3.1.2</span><br><span class="line">export PATH=$PATH:$HIVE_HOME/bin</span><br><span class="line"></span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>
</li>
<li><p>解决jar 冲突 <code> mv $HIVE_HOME/lib/log4j-slf4j-impl2.10.0.jar $HIVE_HOME/lib/log4j-slf4j-impl-2.10.0.bak</code></p>
</li>
<li><p>初始化元数据库</p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">bin/schematool -dbType derby -initSchema</span><br><span class="line"><span class="meta prompt_"> # </span><span class="language-bash">这里可能会出现错误</span></span><br><span class="line">Exception in thread main java.lang.NoSuchMethodError: com.google.common.base.Preconditions.checkArgument(ZLjava/lang/Stringl;Ljava/lang/Object;)V</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">异常原因 hadoop 和 hive 版本guava版本不一致</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">处理方法 复制hadoop guava 到hive 的lib</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">文件地址</span></span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash">HIVE_HOME/lib/guava...</span></span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash">HADOOP_HOME/share/hadoop/common/lib</span></span><br></pre></td></tr></table></figure></li>
<li><p>启动 Hive <code>bin/hive</code></p>
</li>
</ol>
<blockquote>
<p>Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.</p>
</blockquote>
<p>Hive On MapReduce 已经在Hive 2被弃用了，可能在未来的版本不可用。考虑使用不同的执行引擎例如 spark tez 或者使用Hive 1.x 版本</p>
<h3 id="Hive-简单使用"><a href="#Hive-简单使用" class="headerlink" title="Hive 简单使用"></a>Hive 简单使用</h3><p>查询数据库</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">show databases;</span><br><span class="line"></span><br><span class="line">OK</span><br><span class="line">default</span><br></pre></td></tr></table></figure>

<p>查看表</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">show tables;</span><br><span class="line"></span><br><span class="line">OK </span><br><span class="line">test</span><br></pre></td></tr></table></figure>

<p>创建表</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">create table test(id int);</span><br><span class="line">OK </span><br></pre></td></tr></table></figure>

<p>插入数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insert into test values(1);</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/a0fab80cff844db99f0a1304f31e34fd.png" alt="在这里插入图片描述"></p>
<p>使用 hdfs 查询 <code>hadoop fs -tail /user/hive/warehouse/test/000000_0</code><img src="https://img-blog.csdnimg.cn/98b1dc06dcfa445b98d2a3557a2e5737.png" alt="在这里插入图片描述"></p>
<p><img src="https://img-blog.csdnimg.cn/36868cc11f6e40438e350d8132d4f799.png" alt="在这里插入图片描述"></p>
<p>查询</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">select * from test;</span><br><span class="line"></span><br><span class="line">OK</span><br><span class="line">1</span><br><span class="line">Time taken: 0.084 seconds, Fetched: 1 row(s)</span><br></pre></td></tr></table></figure>

<p>Hive 默认使用的元数据库为 derby，开启 Hive 之后就会占用元数据库，且不与其他客户端共享数据，所以我们需要将 Hive 的元数据地址改为 MySQL。</p>
<h3 id="Mysql-安装"><a href="#Mysql-安装" class="headerlink" title="Mysql 安装"></a>Mysql 安装</h3><p>检查是否安装mysql </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">rpm -qa|grep mariadb</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果存在删除mysql</span> </span><br><span class="line"></span><br><span class="line">sudo rpm -e --nodeps mariadb-libs</span><br></pre></td></tr></table></figure>

<p>解压 MySQL 安装包</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tar -xf mysql-5.7.28-1.el7.x86_64.rpmbundle.tar</span><br><span class="line"></span><br><span class="line">rpm -ivh mysql-community-common-5.7.28-1.el7.x86_64.rpm</span><br><span class="line">rpm -ivh mysql-community-libs-5.7.28-1.el7.x86_64.rpm</span><br><span class="line">rpm -ivh mysql-community-libs-compat-5.7.28-1.el7.x86_64.rpm</span><br><span class="line">rpm -ivh mysql-community-client-5.7.28-1.el7.x86_64.rpm</span><br><span class="line">rpm -ivh mysql-community-server-5.7.28-1.el7.x86_64.rpm</span><br></pre></td></tr></table></figure>

<p>通过 yum 安装缺少的依赖,然后重新安装 mysql-community-server-5.7.28-1.el7.x86_64 ，<code>yum install -y libaio</code></p>
<p>查看 &#x2F;etc&#x2F;my.inf的 datadir 的值： &#x2F;var&#x2F;lib&#x2F;mysql </p>
<p>删除该文件加下所有东西</p>
<p>初始化数据库</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysqld --initialize --user=mysql</span><br><span class="line"></span><br><span class="line">cat /var/log/mysqld.log</span><br><span class="line"></span><br><span class="line">systemctl start mysqld</span><br><span class="line"> </span><br><span class="line">mysql -uroot -pXXX</span><br></pre></td></tr></table></figure>

<p>修改参数</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 设置密码</span></span><br><span class="line"><span class="keyword">set</span> password <span class="operator">=</span> password(&quot;123456&quot;);</span><br><span class="line"><span class="comment">-- root 用户允许任意 ip 连接</span></span><br><span class="line"><span class="keyword">update</span> mysql.user <span class="keyword">set</span> host<span class="operator">=</span><span class="string">&#x27;%&#x27;</span> <span class="keyword">where</span> <span class="keyword">user</span><span class="operator">=</span><span class="string">&#x27;root&#x27;</span>;</span><br><span class="line"></span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure>

<p>创建元数据仓库</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> database metastore;</span><br></pre></td></tr></table></figure>



<h3 id="配置Hive-metastore"><a href="#配置Hive-metastore" class="headerlink" title="配置Hive metastore"></a>配置Hive metastore</h3><p>上传mysql-lib，<code> cp /opt/software/mysql-connector-java5.1.38.jar $HIVE_HOME/lib</code></p>
<p>新建 hive-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- jdbc 连接的 URL --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://hadoop201:3306/metastore?useSSL=false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- jdbc 连接的 Driver--&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- jdbc 连接的 username--&gt;</span></span><br><span class="line"> 	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- jdbc 连接的 password --&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>123456<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- Hive 元数据存储版本的验证 --&gt;</span></span><br><span class="line"> 	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.schema.verification<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--元数据存储授权--&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.event.db.notification.api.auth<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- Hive 默认在 HDFS 的工作目录 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>初始化元数据库 <code>schematool -initSchema -dbType mysql -verbose</code>，链接hive。</p>
<p>当我们创建好了以后执行<code>show tables;</code>，发现没有数据，因为 mysql 的元数据的信息都不存在，存在于刚才的derby。但是我们实际执行<code>select * from test</code>时，会发现</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive&gt;select * from test;</span><br><span class="line">OK</span><br><span class="line">1</span><br><span class="line">Time taken: 0.157 seconds, Fetched: 2 row(s)</span><br></pre></td></tr></table></figure>

<p>那我们直接在刚才<code>/user/hive/warehouse/test</code> 添加文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -put a.txt /user/hive/warehouse/test</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">连上hive 查询</span></span><br><span class="line"><span class="meta prompt_">hive&gt;</span><span class="language-bash">select * from <span class="built_in">test</span>;</span></span><br><span class="line">OK</span><br><span class="line">1</span><br><span class="line">1001</span><br><span class="line">1002</span><br><span class="line">1003</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/d755309f239b4532afa687b2d3adc3e6.png" alt="在这里插入图片描述"></p>
<p><img src="https://img-blog.csdnimg.cn/ca7697d5fcff4cb996758eb1a4f86a90.png" alt="在这里插入图片描述"></p>
<p>即我们创建的元数据存放在元数据库 metastore里，实际的文件存储在hdfs 中，而实际在hive 中执行简单的查询只会把sql 解析成对应的 hadoop fs 读取，读取hdfs 文件。</p>
<h3 id="使用元数据服务的方式访问-Hive"><a href="#使用元数据服务的方式访问-Hive" class="headerlink" title="使用元数据服务的方式访问 Hive"></a>使用元数据服务的方式访问 Hive</h3><p>在 hive-site.xml 文件中添加如下配置信息</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定存储元数据要连接的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.uris<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>thrift://hadoop201:9083<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>启动 metastore</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive --service metastore</span><br><span class="line">2020-04-24 16:58:08: Starting Hive Metastore Serverl</span><br></pre></td></tr></table></figure>

<p>注意: 启动后窗口不能再操作，需打开一个新的 shell 窗口做别的操作</p>
<h3 id="使用-JDBC-方式访问-Hive"><a href="#使用-JDBC-方式访问-Hive" class="headerlink" title="使用 JDBC 方式访问 Hive"></a>使用 JDBC 方式访问 Hive</h3><p>修改 hive-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定 hiveserver2 连接的 host --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.thrift.bind.host<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop201<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定 hiveserver2 连接的端口号 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.thrift.port<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>10000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.enable.doAs<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>启动hiveserver2 </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hiveserver2 --service hiveserver2</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动beeline</span></span><br><span class="line">beeline -u jdbc:hive2://hadoop201:10000 -n root</span><br></pre></td></tr></table></figure>

<h3 id="脚本封装"><a href="#脚本封装" class="headerlink" title="脚本封装"></a>脚本封装</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">HIVE_LOG_DIR=$HIVE_HOME/logs</span><br><span class="line">if [ ! -d $HIVE_LOG_DIR ]</span><br><span class="line">then</span><br><span class="line">mkdir -p $HIVE_LOG_DIR</span><br><span class="line">fi</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">检查进程是否运行正常，参数 1 为进程名，参数 2 为进程端口</span></span><br><span class="line">function check_process()</span><br><span class="line">&#123;</span><br><span class="line"> pid=$(ps -ef 2&gt;/dev/null | grep -v grep | grep -i $1 | awk &#x27;&#123;print$2&#125;&#x27;)</span><br><span class="line"> ppid=$(netstat -nltp 2&gt;/dev/null | grep $2 | awk &#x27;&#123;print $7&#125;&#x27; | cut -d &#x27;/&#x27; -f 1)</span><br><span class="line"> echo $pid</span><br><span class="line"> [[ &quot;$pid&quot; =~ &quot;$ppid&quot; ]] &amp;&amp; [ &quot;$ppid&quot; ] &amp;&amp; return 0 || return 1</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">function hive_start()</span><br><span class="line">&#123;</span><br><span class="line"> metapid=$(check_process HiveMetastore 9083)</span><br><span class="line"> cmd=&quot;nohup hive --service metastore &gt;$HIVE_LOG_DIR/metastore.log 2&gt;&amp;1 &amp;&quot;</span><br><span class="line"> [ -z &quot;$metapid&quot; ] &amp;&amp; eval $cmd || echo &quot;Metastroe 服务已启动&quot;</span><br><span class="line"> server2pid=$(check_process HiveServer2 10000)</span><br><span class="line"> cmd=&quot;nohup hiveserver2 &gt;$HIVE_LOG_DIR/hiveServer2.log 2&gt;&amp;1 &amp;&quot;</span><br><span class="line"> [ -z &quot;$server2pid&quot; ] &amp;&amp; eval $cmd || echo &quot;HiveServer2 服务已启动&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">function hive_stop()</span><br><span class="line">&#123;</span><br><span class="line">metapid=$(check_process HiveMetastore 9083)</span><br><span class="line"> [ &quot;$metapid&quot; ] &amp;&amp; kill $metapid || echo &quot;Metastore 服务未启动&quot;</span><br><span class="line"> server2pid=$(check_process HiveServer2 10000)</span><br><span class="line"> [ &quot;$server2pid&quot; ] &amp;&amp; kill $server2pid || echo &quot;HiveServer2 服务未启动&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">case $1 in</span><br><span class="line">&quot;start&quot;)</span><br><span class="line"> hive_start</span><br><span class="line"> ;;</span><br><span class="line">&quot;stop&quot;)</span><br><span class="line"> hive_stop</span><br><span class="line"> ;;</span><br><span class="line">&quot;restart&quot;)</span><br><span class="line"> hive_stop</span><br><span class="line"> sleep 2</span><br><span class="line"> hive_start</span><br><span class="line"> ;;</span><br><span class="line">&quot;status&quot;)</span><br><span class="line">check_process HiveMetastore 9083 &gt;/dev/null &amp;&amp; echo &quot;Metastore 服务运行正常&quot; || echo &quot;Metastore 服务运行异常&quot;</span><br><span class="line"> check_process HiveServer2 10000 &gt;/dev/null &amp;&amp; echo &quot;HiveServer2 服务运行正常&quot; || echo &quot;HiveServer2 服务运行异常&quot;</span><br><span class="line"> ;;</span><br><span class="line">*)</span><br><span class="line"></span><br><span class="line"> echo Invalid Args!</span><br><span class="line"> echo &#x27;Usage: &#x27;$(basename $0)&#x27; start|stop|restart|status&#x27;</span><br><span class="line"> ;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure>

<h2 id="Hive-数据类型"><a href="#Hive-数据类型" class="headerlink" title="Hive 数据类型"></a>Hive 数据类型</h2><table>
<thead>
<tr>
<th align="center">Hive 数据类型</th>
<th align="center">Java 数据类型</th>
<th align="center">长度</th>
<th align="center">例子</th>
</tr>
</thead>
<tbody><tr>
<td align="center">TINYINT</td>
<td align="center">byte</td>
<td align="center">1byte 有符号整数</td>
<td align="center">20</td>
</tr>
<tr>
<td align="center">SMALINT</td>
<td align="center">short</td>
<td align="center">2byte 有符号整数</td>
<td align="center">20</td>
</tr>
<tr>
<td align="center">INT</td>
<td align="center">int</td>
<td align="center">4byte 有符号整数</td>
<td align="center">20</td>
</tr>
<tr>
<td align="center">BIGINT</td>
<td align="center">long</td>
<td align="center">8byte 有符号整数</td>
<td align="center">20</td>
</tr>
<tr>
<td align="center">BOOLEAN</td>
<td align="center">boolean</td>
<td align="center">布尔类型，true 或者 false</td>
<td align="center">true</td>
</tr>
<tr>
<td align="center">FLOAT</td>
<td align="center">float</td>
<td align="center">单精度浮点数</td>
<td align="center">3.14</td>
</tr>
<tr>
<td align="center">DOUBLE</td>
<td align="center">double</td>
<td align="center">双精度浮点数</td>
<td align="center">3.1415</td>
</tr>
<tr>
<td align="center">STRING</td>
<td align="center">String</td>
<td align="center">字符系列。</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">TIMESTAMP</td>
<td align="center"></td>
<td align="center">时间类型</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">BINARY</td>
<td align="center"></td>
<td align="center">字节数组</td>
<td align="center"></td>
</tr>
</tbody></table>
<p>集合数据类型</p>
<table>
<thead>
<tr>
<th align="center">数据类型</th>
<th align="left">描述</th>
<th align="center">语法</th>
</tr>
</thead>
<tbody><tr>
<td align="center">STRUCT</td>
<td align="left">和 c 语言中的 struct 类似，都可以通过“点”符号访问元素内容。例如，如果某个列的数据类型是 STRUCT{first STRING, last STRING},那么第 1 个元素可以通过字段.first 来引用。</td>
<td align="center">struct()例如 struct&lt;street: string&gt;</td>
</tr>
<tr>
<td align="center">MAP</td>
<td align="left">MAP 是一组键-值对元组集合，使用数组表示法可以访问数据。例如，如果某个列的数据类型是 MAP，其中键-&gt;值对是’first’-&gt;’John’和’last’-&gt;’Doe’，那么可以通过字段名[‘last’]获取最后一个元素</td>
<td align="center">map()例如 map&lt;string,int&gt;</td>
</tr>
<tr>
<td align="center">ARRAY</td>
<td align="left">数组是一组具有相同类型和名称的变量的集合。这些变量称为数组的元素，每个数组元素都有一个编号，编号从零开始。例如，数组值为[‘John’, ‘Doe’]，那么第 2 个元素可以通过数组名[1]进行引用。</td>
<td align="center">Array()例如 array<string></td>
</tr>
</tbody></table>
<p>Hive 有三种复杂数据类型 ARRAY、MAP 和 STRUCT。ARRAY 和 MAP 与 Java 中的 Array和 Map 类似，而 STRUCT 与 C 语言中的 Struct 类似，它封装了一个命名字段集合，复杂数据类型允许任意层次的嵌套。</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line"> <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;songsong&quot;</span><span class="punctuation">,</span></span><br><span class="line"> <span class="attr">&quot;friends&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;bingbing&quot;</span> <span class="punctuation">,</span> <span class="string">&quot;lili&quot;</span><span class="punctuation">]</span> <span class="punctuation">,</span> </span><br><span class="line"> <span class="attr">&quot;children&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span> </span><br><span class="line"> <span class="attr">&quot;xiao song&quot;</span><span class="punctuation">:</span> <span class="number">18</span> <span class="punctuation">,</span></span><br><span class="line"> <span class="attr">&quot;xiaoxiao song&quot;</span><span class="punctuation">:</span> <span class="number">19</span></span><br><span class="line"> <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"> <span class="attr">&quot;address&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span> </span><br><span class="line"> <span class="attr">&quot;street&quot;</span><span class="punctuation">:</span> <span class="string">&quot;hui long guan&quot;</span><span class="punctuation">,</span></span><br><span class="line"> <span class="attr">&quot;city&quot;</span><span class="punctuation">:</span> <span class="string">&quot;beijing&quot;</span></span><br><span class="line"> <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>一个复杂的数据结构他的切分应该按照如何切分，包括字段与字段之间的切分，数组之间的切分，k-v之间的切分。</p>
<p>数据</p>
<figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">songsong,bingbing_lili,xiao song:18_xiaoxiao song:19,hui long guan_beijing</span><br><span class="line">yangyang,caicai_susu,xiao yang:18_xiaoxiao yang:19,chao yang_beijing</span><br></pre></td></tr></table></figure>

<p>建表语句</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">create table test(</span><br><span class="line">name string,</span><br><span class="line">friends array&lt;string&gt;,</span><br><span class="line">children map&lt;string, int&gt;,</span><br><span class="line">address struct&lt;street:string, city:string&gt;</span><br><span class="line">)</span><br><span class="line">row format delimited fields terminated by &#x27;,&#x27;</span><br><span class="line">collection items terminated by &#x27;_&#x27;</span><br><span class="line">map keys terminated by &#x27;:&#x27;</span><br><span class="line">lines terminated by &#x27;\n&#x27;;</span><br></pre></td></tr></table></figure>

<p>字段解释：<br>row format delimited fields terminated by ‘,’ – 列分隔符<br>collection items terminated by ‘_’ –MAP STRUCT 和 ARRAY 的分隔符(数据分割符号)<br>map keys terminated by ‘:’ – MAP 中的 key 与 value 的分隔符<br>lines terminated by ‘\n’; – 行分隔符</p>
<p>将文件上传之后执行<code>select * from test2</code></p>
<p><img src="https://img-blog.csdnimg.cn/960dd4a201064f9ba4195956c93dd379.png" alt="在这里插入图片描述"></p>
<p><code>select friends[1], children[&#39;xiao song&#39;], address.street from test2 where name = &#39;songsong&#39;;</code></p>
<p><img src="https://img-blog.csdnimg.cn/a075d435b0a24e7e87562741844d18dc.png" alt="在这里插入图片描述"></p>
<p><strong>隐式类型转换规则如下</strong></p>
<ol>
<li>任何整数类型都可以隐式地转换为一个范围更广的类型，如 TINYINT 可以转换成<br>INT，INT 可以转换成 BIGINT。</li>
<li>所有整数类型、FLOAT 和 STRING 类型都可以隐式地转换成 DOUBLE。</li>
<li>TINYINT、SMALLINT、INT 都可以转换为 FLOAT。</li>
<li>BOOLEAN 类型不可以转换为任何其它的类型。</li>
</ol>
<p><strong>可以使用 CAST 操作显示进行数据类型转换</strong></p>
<p>例如 CAST(‘1’ AS INT)将把字符串’1’ 转换成整数 1；如果强制类型转换失败，如执行 CAST(‘X’ AS INT)，表达式返回空值 NULL。</p>
<p><img src="https://img-blog.csdnimg.cn/9c9ce282a8bb41e6b539157b7f42a92d.png" alt="在这里插入图片描述"></p>
<h2 id="DDL-数据定义"><a href="#DDL-数据定义" class="headerlink" title="DDL 数据定义"></a>DDL 数据定义</h2><h3 id="库操作"><a href="#库操作" class="headerlink" title="库操作"></a>库操作</h3><h4 id="创建数据库"><a href="#创建数据库" class="headerlink" title="创建数据库"></a>创建数据库</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CREATE DATABASE [IF NOT EXISTS] database_name</span><br><span class="line">[COMMENT database_comment]</span><br><span class="line">[LOCATION hdfs_path]</span><br><span class="line">[WITH DBPROPERTIES (property_name=property_value, ...)];</span><br></pre></td></tr></table></figure>

<p>查看默认库的创建语句 <code>show create database default</code></p>
<p><img src="https://img-blog.csdnimg.cn/b34c7eec1b984c139f506c090f00d000.png" alt="在这里插入图片描述"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create database if not exists db_hive;</span><br></pre></td></tr></table></figure>

<p>创建一个数据库，数据库在 HDFS 上的默认存储路径是 &#x2F;user&#x2F;hive&#x2F;warehouse&#x2F;*.db。</p>
<h4 id="查看数据库详情"><a href="#查看数据库详情" class="headerlink" title="查看数据库详情"></a>查看数据库详情</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">desc database db_hive;</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/b6b0d8261c2545ada7a66d8e1d3ee5d0.png" alt="在这里插入图片描述"></p>
<h4 id="切换当前数据库"><a href="#切换当前数据库" class="headerlink" title="切换当前数据库"></a>切换当前数据库</h4><p><code>use db_hive;</code></p>
<h4 id="删除数据库"><a href="#删除数据库" class="headerlink" title="删除数据库"></a>删除数据库</h4><p><code> drop database if exists db_hive2;</code></p>
<p>如果数据库不为空，可以采用 cascade 命令，强制删除</p>
<p><code> drop database db_hive cascade;</code></p>
<h3 id="表操作"><a href="#表操作" class="headerlink" title="表操作"></a>表操作</h3><h4 id="创建表"><a href="#创建表" class="headerlink" title="创建表"></a>创建表</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> [<span class="keyword">EXTERNAL</span>] <span class="keyword">TABLE</span> [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] table_name</span><br><span class="line">[(col_name data_type [COMMENT col_comment], ...)]</span><br><span class="line">[COMMENT table_comment]</span><br><span class="line">[PARTITIONED <span class="keyword">BY</span> (col_name data_type [COMMENT col_comment], ...)]</span><br><span class="line">[CLUSTERED <span class="keyword">BY</span> (col_name, col_name, ...)</span><br><span class="line">[SORTED <span class="keyword">BY</span> (col_name [<span class="keyword">ASC</span><span class="operator">|</span><span class="keyword">DESC</span>], ...)] <span class="keyword">INTO</span> num_buckets BUCKETS]</span><br><span class="line">[<span class="type">ROW</span> FORMAT row_format]</span><br><span class="line">[STORED <span class="keyword">AS</span> file_format]</span><br><span class="line">[LOCATION hdfs_path]</span><br><span class="line">[TBLPROPERTIES (property_name<span class="operator">=</span>property_value, ...)]</span><br><span class="line">[<span class="keyword">AS</span> select_statement]</span><br></pre></td></tr></table></figure>

<p><strong>字段解释说明</strong></p>
<ol>
<li>[CREATE TABLE] 创建一个指定名字的表。如果相同名字的表已经存在，则抛出异常；用户可以用 IF NOT EXISTS 选项来忽略这个异常。</li>
<li>[EXTERNAL] hive中表会有内外之分，关键字可以让用户创建一个外部表，在建表的同时可以指定一个指向实际数据的路径（LOCATION），在删除表的时候，内部表的元数据和数据会被一起删除，而外部表只删除元数据，不删除数据。</li>
<li>[COMMENT]：为表和列添加注释。</li>
<li>[PARTITIONED BY] 创建分区表。</li>
<li>[CLUSTERED BY] 创建分桶表。</li>
<li>[SORTED BY] 不常用，对桶中的一个或多个列另外排序。</li>
<li>[ROW FORMAT ]<ul>
<li>[FIELDS TERMINATED BY char ]字段分割符</li>
<li>[COLLECTION ITEMS TERMINATED BY char] 数组分割符</li>
<li>[MAP KEYS TERMINATED BY char] KV 分隔符</li>
<li>[LINES TERMINATED BY char] 行分隔符</li>
</ul>
</li>
<li>[STORED AS] 指定存储文件类型 默认是text</li>
<li>[LOCATION] 指定表在HDFS的存储位置</li>
<li>[AS] 后跟查询语句，根据查询结果创建表。</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">create table test(</span><br><span class="line">name string,</span><br><span class="line">friends array&lt;string&gt;,</span><br><span class="line">children map&lt;string, int&gt;,</span><br><span class="line">address struct&lt;street:string, city:string&gt;</span><br><span class="line">)</span><br><span class="line">row format delimited fields terminated by &#x27;,&#x27;</span><br><span class="line">collection items terminated by &#x27;_&#x27;</span><br><span class="line">map keys terminated by &#x27;:&#x27;</span><br><span class="line">lines terminated by &#x27;\n&#x27;;</span><br></pre></td></tr></table></figure>

<h4 id="内外部表"><a href="#内外部表" class="headerlink" title="内外部表"></a>内外部表</h4><p>EXTERNAL 默认创建的都是内部表即管理表。。因为这种表，Hive 会（或多或少地）控制着数据的生命周期。Hive 默认情况下会将这些表的数据存储在由配置项<code>hive.metastore.warehouse.dir</code>(例如，&#x2F;user&#x2F;hive&#x2F;warehouse)所定义的目录的子目录下。当我们删除一个管理表时，Hive 也会删除这个表中数据。管理表不适合和其他工具共享<br>数据。</p>
<p><code>create external table test(id int);</code></p>
<p>因为表是外部表，所以 Hive 并非认为其完全拥有这份数据。删除该表并不会删除掉这<br>份数据，不过描述表的元数据信息会被删除掉。</p>
<p><strong>相互转换</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">desc formatted test2;</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/6f585536ee0b4620b181c85eadd568c0.png" alt="在这里插入图片描述"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table test2 set tblproperties(&#x27;EXTERNAL&#x27;=&#x27;TRUE&#x27;);</span><br></pre></td></tr></table></figure>

<p>TRUE 为外部表 FALSE 为内部表，(‘EXTERNAL’&#x3D;’TRUE’)和(‘EXTERNAL’&#x3D;’FALSE’)为固定写法，区分大小写！</p>
<h4 id="修改表-重命名表"><a href="#修改表-重命名表" class="headerlink" title="修改表 - 重命名表"></a>修改表 - 重命名表</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE test RENAME TO new_test</span><br></pre></td></tr></table></figure>

<p>外部表不会修改hdfs上目录的，只修改metastore 元数据的信息。内部表都会修改。</p>
<h4 id="修改表-增加-x2F-修改-x2F-替换列信息"><a href="#修改表-增加-x2F-修改-x2F-替换列信息" class="headerlink" title="修改表 - 增加&#x2F;修改&#x2F;替换列信息"></a>修改表 - 增加&#x2F;修改&#x2F;替换列信息</h4><p><strong>更新列</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE table_name CHANGE [COLUMN] col_old_name col_new_name column_type [COMMENT col_comment] [FIRST|AFTER column_name]</span><br></pre></td></tr></table></figure>

<p>修改表的列名和类型</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table new_test change column id uid int;</span><br></pre></td></tr></table></figure>

<p>类型不一致可能会导致更新失败，比如原本是String 类型，改成int，就会抛出异常。</p>
<p><strong>增加和替换列</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE table_name ADD|REPLACE COLUMNS (col_name data_type [COMMENT col_comment], ...)</span><br></pre></td></tr></table></figure>

<p>增加一列</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table new_test add columns (name string);</span><br></pre></td></tr></table></figure>

<p>替换整张表的列</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table new_test replace columns (name string);</span><br></pre></td></tr></table></figure>

<p>ADD 是代表新增一字段，字段位置在所有列后面(partition 列前)，REPLACE 则是表示替换表中所有字段。</p>
<h4 id="修改表-删除表"><a href="#修改表-删除表" class="headerlink" title="修改表 - 删除表"></a>修改表 - 删除表</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">drop table test;</span><br></pre></td></tr></table></figure>

<h2 id="DML数据操作"><a href="#DML数据操作" class="headerlink" title="DML数据操作"></a>DML数据操作</h2>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://laoshiren1207.github.io/2021/12/23/Hadoop/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Laoshiren">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LaoShiRen1207">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/12/23/Hadoop/" class="post-title-link" itemprop="url">DataWareHouse 数据仓库</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-12-23 15:13:20" itemprop="dateCreated datePublished" datetime="2021-12-23T15:13:20+08:00">2021-12-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-04-13 15:18:11" itemprop="dateModified" datetime="2022-04-13T15:18:11+08:00">2022-04-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hadoop/" itemprop="url" rel="index"><span itemprop="name">Hadoop</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="大数据"><a href="#大数据" class="headerlink" title="大数据"></a>大数据</h1><h2 id="大数据4大特点"><a href="#大数据4大特点" class="headerlink" title="大数据4大特点"></a>大数据4大特点</h2><ol>
<li><code>Volume </code>(海量数据存储)</li>
<li><code>Velocity</code>(高速)</li>
<li><code>Variety</code>(多样性)</li>
<li><code>Value</code>(低价值密度 - 数据清洗)</li>
</ol>
<p>平台</p>
<p><code>Hadoop</code>,<code>Flume</code>,<code>Kafka</code>,<code>HBase</code>,<code>Spark</code>的等框架的平台搭建，集群性能监控，集群新能调优。</p>
<p>数据仓库</p>
<p><code>ETL</code>数据清洗，数据分析，数仓建模</p>
<p>实时指标的分析性能调优，数据挖掘。</p>
<h1 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h1><p><a target="_blank" rel="noopener" href="http://hadoop.apache.org/">Hadoop 官网</a></p>
<h2 id="1-概念"><a href="#1-概念" class="headerlink" title="1 概念"></a>1 概念</h2><h3 id="1-1-Hadoop-是什么？"><a href="#1-1-Hadoop-是什么？" class="headerlink" title="1.1 Hadoop 是什么？"></a>1.1 Hadoop 是什么？</h3><p><code>Hadoop</code>是一个由<code>Apache</code>基金会所开发的<strong>分布式系统基础架构</strong>。主要解决海量数据的<strong>存储</strong>和<strong>分析计算</strong>问题。</p>
<p><code>Hadoop</code>通常是指一个更广泛的概念–<strong><code>Hadoop</code>生态圈</strong></p>
<p><img src="https://img-blog.csdnimg.cn/333ef0d516e94f89a22e7c313881f7f9.png" alt="在这里插入图片描述"></p>
<h3 id="1-2-Hadoop-的优势-4高"><a href="#1-2-Hadoop-的优势-4高" class="headerlink" title="1.2 Hadoop 的优势(4高)"></a>1.2 Hadoop 的优势(4高)</h3><ol>
<li>高可靠性:<code>Hadoop</code>底层维护了多个数据副本，所以即使<code>Hadoop</code>某个计算元素或存储出现故障，也不会导致数据丢失。</li>
<li>高扩展性:在集群分配任务数据，可方便的扩展数以千计的节点。</li>
<li>高效性:在<code>MapReduce</code>是并行工作的加快任务处理速度。</li>
<li>高容错性:能够自动的将失败的任务重新分配。</li>
</ol>
<h3 id="1-3-Hadoop-的组成"><a href="#1-3-Hadoop-的组成" class="headerlink" title="1.3 Hadoop 的组成"></a>1.3 Hadoop 的组成</h3><p><img src="https://img-blog.csdnimg.cn/504c33d9bcb640bca82852e9e38b7f02.png" alt="在这里插入图片描述"></p>
<h4 id="1-3-1-HDFS-架构概述"><a href="#1-3-1-HDFS-架构概述" class="headerlink" title="1.3.1 HDFS 架构概述"></a>1.3.1 HDFS 架构概述</h4><p><code>Hadoop Distributed File System</code>简称<code>HDFS</code>，是一个分布式文件系统。</p>
<ol>
<li><code>NameNode</code>(<code>nn</code>): 存储文件的元数据如文件名，文件目录接口，文件属性，以及每个文件的<strong>块列表</strong>和**块所在的<code>DataNode</code>**等。</li>
<li><code>DataNode</code>(<code>dn</code>): 在本地文件系统<strong>存储文件块数据</strong>，以及<strong>块数据的校验和</strong>。</li>
<li><code>Secondary NameNode</code>(<code>2nn</code>): 每隔一段时间对<code>NameNode</code>数据据备份。</li>
</ol>
<h4 id="1-3-2-Yarn架构概述"><a href="#1-3-2-Yarn架构概述" class="headerlink" title="1.3.2 Yarn架构概述"></a>1.3.2 Yarn架构概述</h4><p><code>Yet Another Resource Negotiator</code> 简称<code>Yarn </code>是<code>Hadoop</code>的资源管理器(主要管理<code>CPU</code>和内存)。</p>
<ol>
<li><code>ResouceManager</code>(<code>RM</code>): 整个集群资源的管理者。</li>
<li><code>NodeManager</code>(<code>NM</code>): 单节点服务器管理者。</li>
<li><code>ApplicationMaster</code>(<code>AM</code>): 单个任务运行的老大。</li>
<li><code>Container</code>: 容器，相当于一台独立的服务器，里面封装了任务运行所需要的资源。</li>
</ol>
<p><img src="https://img-blog.csdnimg.cn/222d8fe9ac8440e594cd6aaa6ba44f8e.png" alt="在这里插入图片描述"></p>
<h4 id="1-3-3-MapReduce架构概述"><a href="#1-3-3-MapReduce架构概述" class="headerlink" title="1.3.3 MapReduce架构概述"></a>1.3.3 MapReduce架构概述</h4><p><code>MapReduce</code>将计算分为两个阶段<code>Map</code>和<code>Reduce</code>。</p>
<ol>
<li><code>Map</code>阶段: 并行处理输入数据。</li>
<li><code>Reduce</code>阶段: 对<code>Map</code>结果进行汇总。</li>
</ol>
<h3 id="1-4-大数据技术生态体系"><a href="#1-4-大数据技术生态体系" class="headerlink" title="1.4 大数据技术生态体系"></a>1.4 大数据技术生态体系</h3><p><img src="https://img-blog.csdnimg.cn/683c98019a7d487eba94d9b95af505f8.png" alt="在这里插入图片描述"></p>
<p>推荐系统: 用户搜索&#x2F;购买记录到日志，<code>Flume</code>采集对应的日志交给<code>Kafka</code>做缓冲，然后交给<code>Flink</code>做实时计算，计算完成存储成文件&#x2F;数据库 推荐业务读取计算完成的结果返回给前端。</p>
<h2 id="2-生产集群搭建"><a href="#2-生产集群搭建" class="headerlink" title="2 生产集群搭建"></a>2 生产集群搭建</h2><h3 id="2-1-准备工作"><a href="#2-1-准备工作" class="headerlink" title="2.1 准备工作"></a>2.1 准备工作</h3><p>正常安装<code>centos7.5</code>最小版</p>
<p>修改<code>ip</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/sysconfig/network-scripts/ifcfg-ens33</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/4783521ddb9748ca98f1f565d71b7d9a.png" alt="在这里插入图片描述"></p>
<p>修改<code>host</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/hostname</span><br></pre></td></tr></table></figure>

<p>应用重启网络服务，如果报错就重启虚拟机<code>reboot</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart network</span><br></pre></td></tr></table></figure>

<p>安装<code>epel-release</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">yum install -y epel-release</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">还需要安装 net-tools</span></span><br><span class="line">yum install -y net-tools</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">vim 编辑器</span></span><br><span class="line">yum install -y vim </span><br></pre></td></tr></table></figure>

<p>关闭防火墙</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl disable firewalld.service</span><br></pre></td></tr></table></figure>

<p>安装<code>jdk</code>，解压配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf jdk***.tar.gz</span><br></pre></td></tr></table></figure>

<p> 进入<code>/etc/profile.d</code>，创建一个<code>shell</code>脚本，然后执行<code>source  /etc/profile</code>。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Java_Home jdk 8</span></span><br><span class="line">export JAVA_HOME=/home/module/jdk1.8.0_152</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br></pre></td></tr></table></figure>

<p>检查<code>java</code>安装</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">java -version</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 打印</span></span> </span><br><span class="line">java version &quot;1.8.0_152&quot;</span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_152-b16)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.152-b16, mixed mode)</span><br></pre></td></tr></table></figure>

<p>无密登录</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa</span><br><span class="line">ssh-copy-id ip</span><br></pre></td></tr></table></figure>

<h4 id="2-1-1-安装Hadoop-3-1-3"><a href="#2-1-1-安装Hadoop-3-1-3" class="headerlink" title="2.1.1 安装Hadoop 3.1.3"></a>2.1.1 安装Hadoop 3.1.3</h4><p>解压缩</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf hadoop-3.1.3.tar.gz </span><br></pre></td></tr></table></figure>

<p> 进入<code>/etc/profile.d</code>，创建一个<code>shell</code>脚本，然后执行<code>source  /etc/profile</code>。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cat /etc/profile.d/my_hadoop_env.sh </span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">Hadoop hadoop 3.1.3</span></span><br><span class="line"></span><br><span class="line">export HADOOP_HOME=/home/module/hadoop-3.1.3</span><br><span class="line"></span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/sbin</span><br></pre></td></tr></table></figure>

<p>检查<code>hadoop</code>安装</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">hadoop</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">打印</span></span><br><span class="line">Usage: hadoop [OPTIONS] SUBCOMMAND [SUBCOMMAND OPTIONS]</span><br><span class="line"> or    hadoop [OPTIONS] CLASSNAME [CLASSNAME OPTIONS]</span><br><span class="line">  where CLASSNAME is a user-provided Java class</span><br><span class="line"></span><br><span class="line">  OPTIONS is none or any of:</span><br><span class="line"></span><br><span class="line">buildpaths                       attempt to add class files from build tree</span><br><span class="line">--config dir                     Hadoop config directory</span><br><span class="line">--debug                          turn on shell script debug mode</span><br><span class="line">--help                           usage information</span><br><span class="line">hostnames list[,of,host,names]   hosts to use in slave mode</span><br><span class="line">hosts filename                   list of hosts to use in slave mode</span><br><span class="line">loglevel level                   set the log4j level for this command</span><br><span class="line">workers                          turn on worker mode</span><br><span class="line"></span><br><span class="line">  SUBCOMMAND is one of:</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    Admin Commands:</span><br><span class="line"></span><br><span class="line">daemonlog     get/set the log level for each daemon</span><br><span class="line"></span><br><span class="line">    Client Commands:</span><br><span class="line"></span><br><span class="line">archive       create a Hadoop archive</span><br><span class="line">checknative   check native Hadoop and compression libraries availability</span><br><span class="line">classpath     prints the class path needed to get the Hadoop jar and the required libraries</span><br><span class="line">conftest      validate configuration XML files</span><br><span class="line">credential    interact with credential providers</span><br><span class="line">distch        distributed metadata changer</span><br><span class="line">distcp        copy file or directories recursively</span><br><span class="line">dtutil        operations related to delegation tokens</span><br><span class="line">envvars       display computed Hadoop environment variables</span><br><span class="line">fs            run a generic filesystem user client</span><br><span class="line">gridmix       submit a mix of synthetic job, modeling a profiled from production load</span><br><span class="line">jar &lt;jar&gt;     run a jar file. NOTE: please use &quot;yarn jar&quot; to launch YARN applications, not this command.</span><br><span class="line">jnipath       prints the java.library.path</span><br><span class="line">kdiag         Diagnose Kerberos Problems</span><br><span class="line">kerbname      show auth_to_local principal conversion</span><br><span class="line">key           manage keys via the KeyProvider</span><br><span class="line">rumenfolder   scale a rumen input trace</span><br><span class="line">rumentrace    convert logs into a rumen trace</span><br><span class="line">s3guard       manage metadata on S3</span><br><span class="line">trace         view and modify Hadoop tracing settings</span><br><span class="line">version       print the version</span><br><span class="line"></span><br><span class="line">    Daemon Commands:</span><br><span class="line"></span><br><span class="line">kms           run KMS, the Key Management Server</span><br><span class="line"></span><br><span class="line">SUBCOMMAND may print help when invoked w/o parameters or with -h.</span><br></pre></td></tr></table></figure>

<p>以上就算安装成功。</p>
<h4 id="2-1-2-hadoop-目录内容"><a href="#2-1-2-hadoop-目录内容" class="headerlink" title="2.1.2 hadoop 目录内容"></a>2.1.2 hadoop 目录内容</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">cd hadoop-3.1.3</span><br><span class="line">[root@hadoop1207 hadoop-3.1.3]# ll</span><br><span class="line">总用量 180</span><br><span class="line">drwxr-xr-x. 2 1000 1000    183 9月  12 2019 bin</span><br><span class="line">drwxr-xr-x. 3 1000 1000     20 9月  12 2019 etc</span><br><span class="line">drwxr-xr-x. 2 1000 1000    106 9月  12 2019 include</span><br><span class="line">drwxr-xr-x. 3 1000 1000     20 9月  12 2019 lib</span><br><span class="line">drwxr-xr-x. 4 1000 1000   4096 9月  12 2019 libexec</span><br><span class="line">-rw-rw-r--. 1 1000 1000 147145 9月   4 2019 LICENSE.txt</span><br><span class="line">-rw-rw-r--. 1 1000 1000  21867 9月   4 2019 NOTICE.txt</span><br><span class="line">-rw-rw-r--. 1 1000 1000   1366 9月   4 2019 README.txt</span><br><span class="line">drwxr-xr-x. 3 1000 1000   4096 9月  12 2019 sbin</span><br><span class="line">drwxr-xr-x. 4 1000 1000     31 9月  12 2019 share</span><br></pre></td></tr></table></figure>

<p><strong>bin 目录</strong> 一些命令的文件目录</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">cd bin/</span><br><span class="line">[root@hadoop1207 bin]# ll</span><br><span class="line">总用量 996</span><br><span class="line">-rwxr-xr-x. 1 1000 1000 441936 9月  12 2019 container-executor</span><br><span class="line">-rwxr-xr-x. 1 1000 1000   8707 9月  12 2019 hadoop</span><br><span class="line">-rwxr-xr-x. 1 1000 1000  11265 9月  12 2019 hadoop.cmd</span><br><span class="line">-rwxr-xr-x. 1 1000 1000  11026 9月  12 2019 hdfs  			# 和资源存储相关的命令</span><br><span class="line">-rwxr-xr-x. 1 1000 1000   8081 9月  12 2019 hdfs.cmd</span><br><span class="line">-rwxr-xr-x. 1 1000 1000   6237 9月  12 2019 mapred			# 和计算相关的命令</span><br><span class="line">-rwxr-xr-x. 1 1000 1000   6311 9月  12 2019 mapred.cmd</span><br><span class="line">-rwxr-xr-x. 1 1000 1000 483728 9月  12 2019 test-container-executor</span><br><span class="line">-rwxr-xr-x. 1 1000 1000  11888 9月  12 2019 yarn				# 和资源调度相关的命令</span><br><span class="line">-rwxr-xr-x. 1 1000 1000  12840 9月  12 2019 yarn.cmd</span><br></pre></td></tr></table></figure>

<p><strong>etc&#x2F;hadoop 目录</strong> 存储一些配置文件，配置<code>hdfs</code>,<code>mapre </code>,<code>yarn</code></p>
<p><strong>sbin 目录</strong> 存储一些启动脚本</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">cd sbin/</span><br><span class="line">[root@hadoop1207 sbin]# ll</span><br><span class="line">总用量 108</span><br><span class="line">-rwxr-xr-x. 1 1000 1000 2756 9月  12 2019 distribute-exclude.sh</span><br><span class="line">drwxr-xr-x. 4 1000 1000   36 9月  12 2019 FederationStateStore</span><br><span class="line">-rwxr-xr-x. 1 1000 1000 1983 9月  12 2019 hadoop-daemon.sh			# 单节点服务器</span><br><span class="line">-rwxr-xr-x. 1 1000 1000 2522 9月  12 2019 hadoop-daemons.sh</span><br><span class="line">-rwxr-xr-x. 1 1000 1000 1542 9月  12 2019 httpfs.sh</span><br><span class="line">-rwxr-xr-x. 1 1000 1000 1500 9月  12 2019 kms.sh</span><br><span class="line">-rwxr-xr-x. 1 1000 1000 1841 9月  12 2019 mr-jobhistory-daemon.sh	# 启动历史服务器</span><br><span class="line">-rwxr-xr-x. 1 1000 1000 2086 9月  12 2019 refresh-namenodes.sh</span><br><span class="line">-rwxr-xr-x. 1 1000 1000 1779 9月  12 2019 start-all.cmd</span><br><span class="line">-rwxr-xr-x. 1 1000 1000 2221 9月  12 2019 start-all.sh</span><br><span class="line">-rwxr-xr-x. 1 1000 1000 1880 9月  12 2019 start-balancer.sh</span><br><span class="line">-rwxr-xr-x. 1 1000 1000 1401 9月  12 2019 start-dfs.cmd</span><br><span class="line">-rwxr-xr-x. 1 1000 1000 5170 9月  12 2019 start-dfs.sh  				# hdfs集群的启动命令</span><br><span class="line">-rwxr-xr-x. 1 1000 1000 1793 9月  12 2019 start-secure-dns.sh</span><br><span class="line">-rwxr-xr-x. 1 1000 1000 1571 9月  12 2019 start-yarn.cmd</span><br><span class="line">-rwxr-xr-x. 1 1000 1000 3342 9月  12 2019 start-yarn.sh				# 资源调度器命令</span><br><span class="line">-rwxr-xr-x. 1 1000 1000 1770 9月  12 2019 stop-all.cmd</span><br><span class="line">-rwxr-xr-x. 1 1000 1000 2166 9月  12 2019 stop-all.sh</span><br><span class="line">-rwxr-xr-x. 1 1000 1000 1783 9月  12 2019 stop-balancer.sh</span><br><span class="line">-rwxr-xr-x. 1 1000 1000 1455 9月  12 2019 stop-dfs.cmd</span><br><span class="line">-rwxr-xr-x. 1 1000 1000 3898 9月  12 2019 stop-dfs.sh</span><br><span class="line">-rwxr-xr-x. 1 1000 1000 1756 9月  12 2019 stop-secure-dns.sh</span><br><span class="line">-rwxr-xr-x. 1 1000 1000 1642 9月  12 2019 stop-yarn.cmd</span><br><span class="line">-rwxr-xr-x. 1 1000 1000 3083 9月  12 2019 stop-yarn.sh</span><br><span class="line">-rwxr-xr-x. 1 1000 1000 1982 9月  12 2019 workers.sh</span><br><span class="line">-rwxr-xr-x. 1 1000 1000 1814 9月  12 2019 yarn-daemon.sh</span><br><span class="line">-rwxr-xr-x. 1 1000 1000 2328 9月  12 2019 yarn-daemons.sh</span><br></pre></td></tr></table></figure>

<h3 id="2-2-本地模式"><a href="#2-2-本地模式" class="headerlink" title="2.2 本地模式"></a>2.2 本地模式</h3><p>不借助<code>hdfs</code>将文件存储再服务器内部。</p>
<p>创建一个文件，随便写一些内容，统计每个单词出现频率。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cat laoshireninput/word.txt</span><br><span class="line">laoshiren</span><br><span class="line">xiangdehua</span><br><span class="line">laoshiren</span><br><span class="line">zhoujielun</span><br></pre></td></tr></table></figure>

<p>执行计算，必须指定一个输入路径，一个输出路径</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount laoshireninput/ ./laoshirenoutput</span><br><span class="line"></span><br><span class="line">cd laoshirenoutput/</span><br><span class="line">[root@hadoop1207 laoshirenoutput]# ll</span><br><span class="line">总用量 4</span><br><span class="line">-rw-r--r--. 1 root root 38 4月  25 01:18 part-r-00000			# 真正的数据</span><br><span class="line">-rw-r--r--. 1 root root  0 4月  25 01:18 _SUCCESS				# 表示标记并没有数据</span><br><span class="line"></span><br><span class="line">cat part-r-00000 </span><br><span class="line">laoshiren	2</span><br><span class="line">xiangdehua	1</span><br><span class="line">zhoujielun	1</span><br></pre></td></tr></table></figure>

<h3 id="2-3-完全分布式集群"><a href="#2-3-完全分布式集群" class="headerlink" title="2.3 完全分布式集群"></a>2.3 完全分布式集群</h3><h4 id="2-3-1-准备工作"><a href="#2-3-1-准备工作" class="headerlink" title="2.3.1 准备工作"></a>2.3.1 准备工作</h4><p>在创建2个完全一致的虚拟机，可以不装<code>JDK</code>和<code>hadoop</code>，等后期使用<code>scp</code>拷贝过去。</p>
<p><img src="https://img-blog.csdnimg.cn/cfc2f17dea214b3dabecf500548fa1dc.png" alt="在这里插入图片描述"></p>
<p>拷贝<code>JDK</code>和<code>Hadoop</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">scp -r jdk1.8.0_152/ root@192.168.8.202:/root/module</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">scp 安全拷贝</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-r 递归</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">本地文件</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">用户@主机:对应路径</span></span><br><span class="line"></span><br><span class="line">scp -r hadoop-3.1.3/ root@192.168.8.202:/opt/modules</span><br></pre></td></tr></table></figure>

<p>修改<code>/etc/hosts</code>文件，追加如下内容</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">172.31.10.201 hadoop201</span><br><span class="line">172.31.10.202 hadoop202</span><br><span class="line">172.31.10.203 hadoop203</span><br></pre></td></tr></table></figure>

<p>安装 <code>rsync</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y rsync </span><br></pre></td></tr></table></figure>

<p>同步脚本，用于同步机器配置文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">if [ $# -lt 1 ]</span><br><span class="line">then</span><br><span class="line"> echo Not Enough Arguement!</span><br><span class="line"> exit;</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">for host in hadoop202 hadoop203 hadoop201</span><br><span class="line">do</span><br><span class="line"> echo ==================== $host ====================</span><br><span class="line"><span class="meta prompt_"> #</span><span class="language-bash">3. 遍历所有目录，挨个发送</span></span><br><span class="line"> for file in $@</span><br><span class="line"> do</span><br><span class="line"><span class="meta prompt_"> #</span><span class="language-bash">4. 判断文件是否存在</span></span><br><span class="line"> if [ -e $file ]</span><br><span class="line"> then</span><br><span class="line"><span class="meta prompt_"> #</span><span class="language-bash">5. 获取父目录</span></span><br><span class="line"> pdir=$(cd -P $(dirname $file); pwd)</span><br><span class="line"><span class="meta prompt_"> #</span><span class="language-bash">6. 获取当前文件的名称</span></span><br><span class="line"> fname=$(basename $file)</span><br><span class="line"> ssh $host &quot;mkdir -p $pdir&quot;</span><br><span class="line"> rsync -av $pdir/$fname $host:$pdir</span><br><span class="line"> else</span><br><span class="line"> echo $file does not exists!</span><br><span class="line"> fi</span><br><span class="line"> done</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<h4 id="2-3-2-Hadoop-配置文件"><a href="#2-3-2-Hadoop-配置文件" class="headerlink" title="2.3.2 Hadoop 配置文件"></a>2.3.2 Hadoop 配置文件</h4><table>
<thead>
<tr>
<th></th>
<th>hadoop201</th>
<th>hadoop202</th>
<th>hadoop203</th>
</tr>
</thead>
<tbody><tr>
<td>HDFS</td>
<td>NameNode DataNode</td>
<td>DataNode</td>
<td>SNN DataNode</td>
</tr>
<tr>
<td>YARN</td>
<td>NodeManager</td>
<td>ResourceManager NodeManager</td>
<td>NodeManager</td>
</tr>
</tbody></table>
<p>默认配置文件</p>
<p>核心配置文件 <code>core-site.xml</code></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定 NameNode 的地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop201:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定 hadoop 数据的存储目录 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/module/hadoop-3.1.3/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 配置 HDFS 网页登录使用的静态用户为 atguigu --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.http.staticuser.user<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>HDFS 配置文件<code>hdfs-site.xml</code></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- nn web 端访问地址--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop201:9870<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 2nn web 端访问地址--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop203:9868<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><code>YARN</code>配置文件<code>yarn-site.xml</code></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定 MR 走 shuffle --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定 ResourceManager 的地址--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop202<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 环境变量的继承 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.env-whitelist<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CO</span><br><span class="line">            NF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAP</span><br><span class="line">            RED_HOME</span><br><span class="line">        <span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 设置日志聚集服务器地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log.server.url<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>http://hadoop201:19888/jobhistory/logs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 设置日志保留时间为 7 天 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>604800<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>MapReduce 配置文件<code>mapred-site.xml</code></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定mapreduce 程序运行在yarn --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.app.mapreduce.am.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=/home/module/hadoop-3.1.3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=/home/module/hadoop-3.1.3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=/home/module/hadoop-3.1.3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.cluster.map.memory.mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.cluster.reduce.memory.mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 历史服务器端地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop201:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 历史服务器 web 端地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop201:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><code>vi workers</code></p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop201</span><br><span class="line">hadoop202</span><br><span class="line">hadoop203</span><br></pre></td></tr></table></figure>

<p>分发配置文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xsync /home/module/hadoop-3.1.3/etc/hadoop</span><br></pre></td></tr></table></figure>

<p>修改启动文件 <code>sbin/start-dfs.sh</code>和<code>sbin/stop-dfs.sh</code> 和<code>sbin/start-yarn.sh</code>和<code>sbin/stop-yarn.sh</code>，并分发<code>xsync /home/module/hadoop-3.1.3/sbin</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/usr/bin/env bash</span></span><br><span class="line">HDFS_DATANODE_USER=root</span><br><span class="line">HADOOP_SECURE_DN_USER=hdfs</span><br><span class="line">HDFS_NAMENODE_USER=root</span><br><span class="line">HDFS_SECONDARYNAMENODE_USER=root</span><br><span class="line">YARN_RESOURCEMANAGER_USER=root</span><br><span class="line">HADOOP_SECURE_DN_USER=yarn</span><br><span class="line">YARN_NODEMANAGER_USER=root</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">...省略</span></span><br></pre></td></tr></table></figure>

<p>集群初始化</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -format</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动hdfs</span></span><br><span class="line">sbin/start-dfs.sh</span><br></pre></td></tr></table></figure>

<p>到<code>hadoop202</code>机器 启动 <code>resouce manager</code>  </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/start-yarn.sh</span><br></pre></td></tr></table></figure>

<p>查看<code>http://hadoop201:9870</code>,<a target="_blank" rel="noopener" href="http://hadoop201:9870/">地址</a></p>
<p>查看<code>http://hadoop202:8088</code>,<a target="_blank" rel="noopener" href="http://hadoop202:8088/">地址</a></p>
<h4 id="2-3-3-基础测试"><a href="#2-3-3-基础测试" class="headerlink" title="2.3.3 基础测试"></a>2.3.3 基础测试</h4><p>创建目录</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mkdir /wcinput</span><br></pre></td></tr></table></figure>

<p>上传文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -put /root/a.txt /wcinput</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">输出</span></span><br><span class="line">2021-05-05 13:15:51,994 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/4a44b09ef326419cacf0d9bbc2ddbbae.png" alt="在这里插入图片描述"></p>
<p>实际存储在</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat $HADOOP_HOME/data/dfs/data/current/BP-1065121377-192.168.8.201-1620119427494/current/finalized/subdir0/subdir0/blk_1073741825</span><br></pre></td></tr></table></figure>

<p>wordcount</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount /wcinput /wcoutput</span><br></pre></td></tr></table></figure>

<p>编写启动脚本</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">if [ $# -lt 1 ]</span><br><span class="line">then</span><br><span class="line"> echo &quot;No Args Input...&quot;</span><br><span class="line"> exit ;</span><br><span class="line">fi</span><br><span class="line">case $1 in</span><br><span class="line">&quot;start&quot;)</span><br><span class="line"> echo &quot; =================== 启动 hadoop 集群 ===================&quot;</span><br><span class="line"> echo &quot; --------------- 启动 hdfs ---------------&quot;</span><br><span class="line"> ssh hadoop201 &quot;/home/module/hadoop-3.1.3/sbin/start-dfs.sh&quot;</span><br><span class="line"> echo &quot; --------------- 启动 yarn ---------------&quot;</span><br><span class="line"></span><br><span class="line">ssh hadoop202 &quot;/home/module/hadoop-3.1.3/sbin/start-yarn.sh&quot;</span><br><span class="line"> echo &quot; --------------- 启动 historyserver ---------------&quot;</span><br><span class="line"> ssh hadoop201 &quot;/home/module/hadoop-3.1.3/bin/mapred --daemon start historyserver&quot;</span><br><span class="line">;;</span><br><span class="line">&quot;stop&quot;)</span><br><span class="line"> echo &quot; =================== 关闭 hadoop 集群 ===================&quot;</span><br><span class="line"> echo &quot; --------------- 关闭 historyserver ---------------&quot;</span><br><span class="line"> ssh hadoop201 &quot;/home/module/hadoop-3.1.3/bin/mapred --daemon stop historyserver&quot;</span><br><span class="line"> echo &quot; --------------- 关闭 yarn ---------------&quot;</span><br><span class="line"> ssh hadoop202 &quot;/home/module/hadoop-3.1.3/sbin/stop-yarn.sh&quot;</span><br><span class="line"> echo &quot; --------------- 关闭 hdfs ---------------&quot;</span><br><span class="line"> ssh hadoop201 &quot;/home/module/hadoop-3.1.3/sbin/stop-dfs.sh&quot;</span><br><span class="line">;;</span><br><span class="line">*)</span><br><span class="line"> echo &quot;Input Args Error...&quot;</span><br><span class="line">;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure>



<h1 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h1><h2 id="hdfs-产生背景"><a href="#hdfs-产生背景" class="headerlink" title="hdfs 产生背景"></a>hdfs 产生背景</h2><p>随着数据量越来越大，在一个操作系统存不下所有的数据，那么就分配到更多的操作系<br>统管理的磁盘中，但是不方便管理和维护，迫切需要一种系统来管理多台机器上的文件，这<br>就是分布式文件管理系统。HDFS 只是分布式文件管理系统中的一种。</p>
<p>HDFS（Hadoop Distributed File System），它是一个文件系统，用于存储文件，通过目<br>录树来定位文件；其次，它是分布式的，由很多服务器联合起来实现其功能，集群中的服务<br>器有各自的角色。<br>HDFS 的使用场景：适合一次写入，多次读出的场景。一个文件经过创建、写入和关闭<br>之后就不需要改变。</p>
<h3 id="hdfs-优缺点"><a href="#hdfs-优缺点" class="headerlink" title="hdfs 优缺点"></a>hdfs 优缺点</h3><p>优点</p>
<ol>
<li>高容错性</li>
</ol>
<ul>
<li>数据自动保存多个副本。它通过增加副本的形式，提高容错性。</li>
<li>某个副本丢失以后，他可以自动恢复。</li>
</ul>
<ol start="2">
<li>适合处理大数据</li>
</ol>
<ul>
<li>数据规模：能够处理数据规模达到GB、TB、甚至PB级别的数据；</li>
<li>文件规模：能够处理百万规模以上的文件数量，数量相当之大。</li>
</ul>
<ol start="3">
<li>可构建在廉价机器上，通过多副本机制，提高可靠性。</li>
</ol>
<p>缺点</p>
<ul>
<li><p>不适合低延时数据访问，比如毫秒级的存储数据，是做不到的。</p>
</li>
<li><p>无法高效的对大量小文件进行存储。</p>
<ul>
<li>存储大量小文件的话，它会占用NameNode大量的内存来存储文件目 录和<br>块信息。这样是不可取的，因为NameNode的内存总是有限的；</li>
<li>小文件存储的寻址时间会超过读取时间，它违反了HDFS的设计目标。</li>
<li>不支持并发写入、文件随机修改。</li>
</ul>
</li>
<li><p>一个文件只能有一个写，不允许多个线程同时写；</p>
</li>
<li><p>仅支持数据append（追加），不支持文件的随机修改</p>
</li>
</ul>
<h3 id="组成"><a href="#组成" class="headerlink" title="组成"></a>组成</h3><p><img src="https://img-blog.csdnimg.cn/910e38c85fc94f068b22dc9650acec7b.png" alt="在这里插入图片描述"></p>
<p>NameNode(NN)：就是Master，它是一个主管、管理者。</p>
<ol>
<li>管理HDFS的名称空间；</li>
<li>配置副本策略；</li>
<li>管理数据块（Block）映射信息；</li>
<li>处理客户端读写请求。</li>
</ol>
<p>DataNode：就是Slave。NameNode下达命令，DataNode执行实际的操作。</p>
<ol>
<li>存储实际的数据块；</li>
<li>执行数据块的读&#x2F;写操作。</li>
</ol>
<p>Client：就是客户端。</p>
<ol>
<li>文件切分。文件上传HDFS的时候，Client将文件切分成一个一个的Block，然后进行上传；（按照NameNode文件块分割）</li>
<li>与NameNode交互，获取文件的位置信息；</li>
<li>与DataNode交互，读取或者写入数据；</li>
<li>Client提供一些命令来管理HDFS，比如NameNode格式化；</li>
<li>Client可以通过一些命令来访问HDFS，比如对HDFS增删查改操作；</li>
</ol>
<p>Secondary NameNode：并非NameNode的热备。当NameNode挂掉的时候，它并不<br>能马上替换NameNode并提供服务。</p>
<ol>
<li>辅助NameNode，分担其工作量，比如定期合并Fsimage和Edits，并推送给NameNode ；</li>
<li>在紧急情况下，可辅助恢复NameNode。</li>
</ol>
<h3 id="文件块大小问题"><a href="#文件块大小问题" class="headerlink" title="文件块大小问题"></a>文件块大小问题</h3><p>HDFS中的文件在物理上是分块存储（Block），块的大小可以通过配置参数<br>( dfs.blocksize）来规定，默认大小在Hadoop2.x&#x2F;3.x版本中是128M，1.x版本中是64M。</p>
<p><img src="https://img-blog.csdnimg.cn/609c8eab39804f349da7735354134ef2.png" alt="在这里插入图片描述"></p>
<p>思考：为什么块的大小不能设置太小，也不能设置太大？<br>（1）HDFS的块设置太小，会增加寻址时间，程序一直在找块的开始位置；<br>（2）如果块设置的太大，从磁盘传输数据的时间会明显大于定位这个块开<br>始位置所需的时间。导致程序在处理这块数据时，会非常慢。<br>总结：HDFS块的大小设置主要取决于磁盘传输速率。</p>
<h2 id="HDFS的shell相关操作"><a href="#HDFS的shell相关操作" class="headerlink" title="HDFS的shell相关操作"></a>HDFS的shell相关操作</h2><h3 id="基本语法"><a href="#基本语法" class="headerlink" title="基本语法"></a>基本语法</h3><p><code>hadoop fs 具体命令 </code>OR <code>hdfs dfs 具体命令</code> 两个是完全相同的。</p>
<p>各个模块启动停止HDFS</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh , stop-dfs.sh</span><br></pre></td></tr></table></figure>

<p>各个模块启动停止yarn</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-yarn.sh , stop-yarn.sh</span><br></pre></td></tr></table></figure>

<p>逐一启动和停止</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hdfs --daemon start/stop namenode/datanode/secondarynamenode</span><br><span class="line"></span><br><span class="line">yarn --daemon start/stop resourcemanager/nodemanager</span><br></pre></td></tr></table></figure>

<h3 id="命令大全"><a href="#命令大全" class="headerlink" title="命令大全"></a>命令大全</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs</span><br><span class="line"></span><br><span class="line">[-appendToFile &lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line"> [-cat [-ignoreCrc] &lt;src&gt; ...]</span><br><span class="line"> [-chgrp [-R] GROUP PATH...]</span><br><span class="line"> [-chmod [-R] &lt;MODE[,MODE]... | OCTALMODE&gt; PATH...]</span><br><span class="line"> [-chown [-R] [OWNER][:[GROUP]] PATH...]</span><br><span class="line"> [-copyFromLocal [-f] [-p] &lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line"> [-copyToLocal [-p] [-ignoreCrc] [-crc] &lt;src&gt; ... &lt;localdst&gt;]</span><br><span class="line"> [-count [-q] &lt;path&gt; ...]</span><br><span class="line"> [-cp [-f] [-p] &lt;src&gt; ... &lt;dst&gt;]</span><br><span class="line"> [-df [-h] [&lt;path&gt; ...]]</span><br><span class="line"> [-du [-s] [-h] &lt;path&gt; ...]</span><br><span class="line"> [-get [-p] [-ignoreCrc] [-crc] &lt;src&gt; ... &lt;localdst&gt;]</span><br><span class="line"> [-getmerge [-nl] &lt;src&gt; &lt;localdst&gt;]</span><br><span class="line"> [-help [cmd ...]]</span><br><span class="line"> [-ls [-d] [-h] [-R] [&lt;path&gt; ...]]</span><br><span class="line"> [-mkdir [-p] &lt;path&gt; ...]</span><br><span class="line"> [-moveFromLocal &lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line"> [-moveToLocal &lt;src&gt; &lt;localdst&gt;]</span><br><span class="line"> [-mv &lt;src&gt; ... &lt;dst&gt;]</span><br><span class="line"> [-put [-f] [-p] &lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line"> [-rm [-f] [-r|-R] [-skipTrash] &lt;src&gt; ...]</span><br><span class="line"> [-rmdir [--ignore-fail-on-non-empty] &lt;dir&gt; ...]</span><br><span class="line">&lt;acl_spec&gt; &lt;path&gt;]]</span><br><span class="line"> [-setrep [-R] [-w] &lt;rep&gt; &lt;path&gt; ...] </span><br><span class="line"> [-stat [format] &lt;path&gt; ...]</span><br><span class="line"> [-tail [-f] &lt;file&gt;]</span><br><span class="line"> [-test -[defsz] &lt;path&gt;]</span><br><span class="line"> [-text [-ignoreCrc] &lt;src&gt; ...]</span><br></pre></td></tr></table></figure>

<h4 id="1-上传和下载"><a href="#1-上传和下载" class="headerlink" title="1 上传和下载"></a>1 上传和下载</h4><ul>
<li>从本地<span style="color: red">剪切粘贴</span>到 HDFS</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -moveFromLocal ./shuguo.txt /sanguo</span><br></pre></td></tr></table></figure>

<ul>
<li>从本地文件系统中拷贝文件到 HDFS 路径去</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -copyFromLocal ./weiguo.txt /sanguo</span><br></pre></td></tr></table></figure>

<p>等同于<code>hadoop fs -put filePath dir</code></p>
<ul>
<li>追加文件到已存在的文件的末尾</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -appendToFile liubei.txt /sanguo/shuguo.txt</span><br></pre></td></tr></table></figure>

<ul>
<li>从hdfs 拷贝到本地</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -copyToLocal /sanguo/shuguo.txt ./downloadFile.txt</span><br></pre></td></tr></table></figure>

<p>等同于<code>-get</code></p>
<h4 id="2-其他操作"><a href="#2-其他操作" class="headerlink" title="2 其他操作"></a>2 其他操作</h4><ul>
<li>list file</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -ls /sanguo</span><br></pre></td></tr></table></figure>

<ul>
<li>显示文件内容</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -cat /sanguo/shuguo.txt</span><br></pre></td></tr></table></figure>

<ul>
<li>创建路径</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mkdir /jinguo</span><br></pre></td></tr></table></figure>

<ul>
<li>从 HDFS 的一个路径拷贝到 HDFS 的另一个路径</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -cp /sanguo/shuguo.txt  /jinguo</span><br></pre></td></tr></table></figure>

<ul>
<li>移动文件</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mv /sanguo/wuguo.txt /jinguo</span><br></pre></td></tr></table></figure>

<ul>
<li>显示一个文件的末尾 1kb 的数据</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -tail /jinguo/shuguo.txt</span><br></pre></td></tr></table></figure>

<ul>
<li>删除文件或文件夹</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -rm /sanguo/shuguo.txt</span><br></pre></td></tr></table></figure>

<ul>
<li>递归删除目录及目录里面内容</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -rm -r /sanguo</span><br></pre></td></tr></table></figure>

<h2 id="HDFS的客户端API"><a href="#HDFS的客户端API" class="headerlink" title="HDFS的客户端API"></a>HDFS的客户端API</h2><h3 id="依赖"><a href="#依赖" class="headerlink" title="依赖"></a>依赖</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"> <span class="tag">&lt;<span class="name">project.hadoop.version</span>&gt;</span>3.1.3<span class="tag">&lt;/<span class="name">project.hadoop.version</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;project.hadoop.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="基础配置"><a href="#基础配置" class="headerlink" title="基础配置"></a>基础配置</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Configuration</span> <span class="variable">configuration</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line"><span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Before</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">init</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="comment">// 1 获取文件系统</span></span><br><span class="line">    configuration = <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        fs = FileSystem.get(<span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">&quot;hdfs://hadoop201:8020&quot;</span>), configuration, <span class="string">&quot;root&quot;</span>);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException | InterruptedException | URISyntaxException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@After</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 3 关闭资源</span></span><br><span class="line">        fs.close();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="创建文件夹"><a href="#创建文件夹" class="headerlink" title="创建文件夹"></a>创建文件夹</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 创建文件夹</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testMkdir</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 2 创建目录</span></span><br><span class="line">        fs.mkdirs(<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/xiyou/huaguoshan/&quot;</span>));</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="上传文件"><a href="#上传文件" class="headerlink" title="上传文件"></a>上传文件</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 上传文件</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">put</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">filePath</span> <span class="operator">=</span> <span class="string">&quot;D:\\IdeaExampleProjects\\data-ware-house\\hadoop\\static\\image\\hadoop_0001.jpg&quot;</span>;</span><br><span class="line">        fs.copyFromLocalFile(<span class="keyword">new</span> <span class="title class_">Path</span>(filePath), <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/xiyou/huaguoshan&quot;</span>));</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/ff6e27eb8b8c463db7f400b0dae898c0.png" alt="在这里插入图片描述"></p>
<p>将 hdfs-site.xml 拷贝到项目的 resources 资源目录下</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"> 		<span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>参数优先级排序：（1）客户端代码中设置的值 <code>configuration.set(&quot;dfs.replication&quot;, &quot;2&quot;);</code> &gt;（2）ClassPath 下的用户自定义配置文<br>件 &gt;（3）然后是服务器的自定义配置（xxx-site.xml）&gt;（4）服务器的默认配置（xxx-default.xml）</p>
<h3 id="下载文件"><a href="#下载文件" class="headerlink" title="下载文件"></a>下载文件</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 文件下载</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testGet</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        fs.copyToLocalFile(<span class="literal">false</span>,</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/xiyou/huaguoshan/hadoop_0001.jpg&quot;</span>),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;d:/sunwukong2.jpg&quot;</span>), </span><br><span class="line">                <span class="literal">true</span>);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/c9219ee3ed134c198ee1b912b5f3f87c.png" alt="在这里插入图片描述"></p>
<p><code>useRawLocalFileSystem</code>:是否开启本地文件校验。设置为true，会生成一个本地文件，即文件名+.crc。将文件加上校验码，传输到客户端，然后在客户端做CRC加密算法进行校验。</p>
<h3 id="删除文件"><a href="#删除文件" class="headerlink" title="删除文件"></a>删除文件</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 文件删除</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testDelete</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        fs.delete(<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/xiyou/huaguoshan/hadoop_0002.png&quot;</span>), </span><br><span class="line">                  <span class="literal">true</span>);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/8062cfdade4b4cc8814dc9a57a4abe1c.png" alt="在这里插入图片描述"></p>
<h3 id="文件重命名和移动"><a href="#文件重命名和移动" class="headerlink" title="文件重命名和移动"></a>文件重命名和移动</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 文件更名和移动</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testMove</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        fs.rename(<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/xiyou/huaGuoshan/hadoop_0001.jpg&quot;</span>),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/xiyou/huaguoshan/hadoop_0003.jpg&quot;</span>));</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="文件详情查看"><a href="#文件详情查看" class="headerlink" title="文件详情查看"></a>文件详情查看</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 文件详情查看</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testFileList</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        RemoteIterator&lt;LocatedFileStatus&gt; fileRemoteIterator = fs.listFiles(<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/xiyou&quot;</span>), <span class="literal">true</span>);</span><br><span class="line">        <span class="keyword">while</span> (fileRemoteIterator.hasNext()) &#123;</span><br><span class="line">            <span class="type">LocatedFileStatus</span> <span class="variable">fileStatus</span> <span class="operator">=</span> fileRemoteIterator.next();</span><br><span class="line">            log.info(<span class="string">&quot;========&#123;&#125;=========&quot;</span>, fileStatus.getPath());</span><br><span class="line">            log.info(<span class="string">&quot;Permission: &#123;&#125;&quot;</span>, fileStatus.getPermission());</span><br><span class="line">            log.info(<span class="string">&quot;Owner: &#123;&#125;&quot;</span>, fileStatus.getOwner());</span><br><span class="line">            log.info(<span class="string">&quot;Group: &#123;&#125;&quot;</span>, fileStatus.getGroup());</span><br><span class="line">            log.info(<span class="string">&quot;Len: &#123;&#125;&quot;</span>, fileStatus.getLen());</span><br><span class="line">            log.info(<span class="string">&quot;ModificationTime: &#123;&#125;&quot;</span>, </span><br><span class="line">                     fileStatus.getModificationTime());</span><br><span class="line">            log.info(<span class="string">&quot;Replication: &#123;&#125;&quot;</span>, fileStatus.getReplication());</span><br><span class="line">            log.info(<span class="string">&quot;BlockSize: &#123;&#125;&quot;</span>, fileStatus.getBlockSize());</span><br><span class="line">            log.info(<span class="string">&quot;filePathName: &#123;&#125;&quot;</span>, </span><br><span class="line">                     fileStatus.getPath().getName());</span><br><span class="line">            <span class="comment">// 获取块信息</span></span><br><span class="line">            BlockLocation[] blockLocations = </span><br><span class="line">                fileStatus.getBlockLocations();</span><br><span class="line">            System.out.println(Arrays.toString(blockLocations));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>第二个参数表示递归</p>
<p><img src="https://img-blog.csdnimg.cn/9062239c79ee45adb18722034aca1809.png" alt="在这里插入图片描述"></p>
<p><code>fileStatus.getBlockLocations() </code>表示文件的块信息</p>
<p><img src="https://img-blog.csdnimg.cn/c0501726a3ec4127a50ea8c73a79de60.png" alt="在这里插入图片描述"></p>
<h2 id="HDFS读写流程"><a href="#HDFS读写流程" class="headerlink" title="HDFS读写流程"></a>HDFS读写流程</h2><h3 id="HDFS的写数据流程"><a href="#HDFS的写数据流程" class="headerlink" title="HDFS的写数据流程"></a>HDFS的写数据流程</h3><p><img src="https://img-blog.csdnimg.cn/287d5cb9ebc644d693c9c0152fbf6bbe.png" alt="在这里插入图片描述"></p>
<ol>
<li>客户端通过 Distributed FileSystem 模块向 NameNode 请求上传文件，NameNode 检查目标文件是否已存在，父目录是否存在。</li>
<li>NameNode 返回是否可以上传。</li>
<li>客户端请求第一个 Block 上传到哪几个 DataNode 服务器上。</li>
<li>NameNode 返回 3 个 DataNode 节点，分别为 dn1、dn2、dn3。</li>
<li>客户端通过 FSDataOutputStream 模块请求 dn1 上传数据，dn1 收到请求会继续调用dn2，然后 dn2 调用 dn3，将这个通信管道建立完成。</li>
<li>dn1、dn2、dn3 逐级应答客户端。</li>
<li>客户端开始往 dn1 上传第一个 Block（先从磁盘读取数据放到一个本地内存缓存），以 Packet 为单位，dn1 收到一个 Packet 就会传给 dn2，dn2 传给 dn3；dn1 每传一个 packet 会放入一个应答队列等待应答。</li>
<li>当一个 Block 传输完成之后，客户端再次请求 NameNode 上传第二个 Block 的服务器。（重复执行 3-7 步）。</li>
</ol>
<h4 id="网络拓扑-节点距离计算"><a href="#网络拓扑-节点距离计算" class="headerlink" title="网络拓扑-节点距离计算"></a>网络拓扑-节点距离计算</h4><p>节点距离：两个节点到达最近的共同祖先的距离总和。</p>
<p><img src="https://img-blog.csdnimg.cn/1f9fbe1830724becb1a2f3b6283dacfb.png" alt="在这里插入图片描述"></p>
<h4 id="副本节点选择"><a href="#副本节点选择" class="headerlink" title="副本节点选择"></a>副本节点选择</h4><blockquote>
<p>For the common case, when the replication factor is three, HDFS’s<br>placement policy is to <strong>put one replica on the local machine</strong> if the writer<br>is on a datanode, otherwise on a random datanode, <strong>another replica on a<br>node in a different (remote) rack</strong>, and <strong>the last on a different node in<br>the same remote rack</strong>. This policy cuts the inter-rack write traffic which<br>generally improves write performance. The chance of rack failure is far<br>less than that of node failure; this policy does not impact data<br>reliability and availability guarantees. However, it does reduce the<br>aggregate network bandwidth used when reading data since a block is<br>placed in only two unique racks rather than three. With this policy, the<br>replicas of a file do not evenly distribute across the racks. One third<br>of replicas are on one node, two thirds of replicas are on one rack, and<br>the other third are evenly distributed across the remaining racks. This<br>policy improves write performance without compromising data reliability<br>or read performance.</p>
</blockquote>
<p><img src="https://img-blog.csdnimg.cn/a727f77317f446c5a3736bddedbb2e1c.png" alt="在这里插入图片描述"></p>
<p>第一个机架选择最近上传速度最快，第二个选择隔壁保证可靠性，第三个再次兼顾效率选择同机架上不同节点。</p>
<p><strong>源码说明</strong></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-hdfs<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;project.hadoop.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><code>BlockPlacementPolicyDefault.chooseTargetInOrder</code></p>
<p><img src="https://img-blog.csdnimg.cn/6b1f70a7634145f2aee6a925baf913ea.png" alt="在这里插入图片描述"></p>
<p><img src="https://img-blog.csdnimg.cn/d8abe72746954b24aa26be309d303420.png" alt="在这里插入图片描述"></p>
<h3 id="HDFS的读数据流程"><a href="#HDFS的读数据流程" class="headerlink" title="HDFS的读数据流程"></a>HDFS的读数据流程</h3><p><img src="https://img-blog.csdnimg.cn/8ae7b3aaf5644411bb08a8a2da143868.png" alt="在这里插入图片描述"></p>
<ol>
<li>客户端通过 DistributedFileSystem 向 NameNode 请求下载文件，NameNode 通过查询元数据，找到文件块所在的 DataNode 地址。</li>
<li>挑选一台 DataNode（就近原则，然后随机）服务器，请求读取数据。</li>
<li>DataNode 开始传输数据给客户端（从磁盘里面读取数据输入流，以 Packet 为单位来做校验）。</li>
<li>客户端以 Packet 为单位接收，先在本地缓存，然后写入目标文件。</li>
</ol>
<p>注意：在读取block数据的时候是串行读。</p>
<h2 id="NN和2NN工作原理"><a href="#NN和2NN工作原理" class="headerlink" title="NN和2NN工作原理"></a>NN和2NN工作原理</h2><h3 id="工作机制"><a href="#工作机制" class="headerlink" title="工作机制"></a>工作机制</h3><p>NameNode的元数据存储在内存还是磁盘中？如果存储在 NameNode 节点的磁盘中，因为经常需要进行随机访问，还有响应客户请求，必然是效率过低。因此，元数据需要存放在内存中。但如果只存在内存中，一旦断电，元数据丢失，整个集群就无法工作了。因此产生在磁盘中备份元数据的 FsImage。</p>
<p>这样又会带来新的问题，当在内存中的元数据更新时，如果同时更新 FsImage，就会导致效率过低，但如果不更新，就会发生一致性问题，一旦 NameNode 节点断电，就会产生数据丢失。因此，引入 Edits 文件（只进行追加操作，效率很高）。每当元数据有更新或者添加元数据时，修改内存中的元数据并追加到 Edits 中。这样，一旦 NameNode 节点断电，可以通过 FsImage 和 Edits 的合并，合成元数据。</p>
<p>但是，如果长时间添加数据到 Edits 中，会导致该文件数据过大，效率降低，而且一旦断电，恢复元数据需要的时间过长。因此，需要定期进行 FsImage 和 Edits 的合并，如果这个操作由NameNode节点完成，又会效率过低。因此，引入一个新的节点SecondaryNamenode，专门用于 FsImage 和 Edits 的合并。</p>
<p><img src="https://img-blog.csdnimg.cn/007ba5160c074fc19efd6e7388e57f6a.png" alt="在这里插入图片描述"></p>
<ul>
<li>第一阶段：NameNode 启动<ol>
<li>第一次启动 NameNode 格式化后，创建 Fsimage 和 Edits 文件。如果不是第一次启动，直接加载编辑日志和镜像文件到内存。</li>
<li>客户端对元数据进行增删改的请求。</li>
<li>NameNode 记录操作日志，更新滚动日志。</li>
<li>NameNode 在内存中对元数据进行增删改。</li>
</ol>
</li>
<li>第二阶段：Secondary NameNode 工作<ol>
<li>Secondary NameNode 询问 NameNode 是否需要 CheckPoint。直接带回 NameNode 是否检查结果。</li>
<li>Secondary NameNode 请求执行 CheckPoint。</li>
<li>NameNode 滚动正在写的 Edits 日志。</li>
<li>将滚动前的编辑日志和镜像文件拷贝到 Secondary NameNode</li>
<li>Secondary NameNode 加载编辑日志和镜像文件到内存，并合并。</li>
<li>生成新的镜像文件 fsimage.chkpoint。</li>
<li>拷贝 fsimage.chkpoint 到 NameNode。</li>
<li>NameNode 将 fsimage.chkpoint 重新命名成 fsimage。</li>
</ol>
</li>
</ul>
<h3 id="Fsimage和Edits解析"><a href="#Fsimage和Edits解析" class="headerlink" title="Fsimage和Edits解析"></a>Fsimage和Edits解析</h3><p>NameNode被格式化之后，将在&#x2F;opt&#x2F;module&#x2F;hadoop-3.1.3&#x2F;data&#x2F;tmp&#x2F;dfs&#x2F;name&#x2F;current 目录中产生如下文件<br>（1）Fsimage文件：HDFS文件系统元数据的一个永久性的检查点，其中包含HDFS文件系统的所有目录和文件inode的序列化信息。</p>
<p>（2）Edits文件：存放HDFS文件系统的所有更新操作的路径，文件系统客户端执行的所有写操作首先会被记录到Edits文件中。</p>
<p>（3）seen_txid文件保存的是一个数字，就是最后一个edits_的数字。<br>（4）每 次NameNode启动的时候都会将Fsimage文件读入内存，加 载Edits里面的更新操作，保证内存中的元数据信息是最新的、同步的，可以看成NameNode启动的时候就将Fsimage和Edits文件进行了合并。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hdfs oiv -p XML -i fsimage_0000000000000000025 -o /home/fsimage.xml</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">hdfs oev -p XML -i edits_0000000000000000012-0000000000000000013 -o /home/edits.xml</span><br></pre></td></tr></table></figure>

<h2 id="DataNode工作机制"><a href="#DataNode工作机制" class="headerlink" title="DataNode工作机制"></a>DataNode工作机制</h2><p><img src="https://img-blog.csdnimg.cn/563c0646f34e4aa6999342f7fb7e1ef9.png" alt="在这里插入图片描述"></p>
<ol>
<li>一个数据块在 DataNode 上以文件形式存储在磁盘上，包括两个文件，一个是数据本身，一个是元数据包括数据块的长度，块数据的校验和，以及时间戳。</li>
<li>DataNode 启动后向 NameNode 注册，通过后，周期性（6 小时）的向  NameNode 上报所有的块信息。</li>
<li>心跳是每 3 秒一次，心跳返回结果带有 NameNode 给该 DataNode 的命令如复制块数据到另一台机器，或删除某个数据块。如果超过 10 分钟没有收到某个 DataNode 的心跳，则认为该节点不可用。</li>
<li>集群运行中可以安全加入和退出一些机器。</li>
</ol>
<h1 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h1><h2 id="MapReduce-概述"><a href="#MapReduce-概述" class="headerlink" title="MapReduce 概述"></a>MapReduce 概述</h2><h3 id="MapReduce-定义"><a href="#MapReduce-定义" class="headerlink" title="MapReduce 定义"></a>MapReduce 定义</h3><p>MapReduce 是一个<strong>分布式运算程序</strong>的编程框架，是用户开发“基于 Hadoop 的数据分析应用”的核心框架。MapReduce 核心功能是将<strong>用户编写的业务逻辑代码和自带默认组件</strong>整合成一个完整的<strong>分布式运算程序</strong>，并发运行在一个 Hadoop 集群上。</p>
<h3 id="MapReduce-优缺点"><a href="#MapReduce-优缺点" class="headerlink" title="MapReduce 优缺点"></a>MapReduce 优缺点</h3><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ul>
<li>MapReduce 易于编程</li>
</ul>
<p><strong>它简单的实现一些接口，就可以完成一个分布式程序</strong>，这个分布式程序可以分布到大量廉价的 PC 机器上运行。也就是说你写一个分布式程序，跟写一个简单的串行程序是一模一样的。就是因为这个特点使得 MapReduce 编程变得非常流行。</p>
<ul>
<li>良好的扩展性</li>
</ul>
<p>当你的计算资源不能得到满足的时候，你可以通过<strong>简单的增加机器</strong>来扩展它的计算能力。</p>
<ul>
<li>高容错性</li>
</ul>
<p>MapReduce 设计的初衷就是使程序能够部署在廉价的 PC 机器上，这就要求它具有很高的容错性。比如<strong>其中一台机器挂了，它可以把上面的计算任务转移到另外一个节点上运行，不至于这个任务运行失败</strong>，而且这个过程不需要人工参与，而完全是由 Hadoop 内部完成的。</p>
<ul>
<li>适合 PB 级以上海量数据的离线处理</li>
</ul>
<p>可以实现上千台服务器集群并发工作，提供数据处理能力。</p>
<h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><ul>
<li>不擅长实时计算</li>
</ul>
<p>MapReduce 无法像 MySQL 一样，在毫秒或者秒级内返回结果。</p>
<ul>
<li>不擅长流式计算</li>
</ul>
<p>流式计算的输入数据是动态的，而 MapReduce 的<strong>输入数据集是静态的</strong>，不能动态变化。这是因为 MapReduce 自身的设计特点决定了数据源必须是静态的。</p>
<ul>
<li>不擅长 DAG（有向无环图）计算</li>
</ul>
<p>多个应用程序存在依赖关系，后一个应用程序的输入为前一个的输出。在这种情况下，MapReduce 并不是不能做，而是使用后，<strong>每个 MapReduce 作业的输出结果都会写入到磁盘，会造成大量的磁盘 IO，导致性能非常的低下</strong>。</p>
<h3 id="MapReduce-核心思想"><a href="#MapReduce-核心思想" class="headerlink" title="MapReduce 核心思想"></a>MapReduce 核心思想</h3><p><img src="https://img-blog.csdnimg.cn/8feec7754e67411abedb920d6b45f309.png" alt="在这里插入图片描述"></p>
<ul>
<li>分布式的运算程序往往需要分成至少 2 个阶段。</li>
<li>第一个阶段的 MapTask 并发实例，完全并行运行，互不相干。</li>
<li>第二个阶段的 ReduceTask 并发实例互不相干，但是他们的数据依赖于上一个阶段的所有 MapTask 并发实例的输出。</li>
<li>MapReduce 编程模型只能包含一个 Map 阶段和一个 Reduce 阶段，如果用户的业务逻辑非常复杂，那就只能多个 MapReduce 程序，串行运行。</li>
</ul>
<h3 id="MapReduce-进程"><a href="#MapReduce-进程" class="headerlink" title="MapReduce 进程"></a>MapReduce 进程</h3><p>一个完整的 MapReduce 程序在分布式运行时有三类实例进程：</p>
<ul>
<li>MrAppMaster：负责整个程序的过程调度及状态协调。</li>
<li>MapTask：负责 Map 阶段的整个数据处理流程。</li>
<li>ReduceTask：负责 Reduce 阶段的整个数据处理流程。</li>
</ul>
<h3 id="官方-WordCount-源码"><a href="#官方-WordCount-源码" class="headerlink" title="官方 WordCount 源码"></a>官方 WordCount 源码</h3><table>
<thead>
<tr>
<th align="center">Java 类型</th>
<th align="center">Hadoop Writable 类型</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Boolean</td>
<td align="center">BooleanWritable</td>
</tr>
<tr>
<td align="center">Byte</td>
<td align="center">ByteWritable</td>
</tr>
<tr>
<td align="center">Int</td>
<td align="center">IntWritable</td>
</tr>
<tr>
<td align="center">Float</td>
<td align="center">FloatWritable</td>
</tr>
<tr>
<td align="center">Long</td>
<td align="center">LongWritable</td>
</tr>
<tr>
<td align="center">Double</td>
<td align="center">DoubleWritable</td>
</tr>
<tr>
<td align="center">String</td>
<td align="center">Text</td>
</tr>
<tr>
<td align="center">Map</td>
<td align="center">MapWritable</td>
</tr>
<tr>
<td align="center">Array</td>
<td align="center">ArrayWritable</td>
</tr>
<tr>
<td align="center">Null</td>
<td align="center">NullWritable</td>
</tr>
</tbody></table>
<h3 id="MapReduce-编程规范"><a href="#MapReduce-编程规范" class="headerlink" title="MapReduce 编程规范"></a>MapReduce 编程规范</h3><p>用户编写的程序分成三个部分：Mapper、Reducer 和 Driver。</p>
<p>1．Mapper阶段</p>
<ul>
<li>用户自定义的Mapper要继承自己的父类</li>
<li>Mapper的输入数据是KV对的形式（KV的类型可自定义）</li>
<li>Mapper中的业务逻辑写在map()方法中</li>
<li>Mapper的输出数据是KV对的形式（KV的类型可自定义）</li>
<li>map()方法（MapTask进程）对每一个调用一次</li>
</ul>
<p>2．Reducer阶段</p>
<ul>
<li>用户自定义的Reducer要继承自己的父类</li>
<li>Reducer的输入数据类型对应Mapper的输出数据类型，也是KV</li>
<li>Reducer的业务逻辑写在reduce()方法中</li>
<li>ReduceTask进程对每一组相同k的组调用一次reduce()方法</li>
</ul>
<p>3．Driver阶段<br>相当于YARN集群的客户端，用于提交我们整个程序到YARN集群，提交的是封装了MapReduce程序相关运行参数的job对象</p>
<h4 id="Mapper"><a href="#Mapper" class="headerlink" title="Mapper"></a>Mapper</h4><p>继承<code>org.apache.hadoop.mapreduce.Mapper</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.apache.hadoop.mapreduce;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.classification.InterfaceAudience;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.classification.InterfaceStability;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.RawComparator;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.compress.CompressionCodec;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.task.MapContextImpl;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@InterfaceAudience</span>.Public</span><br><span class="line"><span class="meta">@InterfaceStability</span>.Stable</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Mapper</span>&lt;KEYIN, VALUEIN, KEYOUT, VALUEOUT&gt; &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">class</span> <span class="title class_">Context</span> <span class="keyword">implements</span> <span class="title class_">MapContext</span>&lt;KEYIN,VALUEIN,KEYOUT,VALUEOUT&gt; &#123;</span><br><span class="line">  </span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Map阶段开始被调用一次.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">   <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">setup</span><span class="params">(Context context)</span> &#123;</span><br><span class="line">   </span><br><span class="line">   &#125;</span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 每一对Key value 都会调用异常，所有的MRA都应该重写这个方法</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span></span><br><span class="line">  <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(KEYIN key, VALUEIN value, </span></span><br><span class="line"><span class="params">                     Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">    context.write((KEYOUT) key, (VALUEOUT) value);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Map阶段结束之后执行一次</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">cleanup</span><span class="params">(Context context )</span> &#123;&#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">  	<span class="comment">// 初始化方法</span></span><br><span class="line">    setup(context);</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">while</span> (context.nextKeyValue()) &#123;</span><br><span class="line">      <span class="comment">// map </span></span><br><span class="line">        map(context.getCurrentKey(), context.getCurrentValue(), context);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      <span class="comment">// 结束方法</span></span><br><span class="line">      cleanup(context);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCountMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;Object, Text, Text, IntWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Mapper&lt;KEYIN, VALUEIN, KEYOUT, VALUEOUT&gt;</span></span><br><span class="line"><span class="comment">     *     KEYIN map阶段 输入的Key的类型</span></span><br><span class="line"><span class="comment">     *     VALUEIN map阶段输入的value 类型 通常用String 也就是 hdfs 的 text 类型</span></span><br><span class="line"><span class="comment">     *     KEYOUT 输入的Key 类型</span></span><br><span class="line"><span class="comment">     *     VALUEOUT map 阶段输出的Key 类型</span></span><br><span class="line"><span class="comment">     *     map(Key,value,context)</span></span><br><span class="line"><span class="comment">     *     context</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="type">Text</span> <span class="variable">k</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line">    <span class="type">IntWritable</span> <span class="variable">v</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>(<span class="number">1</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(Object key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">// 1 获取一行</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> value.toString();</span><br><span class="line">        <span class="comment">// 2 切割</span></span><br><span class="line">        String[] words = line.split(<span class="string">&quot; &quot;</span>);</span><br><span class="line">        <span class="comment">// 3 输出</span></span><br><span class="line">        <span class="keyword">for</span> (String word : words) &#123;</span><br><span class="line">            k.set(word);</span><br><span class="line">            context.write(k, v);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="Reducer"><a href="#Reducer" class="headerlink" title="Reducer"></a>Reducer</h4><p>继承<code>org.apache.hadoop.mapreduce.Reducer</code></p>
<p><img src="https://img-blog.csdnimg.cn/83406ca8165b4af4aac5e3db24b14c40.png" alt="在这里插入图片描述"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 这个方法对每个 键 调用一次。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span></span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(KEYIN key, Iterable&lt;VALUEIN&gt; values, Context c)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">  <span class="keyword">for</span>(VALUEIN value: values) &#123;</span><br><span class="line">    context.write((KEYOUT) key, (VALUEOUT) value);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Job</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException &#123;</span><br><span class="line">    <span class="comment">// 1 获取配置信息以及获取 job 对象</span></span><br><span class="line">    <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">    <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf);</span><br><span class="line">    <span class="comment">// 2 关联本 Driver 程序的 jar</span></span><br><span class="line">    job.setJarByClass(WordCountLinuxJobDriver.class);</span><br><span class="line">    <span class="comment">// 3 关联 Mapper 和 Reducer 的 jar</span></span><br><span class="line">    job.setMapperClass(WordCountMapper.class);</span><br><span class="line">    job.setReducerClass(WordCountReducer.class);</span><br><span class="line">    <span class="comment">// 4 设置 Mapper 输出的 kv 类型</span></span><br><span class="line">    job.setMapOutputKeyClass(Text.class);</span><br><span class="line">    job.setMapOutputValueClass(IntWritable.class);</span><br><span class="line">    <span class="comment">// 5 设置最终输出 kv 类型</span></span><br><span class="line">    job.setOutputKeyClass(Text.class);</span><br><span class="line">    job.setOutputValueClass(IntWritable.class);</span><br><span class="line">    <span class="comment">// 6 设置输入和输出路径</span></span><br><span class="line">    FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]));</span><br><span class="line">    FileOutputFormat.setOutputPath(job,<span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]));</span><br><span class="line">    <span class="comment">// 7 提交 job</span></span><br><span class="line">    <span class="type">boolean</span> <span class="variable">result</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">    System.exit(result ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>hadoop jar xxx.jar xx.xx.xxx  /input /output</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar hello-mapreduce.jar com.laoshiren.hello.hdfs.mapreduce.WordCountLinuxJobDriver /laoshiren/wordcount /laoshiren/output</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/7a47ba9403514379be52890ffd3302d4.png" alt="在这里插入图片描述"></p>
<p>具体代码看<code>hadoop/hello-mapreduce/../hdfs/mapreduce</code></p>
<h2 id="序列化"><a href="#序列化" class="headerlink" title="序列化"></a>序列化</h2><p>为什么不用 Java 的序列化?<br>Java 的序列化是一个重量级序列化框架（Serializable），一个对象被序列化后，会附带很多额外的信息（各种校验信息，Header，继承体系等），不便于在网络中高效传输。所以，Hadoop 自己开发了一套序列化机制（Writable）。</p>
<p>Hadoop 序列化特点：</p>
<ul>
<li>紧凑 ：高效使用存储空间。</li>
<li>快速：读写数据的额外开销小。</li>
<li>互操作：支持多语言的交互</li>
</ul>
<h3 id="自定义序列化"><a href="#自定义序列化" class="headerlink" title="自定义序列化"></a>自定义序列化</h3><p>具体实现 bean 对象序列化如下 。</p>
<ol>
<li>必须实现 Writable 接口<code>org.apache.hadoop.io.Writable</code></li>
<li>反序列化时，需要反射调用空参构造函数，所以必须有空参构造</li>
<li>重写序列化方法，重写反序列化方法</li>
<li>注意反序列化的顺序和序列化的顺序完全一致</li>
<li>要想把结果显示在文件中，需要重写<code>toString()</code>，可用”\t”分开，方便后续用。</li>
<li>如果需要将自定义的 bean 放在 key 中传输，则还需要实现 Comparable 接口，因为MapReduce 框中的 Shuffle 过程要求对 key 必须能排序。</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">write</span><span class="params">(DataOutput out)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    out.writeUTF(<span class="built_in">this</span>.phoneNo);</span><br><span class="line">    out.writeLong(<span class="built_in">this</span>.upStream);</span><br><span class="line">    out.writeLong(<span class="built_in">this</span>.downloadStream);</span><br><span class="line">    out.writeLong(<span class="built_in">this</span>.totalStream);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">readFields</span><span class="params">(DataInput in)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    <span class="built_in">this</span>.phoneNo = in.readUTF();</span><br><span class="line">    <span class="built_in">this</span>.upStream = in.readLong();</span><br><span class="line">    <span class="built_in">this</span>.downloadStream = in.readLong();</span><br><span class="line">    <span class="built_in">this</span>.totalStream = in.readLong();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> phoneNo + <span class="string">&quot;\t&quot;</span> + upStream + <span class="string">&quot;\t&quot;</span> + downloadStream + <span class="string">&quot;\t&quot;</span> + totalStream;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>具体代码看<code>hadoop/hello-mapreduce/../hdfs/io</code></p>
<h2 id="MapReduce框架原理"><a href="#MapReduce框架原理" class="headerlink" title="MapReduce框架原理"></a>MapReduce框架原理</h2><h3 id="InputFormat-数据输入"><a href="#InputFormat-数据输入" class="headerlink" title="InputFormat 数据输入"></a>InputFormat 数据输入</h3><h4 id="切片与-MapTask-并行度决定机制"><a href="#切片与-MapTask-并行度决定机制" class="headerlink" title="切片与 MapTask 并行度决定机制"></a>切片与 MapTask 并行度决定机制</h4><p>数据块：Block 是 HDFS 物理上把数据分成一块一块。数据块是 HDFS 存储数据单位。</p>
<p>数据切片：数据切片只是在逻辑上对输入进行分片，并不会在磁盘上将其切分成片进行存储。数据切片是 MapReduce 程序计算输入数据的单位，一个切片会对应启动一个MapTask。</p>
<ol>
<li>一个Job的Map阶段并行度由客户端在提交Job时的切片数决定</li>
<li>每一个Split切片分配一个MapTask并行实例处理</li>
<li>默认情况下，切片大小&#x3D;BlockSize</li>
<li>切片时不考虑数据集整体，而是逐个针对每一个文件单独切片</li>
</ol>
<h4 id="Job-提交流程源码和切片源码详解"><a href="#Job-提交流程源码和切片源码详解" class="headerlink" title="Job 提交流程源码和切片源码详解"></a>Job 提交流程源码和切片源码详解</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">waitForCompletion()</span><br><span class="line">submit();</span><br><span class="line"><span class="comment">// 1 建立连接</span></span><br><span class="line">connect();</span><br><span class="line"><span class="comment">// 1）创建提交 Job 的代理</span></span><br><span class="line"><span class="keyword">new</span> <span class="title class_">Cluster</span>(getConfiguration());</span><br><span class="line"><span class="comment">// （1）判断是本地运行环境还是 yarn 集群运行环境</span></span><br><span class="line">initialize(jobTrackAddr, conf);</span><br><span class="line"><span class="comment">// 2 提交 job</span></span><br><span class="line">submitter.submitJobInternal(Job.<span class="built_in">this</span>, cluster)</span><br><span class="line"><span class="comment">// 1）创建给集群提交数据的 Stag 路径</span></span><br><span class="line"><span class="type">Path</span> <span class="variable">jobStagingArea</span> <span class="operator">=</span> JobSubmissionFiles.getStagingDir(cluster, conf);</span><br><span class="line"><span class="comment">// 2）获取 jobid ，并创建 Job 路径</span></span><br><span class="line"><span class="type">JobID</span> <span class="variable">jobId</span> <span class="operator">=</span> submitClient.getNewJobID();</span><br><span class="line"><span class="comment">// 3）拷贝 jar 包到集群</span></span><br><span class="line">copyAndConfigureFiles(job, submitJobDir);</span><br><span class="line">rUploader.uploadFiles(job, jobSubmitDir);</span><br><span class="line"><span class="comment">// 4）计算切片，生成切片规划文件</span></span><br><span class="line">writeSplits(job, submitJobDir);</span><br><span class="line">maps = writeNewSplits(job,jobSubmitDir);</span><br><span class="line">input.getSplits(job);</span><br><span class="line"><span class="comment">// 5）向 Stag 路径写 XML 配置文件</span></span><br><span class="line">writeConf(conf, submitJobFile);</span><br><span class="line">conf.writeXml(out);</span><br><span class="line"><span class="comment">// 6）提交 Job,返回提交状态</span></span><br><span class="line">status = submitClient.submitJob(jobId,submitJobDir.toString(),job.getCredentials());</span><br></pre></td></tr></table></figure>

<ul>
<li><p>程序先找到你数据存储的目录。</p>
</li>
<li><p>开始遍历处理（规划切片）目录下的每一个文件</p>
</li>
<li><p>遍历第一个文件ss.txt</p>
<ul>
<li>获取文件大小fs.sizeOf(ss.txt) </li>
<li>计算切片大小computeSplitSize(Math.max(minSize,Math.min(maxSize,blocksize)))&#x3D;blocksize&#x3D;128M</li>
<li>默认情况下，切片大小&#x3D;blocksize</li>
<li>开始切，形成第1个切片：ss.txt—0:128M 第2个切片ss.txt—128:256M 第3个切片ss.txt—256M:300M<br>（每次切片时，都要判断切完剩下的部分是否大于块的1.1倍，不大于1.1倍就划分一块切片）</li>
<li>将切片信息写到一个切片规划文件中</li>
<li>整个切片的核心过程在getSplit()方法中完成</li>
<li>InputSplit只记录了切片的元数据信息，比如起始位置、长度以及所在的节点列表等。</li>
</ul>
</li>
<li><p>提交切片规划文件到YARN上，YARN上的MrAppMaster就可以根据切片规划文件计算开启MapTask个数。</p>
</li>
</ul>
<h3 id="MapReduce-工作流程"><a href="#MapReduce-工作流程" class="headerlink" title="MapReduce 工作流程"></a>MapReduce 工作流程</h3><p><img src="https://img-blog.csdnimg.cn/070f1205d662436a805a844c2616d29c.png" alt="在这里插入图片描述"></p>
<p><img src="https://img-blog.csdnimg.cn/b28473ac4f134e339de05e8c60771b34.png" alt="在这里插入图片描述"></p>
<h4 id="Partition"><a href="#Partition" class="headerlink" title="Partition"></a>Partition</h4><p>默认分区是根据key的hashCode对ReduceTasks个数取模得到的。用户没法控制哪个key存储到哪个分区。</p>
<p><img src="https://img-blog.csdnimg.cn/4f06f40936af400abb13dbdb4388675a.png" alt="在这里插入图片描述"></p>
<p>具体代码看<code>hadoop/hello-mapreduce/../hdfs/partitioner</code></p>
<h4 id="OutputFormat"><a href="#OutputFormat" class="headerlink" title="OutputFormat"></a>OutputFormat</h4><p>OutputFormat是MapReduce输出的基类，所有实现MapReduce输出都实现了 OutputFormat接口。</p>
<p><img src="https://img-blog.csdnimg.cn/7a18f76185e049e58e875cfb36e1ba77.png" alt="在这里插入图片描述"></p>
<p><img src="https://img-blog.csdnimg.cn/ddbd66e7321e4a909d85935c6c540844.png" alt="在这里插入图片描述"></p>
<p>继承OutputFormat 返回一个RecordWriter ,然后自定义RecordWrite就可以向DB等写。</p>
<p><img src="https://img-blog.csdnimg.cn/a187ba3becb8439a9ddd7e6f497d839e.png" alt="在这里插入图片描述"></p>
<p>在Driver加上<code>job.setOutputFormatClass(XXXOutputFormat.class);</code></p>
<p>具体代码看<code>hadoop/hello-mapreduce/../hdfs/outputformat</code></p>
<h4 id="Reduce-Join"><a href="#Reduce-Join" class="headerlink" title="Reduce Join"></a>Reduce Join</h4><p>Map 端的主要工作：为来自不同表或文件的 key&#x2F;value 对，打标签以区别不同来源的记录。然后用连接字段作为 key，其余部分和新加的标志作为 value，最后进行输出。<br>Reduce 端的主要工作：在 Reduce 端以连接字段作为 key 的分组已经完成，我们只需要在每一个分组当中将那些来源于不同文件的记录（在 Map 阶段已经打标志）分开，最后进行合并就 ok 了。</p>
<p><img src="https://img-blog.csdnimg.cn/d688562abe694052984226c219ba9ca2.png" alt="在这里插入图片描述"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TableBean</span> <span class="keyword">implements</span> <span class="title class_">Writable</span> &#123;</span><br><span class="line">    <span class="comment">//订单 id</span></span><br><span class="line">    <span class="keyword">private</span> String id; </span><br><span class="line">    <span class="comment">//产品 id</span></span><br><span class="line">    <span class="keyword">private</span> String pid;</span><br><span class="line">    <span class="comment">//产品数量</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> amount; </span><br><span class="line">    <span class="comment">//产品名称</span></span><br><span class="line">    <span class="keyword">private</span> String pname; </span><br><span class="line">    <span class="comment">//判断是 order 表还是 pd 表的标志字段</span></span><br><span class="line">    <span class="keyword">private</span> String flag; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>具体代码看<code>hadoop/hello-mapreduce/../hdfs/reducejoin</code></p>
<h4 id="Map-Join"><a href="#Map-Join" class="headerlink" title="Map Join"></a>Map Join</h4><p>Map Join 适用于一张表十分小、一张表很大的场景。</p>
<ul>
<li>在 Mapper 的 setup 阶段，将文件读取到缓存集合中。</li>
<li>在 Driver 驱动类中加载缓存。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">job.addCacheFile(<span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">&quot;file:///D:/IdeaExampleProjects/data-ware-house/env/example/join/input/dt.txt&quot;</span>));</span><br></pre></td></tr></table></figure>

<p>Mapper</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> Map&lt;String, String&gt; pdMap = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">setup</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">    <span class="comment">//通过缓存文件得到小表数据 pd.txt</span></span><br><span class="line">    URI[] cacheFiles = context.getCacheFiles();</span><br><span class="line">    <span class="type">Path</span> <span class="variable">path</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(cacheFiles[<span class="number">0</span>]);</span><br><span class="line">    <span class="comment">//获取文件系统对象,并开流</span></span><br><span class="line">    <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(context.getConfiguration());</span><br><span class="line">    <span class="type">FSDataInputStream</span> <span class="variable">fis</span> <span class="operator">=</span> fs.open(path);</span><br><span class="line">    <span class="comment">//通过包装流转换为 reader,方便按行读取</span></span><br><span class="line">    <span class="type">BufferedReader</span> <span class="variable">reader</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">BufferedReader</span>(<span class="keyword">new</span></span><br><span class="line">            <span class="title class_">InputStreamReader</span>(fis, <span class="string">&quot;UTF-8&quot;</span>));</span><br><span class="line">    String line;</span><br><span class="line">    <span class="keyword">while</span> (StringUtils.isNotEmpty(line = reader.readLine())) &#123;</span><br><span class="line">        <span class="comment">//切割一行</span></span><br><span class="line">        <span class="comment">//01 小米</span></span><br><span class="line">        String[] split = line.split(<span class="string">&quot;\t&quot;</span>);</span><br><span class="line">        pdMap.put(split[<span class="number">0</span>], split[<span class="number">1</span>]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//关流</span></span><br><span class="line">    IOUtils.closeStream(reader);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="MapReduce开发总结"><a href="#MapReduce开发总结" class="headerlink" title="MapReduce开发总结"></a>MapReduce开发总结</h3><ol>
<li>输入接口是<code>Inputformat</code><ul>
<li>默认使用的实现类是：TextInputFormat 一次读一行文本，然后将该行的起始偏移量作为 key，行内容作为 value 返回。</li>
</ul>
</li>
<li>逻辑处理结构是<code>Mapper</code><ul>
<li>用户根据业务需求实现其中三个方法：map() setup() cleanup ()</li>
</ul>
</li>
<li><code>Partitioner</code>分区，<code>job.setNumReduceTasks(4);</code><ul>
<li>有默认实现 HashPartitioner，逻辑是根据 key 的哈希值和 numReduces 来返回一个分区号；<code>key.hashCode()&amp;Integer.MAXVALUE % numReduces</code></li>
</ul>
</li>
<li><code>Comparable</code> 排序</li>
<li><code>Combiner</code> 合并</li>
<li>逻辑处理接口：<code>Reducer</code><ul>
<li>用户根据业务需求实现其中三个方法：reduce() setup() cleanup ()</li>
</ul>
</li>
<li>输出数据接口：<code>OutputFormat</code><ul>
<li>默认实现类是 TextOutputFormat，功能逻辑是：将每一个 KV 对，向目标文本文件输出一行。</li>
</ul>
</li>
</ol>
<h2 id="压缩"><a href="#压缩" class="headerlink" title="压缩"></a>压缩</h2><ul>
<li>压缩的好处和坏处<br>压缩的优点：以减少磁盘 IO、减少磁盘存储空间。<br>压缩的缺点：增加 CPU 开销。</li>
<li>压缩原则<ul>
<li>运算密集型的 Job，少用压缩</li>
<li>IO 密集型的 Job，多用压缩</li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th align="center">压缩格式</th>
<th align="center">Hadoop 自带</th>
<th align="center">算法</th>
<th align="center">文件扩展名</th>
<th align="center">是否可切片</th>
<th align="center">换成压缩格式后，原来的程序是否需要修改</th>
<th align="center">速度</th>
</tr>
</thead>
<tbody><tr>
<td align="center">DEFLATE</td>
<td align="center">是</td>
<td align="center">DEFLATE</td>
<td align="center">.deflate</td>
<td align="center">否</td>
<td align="center">和文本处理一样，不需要修改</td>
<td align="center">快</td>
</tr>
<tr>
<td align="center">Gzip</td>
<td align="center">是</td>
<td align="center">Gzip</td>
<td align="center">.gz</td>
<td align="center">否</td>
<td align="center">和文本处理一样，不需要修改</td>
<td align="center">一般</td>
</tr>
<tr>
<td align="center">bzip2</td>
<td align="center">是</td>
<td align="center">bzip2</td>
<td align="center">.bz2</td>
<td align="center">是</td>
<td align="center">和文本处理一样，不需要修改</td>
<td align="center">慢</td>
</tr>
<tr>
<td align="center">LZO</td>
<td align="center">否</td>
<td align="center">LZO</td>
<td align="center">.lzo</td>
<td align="center">是</td>
<td align="center">需要建索引，还需要指定输入格式</td>
<td align="center">一般</td>
</tr>
<tr>
<td align="center">Snappy</td>
<td align="center">是</td>
<td align="center">Snappy</td>
<td align="center">.snappy</td>
<td align="center">否</td>
<td align="center">和文本处理一样，不需要修改</td>
<td align="center">极快</td>
</tr>
</tbody></table>
<h3 id="Mapper-压缩"><a href="#Mapper-压缩" class="headerlink" title="Mapper 压缩"></a>Mapper 压缩</h3><p>[文件] -&gt; mapper() -&gt; 压缩 -&gt; 传输 -&gt; 解压缩 -&gt; reducer()</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1 获取配置信息以及获取 job 对象</span></span><br><span class="line"><span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line"><span class="comment">// 开启 map 端输出压缩</span></span><br><span class="line">conf.setBoolean(<span class="string">&quot;mapreduce.map.output.compress&quot;</span>, <span class="literal">true</span>);</span><br><span class="line"><span class="comment">// 设置 map 端输出压缩方式</span></span><br><span class="line">conf.setClass(<span class="string">&quot;mapreduce.map.output.compress.codec&quot;</span>, BZip2Codec.class, CompressionCodec.class);</span><br></pre></td></tr></table></figure>

<h3 id="Reduce压缩"><a href="#Reduce压缩" class="headerlink" title="Reduce压缩"></a>Reduce压缩</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 设置 reduce 端输出压缩开启</span></span><br><span class="line">FileOutputFormat.setCompressOutput(job, <span class="literal">true</span>);</span><br><span class="line"><span class="comment">// 设置压缩的方式</span></span><br><span class="line">FileOutputFormat.setOutputCompressorClass(job, BZip2Codec.class);</span><br></pre></td></tr></table></figure>

<p>具体代码看<code>hadoop/hello-mapreduce/../hdfs/zip</code></p>
<h1 id="YARN"><a href="#YARN" class="headerlink" title="YARN"></a>YARN</h1><p>Yarn 是一个资源调度平台，负责为运算程序提供服务器运算资源，相当于一个分布式的操作系统平台，而 MapReduce 等运算程序则相当于运行于操作系统之上的应用程序。</p>
<h2 id="Yarn-基础架构"><a href="#Yarn-基础架构" class="headerlink" title="Yarn 基础架构"></a>Yarn 基础架构</h2><p>YARN 主要由 ResourceManager、NodeManager、ApplicationMaster 和 Container 等组件构成。</p>
<p><strong>ResourceManager 主要作用如下</strong></p>
<ol>
<li>处理客户端请求</li>
<li>监控 NodeManager</li>
<li>启动或监控 ApplicationMaster</li>
<li>资源的分配与调度</li>
</ol>
<p><strong>NodeManager（NM）主要作用如下</strong></p>
<ol>
<li>管理单个节点上的资源</li>
<li>处理来自 ResourceManager 的命令</li>
<li>处理来自 ApplicationMaster 的命令</li>
</ol>
<p><strong>ApplicationMaster（AM）作用如下</strong></p>
<ol>
<li>为应用程序申请资源并分配给内部的任务</li>
<li>任务的监控与容错</li>
</ol>
<p><strong>Container</strong></p>
<p>Container 是 YARN 中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、磁 盘、网络等。</p>
<p><img src="https://img-blog.csdnimg.cn/33facb058f114500b3b74ea5d6909943.png" alt="在这里插入图片描述"></p>
<h2 id="YARN工作机制"><a href="#YARN工作机制" class="headerlink" title="YARN工作机制"></a>YARN工作机制</h2><p><img src="https://img-blog.csdnimg.cn/58fc20358e96479f860a947dbfa19537.png" alt="在这里插入图片描述"></p>
<ol>
<li>MR 程序提交到客户端所在的节点。<code>Job#waitForCompletion()</code> 创建 YarnRunner </li>
<li>Yarn 向 ResourceManager 申请一个 Application，RM 将该应用程序的资源路径返回给 YarnRunner 。</li>
<li>该程序将运行所需资源提交到 HDFS 上 。</li>
<li>程序资源提交完毕后，申请运行 mrAppMaster 。</li>
<li>RM 将用户的请求初始化成一个 Task ，放入调度队列。</li>
<li>其中一个 NodeManager 领取到 Task 任务。</li>
<li>该 NodeManager 创建容器 Container，并产生 MRAppmaster。</li>
<li>Container 从 HDFS 上拷贝资源到本地。</li>
<li>MRAppmaster 向 RM 申请运行 MapTask 资源。</li>
<li>RM 将运行 MapTask 任务分配给另外两个 NodeManager，另两个 NodeManager 分别领取任务并创建容器。</li>
<li>MR 向两个接收到任务的 NodeManager 发送程序启动脚本，这两个 NodeManager分别启动 MapTask，MapTask 对数据分区排序。</li>
<li>MrAppMaster 等待所有 MapTask 运行完毕后，向 RM 申请容器，运行 ReduceTask。</li>
<li>ReduceTask 向 MapTask 获取相应分区的数据。</li>
<li>程序运行完毕后，MR 会向 RM 申请注销自己。</li>
</ol>
<h2 id="Yarn-调度器和调度算法"><a href="#Yarn-调度器和调度算法" class="headerlink" title="Yarn 调度器和调度算法"></a>Yarn 调度器和调度算法</h2><p>目前，Hadoop 作业调度器主要有三种：FIFO、容量（Capacity Scheduler）和公平（Fair Scheduler）。Apache Hadoop3.1.3 默认的资源调度器是 Capacity Scheduler。CDH 框架默认调度器是 Fair Scheduler。</p>
<h3 id="先进先出调度器（FIFO）"><a href="#先进先出调度器（FIFO）" class="headerlink" title="先进先出调度器（FIFO）"></a>先进先出调度器（FIFO）</h3><p>FIFO 调度器（First In First Out）：单队列，根据提交作业的先后顺序，先来先服务。</p>
<h3 id="容量调度器（Capacity-Scheduler）"><a href="#容量调度器（Capacity-Scheduler）" class="headerlink" title="容量调度器（Capacity Scheduler）"></a>容量调度器（Capacity Scheduler）</h3><p><img src="https://img-blog.csdnimg.cn/93c2fa56748541ccbe1b73aaa1ee8a65.png" alt="在这里插入图片描述"></p>
<ol>
<li>多队列：每个队列可配置一定的资源量，每个队列采用FIFO调度策略。</li>
<li>容量保证：管理员可为每个队列设置资源最低保证和资源使用上限</li>
<li>灵活性：如果一个队列中的资源有剩余，可以暂时共享给那些需要资源的队列，而一旦该队列有新的应用程序提交，则其他队列借调的资源会归还给该队列。</li>
<li>多租户：<ul>
<li>支持多用户共享集群和多应用程序同时运行。</li>
<li>为了防止同一个用户的作业独占队列中的资源，该调度器会对同一用户提交的作业所占资源量进行限定。</li>
</ul>
</li>
</ol>
<p><strong>容量调度器资源分配算法</strong></p>
<p><img src="https://img-blog.csdnimg.cn/6625724dffad459ab6204811ec5482b4.png" alt="在这里插入图片描述"></p>
<h3 id="公平调度器（Fair-Scheduler）"><a href="#公平调度器（Fair-Scheduler）" class="headerlink" title="公平调度器（Fair Scheduler）"></a>公平调度器（Fair Scheduler）</h3><h2 id="Yarn-常用命令"><a href="#Yarn-常用命令" class="headerlink" title="Yarn 常用命令"></a>Yarn 常用命令</h2><p>**查询任务列表 **</p>
<p><code>yarn application -list  -appStates finished</code></p>
<p>states: [NEW, NEW_SAVING, SUBMITTED, ACCEPTED, RUNNING, FINISHED, FAILED, KILLED]</p>
<p><img src="https://img-blog.csdnimg.cn/f5b65a284a2144bea9bf3faf03d03e8d.png" alt="在这里插入图片描述"></p>
<p><strong>杀死应用程序</strong></p>
<p><code>yarn  application -kill [application ID]</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">yarn application -kill application_1640246979505_0001</span><br><span class="line"></span><br><span class="line">2021-12-23 17:33:02,104 INFO client.RMProxy: Connecting to ResourceManager at hadoop202/172.31.10.202:8032</span><br><span class="line">Application application_1640246979505_0001 has already finished </span><br></pre></td></tr></table></figure>

<p><strong>查看日志</strong></p>
<p><code>yarn logs -applicationId  application_1640246979505_0001</code></p>
<p><strong>查看尝试运行的任务</strong></p>
<p><code>yarn applicationattempt -list application_1640246979505_0002</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">2021-12-23 17:42:29,838 INFO client.RMProxy: Connecting to ResourceManager at hadoop202/172.31.10.202:8032</span><br><span class="line">Total number of application attempts :1</span><br><span class="line">         ApplicationAttempt-Id	               State	                    AM-Container-Id	                       Tracking-URL</span><br><span class="line">appattempt_1640246979505_0002_000001	            FINISHED	container_1640246979505_0002_01_000001	http://hadoop202:8088/proxy/application_1640246979505_0002/</span><br></pre></td></tr></table></figure>

<p><strong>ApplicationAttemp 状态</strong></p>
<p><code>yarn applicationattempt -status appattempt_1640246979505_0002_000001</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">2021-12-23 20:17:51,948 INFO client.RMProxy: Connecting to ResourceManager at hadoop202/172.31.10.202:8032</span><br><span class="line">Application Attempt Report : </span><br><span class="line">	ApplicationAttempt-Id : appattempt_1640246979505_0002_000001</span><br><span class="line">	State : FINISHED</span><br><span class="line">	AMContainer : container_1640246979505_0002_01_000001</span><br><span class="line">	Tracking-URL : http://hadoop202:8088/proxy/application_1640246979505_0002/</span><br><span class="line">	RPC Port : 35243</span><br><span class="line">	AM Host : hadoop203</span><br><span class="line">	Diagnostics : </span><br></pre></td></tr></table></figure>

<p><strong>查看 container 日志</strong></p>
<p><code>yarn logs -applicationId  application_1640246979505_0002 -containerId container_1640246979505_0002_01_000001 </code></p>
<p><strong>yarn node 查看节点状态</strong></p>
<p><code>yarn node -list all</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">2021-12-23 20:19:35,826 INFO client.RMProxy: Connecting to ResourceManager at hadoop202/172.31.10.202:8032</span><br><span class="line">Total Nodes:3</span><br><span class="line">         Node-Id	     Node-State	Node-Http-Address	Number-of-Running-Containers</span><br><span class="line"> hadoop201:35523	        RUNNING	   hadoop201:8042	                           0</span><br><span class="line"> hadoop203:39840	        RUNNING	   hadoop203:8042	                           0</span><br><span class="line"> hadoop202:40982	        RUNNING	   hadoop202:8042	                           0</span><br></pre></td></tr></table></figure>

<p><strong>yarn rmadmin 更新配置</strong></p>
<p>加载队列配置：<code>yarn rmadmin -refreshQueues</code></p>
<p><strong>yarn queue 查看队列</strong></p>
<p><code>yarn queue -status default</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">2021-12-23 20:22:16,517 INFO client.RMProxy: Connecting to ResourceManager at hadoop202/172.31.10.202:8032</span><br><span class="line">Queue Information : </span><br><span class="line">Queue Name : default</span><br><span class="line">	State : RUNNING</span><br><span class="line">	Capacity : 100.0%</span><br><span class="line">	Current Capacity : .0%</span><br><span class="line">	Maximum Capacity : 100.0%</span><br><span class="line">	Default Node Label expression : &lt;DEFAULT_PARTITION&gt;</span><br><span class="line">	Accessible Node Labels : *</span><br><span class="line">	Preemption : disabled</span><br><span class="line">	Intra-queue Preemption : disabled</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="Yarn-生产环境核心参数"><a href="#Yarn-生产环境核心参数" class="headerlink" title="Yarn 生产环境核心参数"></a>Yarn 生产环境核心参数</h2><h3 id="ResourceManager-相关"><a href="#ResourceManager-相关" class="headerlink" title="ResourceManager 相关"></a>ResourceManager 相关</h3><table>
<thead>
<tr>
<th align="left">配置</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left">yarn.resourcemanager.scheduler.class</td>
<td align="left">配置调度器，默认容量</td>
</tr>
<tr>
<td align="left">yarn.resourcemanager.scheduler.client.thread-count</td>
<td align="left">ResourceManager处理调度器请求的线程数量，默认50</td>
</tr>
</tbody></table>
<h3 id="NodeManager-相关"><a href="#NodeManager-相关" class="headerlink" title="NodeManager 相关"></a>NodeManager 相关</h3><table>
<thead>
<tr>
<th align="left">配置</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left">yarn.nodemanager.resource.detect-hardware-capabilities</td>
<td align="left">是否让yarn自己检测硬件进行配置，默认false</td>
</tr>
<tr>
<td align="left">yarn.nodemanager.resource.count-logical-processors-as-cores</td>
<td align="left">是否将虚拟核数当作CPU核数，默认false</td>
</tr>
<tr>
<td align="left">yarn.nodemanager.resource.pcores-vcores-multiplier</td>
<td align="left">虚拟核数和物理核数乘数，例如：4核8线程，该参数就应设为2，默认1.0</td>
</tr>
<tr>
<td align="left">yarn.nodemanager.resource.memory-mb</td>
<td align="left">NodeManager使用内存，默认8G</td>
</tr>
<tr>
<td align="left">yarn.nodemanager.resource.system-reserved-memory-mb</td>
<td align="left">NodeManager为系统保留多少内存,以上二个参数配置一个即可</td>
</tr>
<tr>
<td align="left">yarn.nodemanager.resource.cpu-vcores</td>
<td align="left">NodeManager使用CPU核数，默认8个</td>
</tr>
<tr>
<td align="left">yarn.nodemanager.pmem-check-enabled</td>
<td align="left">是否开启物理内存检查限制container，默认打开</td>
</tr>
<tr>
<td align="left">yarn.nodemanager.vmem-check-enabled</td>
<td align="left">是否开启虚拟内存检查限制container，默认打开</td>
</tr>
<tr>
<td align="left">yarn.nodemanager.vmem-pmem-ratio</td>
<td align="left">虚拟内存物理内存比例，默认2.1</td>
</tr>
</tbody></table>
<h3 id="Containe-相关"><a href="#Containe-相关" class="headerlink" title="Containe 相关"></a>Containe 相关</h3><table>
<thead>
<tr>
<th align="left">配置</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left">yarn.scheduler.minimum-allocation-mb</td>
<td align="left">容器最最小内存，默认1G</td>
</tr>
<tr>
<td align="left">yarn.scheduler.maximum-allocation-mb</td>
<td align="left">容器最最大内存，默认8G</td>
</tr>
<tr>
<td align="left">yarn.scheduler.minimum-allocation-vcores</td>
<td align="left">容器最小CPU核数，默认1个</td>
</tr>
<tr>
<td align="left">yarn.scheduler.maximum-allocation-vcores</td>
<td align="left">容器最大CPU核数，默认4个</td>
</tr>
</tbody></table>
<h2 id="Tools"><a href="#Tools" class="headerlink" title="Tools"></a>Tools</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.Tool;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCountTools</span> <span class="keyword">implements</span> <span class="title class_">Tool</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Configuration conf;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">run</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> job.waitForCompletion(<span class="literal">true</span>) ? <span class="number">0</span> : <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setConf</span><span class="params">(Configuration conf)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.conf = conf;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Configuration <span class="title function_">getConf</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> conf;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.Tool;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.ToolRunner;</span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCountDriver</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Tool tool;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="comment">// 1. 创建配置文件</span></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="comment">// 2. 判断是否有 tool 接口</span></span><br><span class="line">        <span class="keyword">switch</span> (args[<span class="number">0</span>])&#123;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&quot;wordcount&quot;</span>:</span><br><span class="line">                tool = <span class="keyword">new</span> <span class="title class_">WordCountTools</span>();</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">default</span>:</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(<span class="string">&quot; No such tool: &quot;</span>+ args[<span class="number">0</span>] );</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 3. 用 Tool 执行程序</span></span><br><span class="line">        <span class="comment">// Arrays.copyOfRange 将老数组的元素放到新数组里面</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">run</span> <span class="operator">=</span> ToolRunner.run(conf, tool, Arrays.copyOfRange(args, <span class="number">1</span>, args.length));</span><br><span class="line">        System.exit(run);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yarn jar hello-yarn.jar com.laoshiren.hello.yarn.tools.WordCountDriver wordcount /input /output</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://laoshiren1207.github.io/2021/11/29/DataWareHouse/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Laoshiren">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LaoShiRen1207">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/11/29/DataWareHouse/" class="post-title-link" itemprop="url">DataWareHouse 数据仓库</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-11-29 15:13:20" itemprop="dateCreated datePublished" datetime="2021-11-29T15:13:20+08:00">2021-11-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-04-13 15:15:02" itemprop="dateModified" datetime="2022-04-13T15:15:02+08:00">2022-04-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/DataWareHouse/" itemprop="url" rel="index"><span itemprop="name">DataWareHouse</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="架构"><a href="#架构" class="headerlink" title="[架构]"></a>[架构]</h2><p>MPP架构优点</p>
<ol>
<li>传统数仓常见的随机数架构，将单机数据库节点组成集群，提升性能</li>
<li>节点间为非共享架构（Share Noting），没个节点都有独立的磁盘存储系统和内存系统</li>
<li>每台数据通过专用网络或者商业通用网络互相连接，彼此协同计算，作为整体提供服务</li>
<li>设计上优先考虑C 其实A P</li>
</ol>
<p><img src="https://img-blog.csdnimg.cn/113780f4e7044d648dacb5fc005d63e2.png"></p>
<p>MPP架构缺点</p>
<ol>
<li>存储位置不透明，通过hash确定数据所在物理节点，查询任务在所有节点均会执行</li>
<li>并行计算式，单节点瓶颈会成为整个系统短板，容错性差</li>
<li>分布式事务的实现会导致扩展性降低</li>
</ol>
<p>分布式架构（Hadoop 架构）</p>
<ol>
<li>各节点实现场地自治（可以单独运行局部应用），数据在及群众全局透明共享</li>
<li>每个节点通过局域网连接，节点间的通信开销较大，运算时致力减少数据移动</li>
<li>有效考虑分区容错 然后是A C</li>
</ol>
<p>MPP + 分布式架构</p>
<ol>
<li>数据存储采用分布式架构中的公共存储，提高分区容错</li>
<li>上层架构采用MPP，减少运算延迟</li>
</ol>
<h3 id="通用架构"><a href="#通用架构" class="headerlink" title="通用架构"></a>通用架构</h3><p><img src="https://img-blog.csdnimg.cn/0f00d56c5fff436b91fc36547d960020.png"></p>
<p>ETL（Extract-Transform-Load）数据同步模块，将业务数据抽酒进行交互转换清洗，标准化。</p>
<p>ODS 存储清洗过后的原始数据（不允许修改，保证数据一致）</p>
<p>CDM </p>
<p>DWD 数据明细</p>
<p>DWS 数据汇总（宽表，提升数据分析）</p>
<p>ADS 数据应用</p>
<h3 id="ETL流程"><a href="#ETL流程" class="headerlink" title="ETL流程"></a>ETL流程</h3><h4 id="Extract-Transform-Load"><a href="#Extract-Transform-Load" class="headerlink" title="Extract-Transform-Load"></a>Extract-Transform-Load</h4><ul>
<li>将数据从来源段经过抽取，交互转换，加载至目的端的过程</li>
<li>构建数据仓库的重要一环，用户从数据源抽取所需的数据，经过数据清洗，最终按照预先定义好的数据仓库模型，将数据加载到数据仓库中。</li>
</ul>
<h4 id="数据抽取-Extraction"><a href="#数据抽取-Extraction" class="headerlink" title="数据抽取[Extraction]"></a>数据抽取[Extraction]</h4><ul>
<li>抽取的数据源可分为结构化、非结构化数据、半结构化数据</li>
<li>结构化的数据一般采用JDBC、数据库日志的方式，非|半结构化的数据会监听文件变动</li>
</ul>
<h4 id="抽取方式"><a href="#抽取方式" class="headerlink" title="抽取方式"></a>抽取方式</h4><ul>
<li>数据抽取方式有全量同步、增量同步两种方式</li>
<li>全量同步会将全部数据进行抽取，一般用于初始化数据装载</li>
<li>增量同步方式会检测数据的变动，抽取发生变动的数据，一般用于数据更新</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/e7293ffd698b480186ff5d2c6f048590.png"></p>
<h4 id="数据转换-Transformation"><a href="#数据转换-Transformation" class="headerlink" title="数据转换[Transformation]"></a>数据转换[Transformation]</h4><ul>
<li>数据转换姚经理数据清洗和转换两个阶段<ul>
<li>数据清洗主要是对出现的重复、二义性、不完整、违反业务或者逻辑规则等问题的数据进行统一的处理</li>
<li>数据转换主要是对数据进行标准化处理，进行字段、数据类型、数据定义的转换</li>
</ul>
</li>
<li>结构化数据在转换过程中的逻辑较为简单，非|半结构化的数据转换较为复杂</li>
</ul>
<h4 id="数据加载-Loading"><a href="#数据加载-Loading" class="headerlink" title="数据加载[Loading]"></a>数据加载[Loading]</h4><ul>
<li>将最后处理完的数据导入到对应的目标源里</li>
</ul>
<p>结构化数据ETL工具：<code>Sqoop</code> <code>Kettle</code></p>
<p>半|非结构化数据ETL工具：<code>Flume</code> <code>Logstash</code></p>
<h3 id="数据积存-ODS"><a href="#数据积存-ODS" class="headerlink" title="数据积存 ODS"></a>数据积存 ODS</h3><h4 id="操作数据层-ODS"><a href="#操作数据层-ODS" class="headerlink" title="操作数据层[ODS]"></a>操作数据层[ODS]</h4><ul>
<li>数据与原业务数据保持一致，可以增加字段用来进行数据管理（扩充集）</li>
<li>存储的历史数据是只读的，提供业务系统查询使用</li>
<li>业务系统对历史数据完成修改后，将update_type字段更新为UPDATE，追加回ODS中</li>
</ul>
<blockquote>
<p>比如业务系统需要对N年前的数据进行修改，那ODS层提供了查询功能，业务系统修改数据后，发现ODS层数据不能被修改。</p>
<p>所以业务系统只能将查询的出来的数据追加到ODS层将update_type修改为UPDATE，然后将历史数据删除，保证数据仓库最新的时效性</p>
</blockquote>
<p><img src="https://img-blog.csdnimg.cn/a505e2a03b8a4001b090529d006ebd14.png"></p>
<ul>
<li>在离线数据中，业务数据定期通过ETL流程导入到ODS中，导入的方式也有全量、增量两种<ul>
<li>全量导入：数据第一次导入时，选择此种方式</li>
<li>增量导入：数据非第一次导入是，每次只需要导入新增、修改的数据，建议使用外连接&amp;全覆盖</li>
</ul>
</li>
</ul>
<h3 id="数据分析-DWD-DWS-ADS"><a href="#数据分析-DWD-DWS-ADS" class="headerlink" title="数据分析 DWD DWS ADS"></a>数据分析 DWD DWS ADS</h3><h4 id="数据明细层-DWD"><a href="#数据明细层-DWD" class="headerlink" title="数据明细层[DWD]"></a>数据明细层[DWD]</h4><ul>
<li>数明细层对ODS层的数据进行清洗、标准化、维度退化（时间、分类、地域）</li>
<li>数据仍然班组3NF模型，为分析运算做准备</li>
</ul>
<p>维度退化(多张表合并成一张表)</p>
<p><img src="https://img-blog.csdnimg.cn/7cd52e8672e9484ab2de97ef8708fc4e.png"></p>
<h4 id="数据汇总层-DWS"><a href="#数据汇总层-DWS" class="headerlink" title="数据汇总层[DWS]"></a>数据汇总层[DWS]</h4><ul>
<li>数据汇总层的数据对数据明细层的数据，按照分析主题镜像计算汇总，存放便于分析的宽表</li>
<li>存储模型并非3NF，而是注重数据聚合，复杂查询、性能处理更优的数仓模型</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/136bd8990bb24d9b81490c6e047d9693.png" alt="在这里插入图片描述"></p>
<p>DWS层应该包含模型和基于模型汇总的数据</p>
<h4 id="数据应用层-ADS"><a href="#数据应用层-ADS" class="headerlink" title="数据应用层[ADS]"></a>数据应用层[ADS]</h4><ul>
<li>数据应用层也被称为数据集市</li>
<li>存储数据分析结果，为不用业务场景提供接口，减轻数据仓库的负<ul>
<li>数据仓库擅长数据分析，直接方法业务查询结构，会加重其负担</li>
</ul>
</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/ec19d78275934cf1ad0b53abb05431a6.png" alt="在这里插入图片描述"></p>
<h2 id="建模"><a href="#建模" class="headerlink" title="[建模]"></a>[建模]</h2><h3 id="OLTP，OLAP"><a href="#OLTP，OLAP" class="headerlink" title="OLTP，OLAP"></a>OLTP，OLAP</h3><h4 id="OLTP系统建模方法"><a href="#OLTP系统建模方法" class="headerlink" title="OLTP系统建模方法"></a>OLTP系统建模方法</h4><p>OLTP（在线事务处理）系统中，主要操作是随机读写</p>
<ul>
<li>为了保证数据一致性、减少冗余，尝试用关系模型</li>
<li>在关系模型中，使用三范式规则来减少冗余</li>
</ul>
<h4 id="OLAP"><a href="#OLAP" class="headerlink" title="OLAP"></a>OLAP</h4><p>OLAP系统中，主要操作是复杂分析查询，关注数据整合，以及分析、处理性能。根据存储的方式不同，又可以分为ROLAP，MOLAP和HOLAP</p>
<ul>
<li>ROLAP（Relation OLAP，关系型OLAP）：使用关系模型构建，存储系统一般为RDBMS</li>
<li>MOLAP（Multidimensional OLAP，多维度OLAP）：预先聚合计算，使用多维度数组的形式保存数据结果，加快查询分析时间</li>
<li>HOLAP（Hybrid OLAP，混合架构的OLAP）：ROLAP和MOLAP两者的继承，如底层是关系型，高层是多维矩阵型；查询高于ROLAP，低于MOLAP</li>
</ul>
<h3 id="ROLAP，MOLAP建模理论"><a href="#ROLAP，MOLAP建模理论" class="headerlink" title="ROLAP，MOLAP建模理论"></a>ROLAP，MOLAP建模理论</h3><h4 id="ROLAP系统建模方法"><a href="#ROLAP系统建模方法" class="headerlink" title="ROLAP系统建模方法"></a>ROLAP系统建模方法</h4><p>典型的数仓建方法有ER模型，维度模型，DataValue，Anchor（维度模型适合频繁变动的业务）</p>
<p><img src="https://img-blog.csdnimg.cn/71025049edc345978db966b80da277d9.png" alt="在这里插入图片描述"></p>
<h5 id="维度模型"><a href="#维度模型" class="headerlink" title="维度模型"></a>维度模型</h5><ul>
<li>维度模型中，表被分为维度表、事实表，维度是对事实的一种组织</li>
<li>维度一般包含分类、时间、地域</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/b229d41c9b9d4e089980e43cb8e40bf7.png" alt="在这里插入图片描述"></p>
<p><img src="https://img-blog.csdnimg.cn/fab0230b7eec46218a6b106ba607c974.png" alt="在这里插入图片描述"></p>
<blockquote>
<p>中间的订单就是事实表，旁边围绕的就是维度表</p>
<p>建立好维度表后，可以根据不同的维度进行分析，比如地区，年份的分析</p>
</blockquote>
<p>维度模型分为星型模型、雪花模型、星座模型，模型建立后方便对数据进行多维分析。 </p>
<h5 id="星型模型"><a href="#星型模型" class="headerlink" title="星型模型"></a>星型模型</h5><p>标准的星型模型，维度只有一层，性能分析最优</p>
<p><img src="https://img-blog.csdnimg.cn/deebdebccc254795871bedf1a0518e8a.png" alt="在这里插入图片描述"></p>
<h5 id="雪花模型"><a href="#雪花模型" class="headerlink" title="雪花模型"></a>雪花模型</h5><p>雪花模型具有多层维度，比较接近3NF，较为灵活</p>
<p><img src="https://img-blog.csdnimg.cn/4e04ad43a9d74e2a87cedfcad9a089d5.png" alt="在这里插入图片描述"></p>
<h5 id="星座模型"><a href="#星座模型" class="headerlink" title="星座模型"></a>星座模型</h5><ul>
<li>星座模型基于多个事实表，事实表之间会共享一些维度表</li>
<li>是大型数据仓库中的常态，是业务增长的结果，与模型设计无关</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/62dd29869efb465d9dfb3536642a5334.png" alt="在这里插入图片描述"></p>
<h5 id="宽表模型"><a href="#宽表模型" class="headerlink" title="宽表模型"></a>宽表模型</h5><ul>
<li>宽表模型是维度模型的衍生，适合Join性能不佳的数据仓库产品</li>
<li>宽表模型将维度冗余到事实表中，形成宽表，以此减少Join操作</li>
</ul>
<img src="https://img-blog.csdnimg.cn/a280eaf339194a5ba8e2ce15714389b0.png" alt="在这里插入图片描述" style="zoom:50%;" />

<h4 id="MOLAP系统建模方式"><a href="#MOLAP系统建模方式" class="headerlink" title="MOLAP系统建模方式"></a>MOLAP系统建模方式</h4><ul>
<li>MOLAP将数据进行预结算，并将聚合结果存储到CUBE模型中</li>
<li>CUBE 模型以多维数组的形式，物化到存储系统中，加快后续的查询</li>
<li>生成CUBE需要大量的时间、空间，维度预处理可能为导致数据膨胀</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/a85265ef3c674108974797e33d7b19e2.png" alt="在这里插入图片描述"></p>
<p>常见MOLAP产品：<code>Kylin</code>，<code>Druid</code></p>
<h3 id="多维分析"><a href="#多维分析" class="headerlink" title="多维分析"></a>多维分析</h3><ul>
<li>OLAP主要操作是复杂查询，可以多表关联，使用COUNT，SUM，AVG等聚合函数</li>
<li>OLAP对复杂查询操作做了直观的定义，包括钻取、切片、切块、旋转。</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/73e49bb4c69c466ca159a52b63c208f1.png" alt="在这里插入图片描述"></p>
<h4 id="钻取"><a href="#钻取" class="headerlink" title="[钻取]"></a>[钻取]</h4><ul>
<li>对维度不同次的分析，通过改变维度的层次来变换分析的粒度</li>
<li>钻取包括上卷，下钻</li>
</ul>
<p>上卷（Roll-up）也称为向上钻取，指从低层次到高层次的切换</p>
<p>下钻（Drill-down），指从高层次到低层次的切换</p>
<p><img src="https://img-blog.csdnimg.cn/40d30b19f01d4793a4d8d2fe7507d172.png" alt="在这里插入图片描述"></p>
<h4 id="切片，切块"><a href="#切片，切块" class="headerlink" title="[切片，切块]"></a>[切片，切块]</h4><p>选择某个维度进行分割称为切片</p>
<p>按照多维进行的切片称为切块</p>
<p><img src="https://img-blog.csdnimg.cn/0a5f8f81157c470f8bd3edb8b7411e1d.png" alt="在这里插入图片描述"></p>
<h4 id="旋转"><a href="#旋转" class="headerlink" title="[旋转]"></a>[旋转]</h4><p>对维度方向的转换，类似交换坐标轴上卷</p>
<p><img src="https://img-blog.csdnimg.cn/af32254bc744413a856e24c540d25a19.png" alt="在这里插入图片描述"></p>
<h2 id="最佳实践"><a href="#最佳实践" class="headerlink" title="[最佳实践]"></a>[最佳实践]</h2><h3 id="数据仓库表类型"><a href="#数据仓库表类型" class="headerlink" title="数据仓库表类型"></a>数据仓库表类型</h3><h4 id="维度建模中的表分类"><a href="#维度建模中的表分类" class="headerlink" title="维度建模中的表分类"></a>维度建模中的表分类</h4><ul>
<li>事实表</li>
<li>维度表</li>
<li>事务事实表</li>
<li>周期快照事实表</li>
<li>累计快照事实表</li>
</ul>
<h5 id="事实表"><a href="#事实表" class="headerlink" title="事实表"></a>事实表</h5><p>一般是指一个现实存在的业务对象，比如用户，商品，商家，销售员等</p>
<p><img src="https://img-blog.csdnimg.cn/73f806f189b44104baf22b190b605a8a.png" alt="在这里插入图片描述"></p>
<h5 id="维度表"><a href="#维度表" class="headerlink" title="维度表"></a>维度表</h5><p>一般是指对应一些业务状态，代码的解释表。通常使用维度对事实表中的数据进行统计，聚合运算</p>
<p><img src="https://img-blog.csdnimg.cn/9aeb38083377422b91792bdb292ce723.png" alt="在这里插入图片描述"></p>
<h5 id="事务事实表"><a href="#事务事实表" class="headerlink" title="事务事实表"></a>事务事实表</h5><p>随着业务不断产生的数据，一旦生产不再会发生变化，比如交易流水，操作日志，出库入库记录<br><img src="https://img-blog.csdnimg.cn/47910569e2954f01a99355e550f42410.png" alt="在这里插入图片描述"></p>
<h5 id="周期事实表"><a href="#周期事实表" class="headerlink" title="周期事实表"></a>周期事实表</h5><ul>
<li>随着业务周期型的推荐而变化，完成建个周期内的度量统计，如年，季度累计。</li>
<li>使用周期+状态度量的组合，如年累计订单数量。</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/1750424c85744fba845ce4d687f009ae.png" alt="在这里插入图片描述"></p>
<h5 id="累计快照事实表"><a href="#累计快照事实表" class="headerlink" title="累计快照事实表"></a>累计快照事实表</h5><p>记录不确定周期的度量统计，完全覆盖一个事实的生命周期，如订单状态，通常有多个时间字段记录生命周期的关键时间点，只有<strong>一条记录</strong>针对此记录不断更新</p>
<p><img src="https://img-blog.csdnimg.cn/c48dd9a3619a4a25bcd5ec1ed7756b9f.png" alt="在这里插入图片描述"></p>
<blockquote>
<p><strong>实现方式一</strong></p>
<ul>
<li>使用日期分区表，全量记录数据，每天的分区存储全量数据与当天增量数据合并的结果</li>
<li>数据量大会导致全量表膨胀，存储大量永远不更新的冷数据，对性能影响较大</li>
<li>适用于数据量少的情况</li>
</ul>
</blockquote>
<blockquote>
<p><strong>实现方式二</strong></p>
<ul>
<li>使用日期分区表，推测数据最长的生命周期，存储周期内数据，周期外的类数据存储到归档表</li>
<li>需要保留多天的分区数据，存储消耗依然很大</li>
</ul>
</blockquote>
<blockquote>
<p><strong>实现方式三</strong></p>
<ul>
<li>使用日期分区表，以业务实体结束的时间分区，每天分区存放当天结束的数据；设计一个时间非常大的分区</li>
<li>已结束的数据存放到相对应的分区，未结束的数据分区，数据量也不会很大，ETL性能好</li>
<li>无存储浪费，数据全局唯一</li>
<li>业务系统可能无法表示业务实体的结束时间，可以用奇台相关业务系统的结束标志作为此业务系统的结束，业务以使用最长生命周期时间或者前端系统的数据归档时间</li>
</ul>
</blockquote>
<h5 id="拉链表"><a href="#拉链表" class="headerlink" title="拉链表"></a>拉链表</h5><p>拉链表记录每条信息的生命周期，用于保存历史数据的所有（变更）状态，拉链表将表数据的随机修改方式变城顺序追加</p>
<p><img src="https://img-blog.csdnimg.cn/7fff73ab9de240a4a37aea8d0c106fe7.png" alt="在这里插入图片描述"></p>
<h3 id="ETL策略"><a href="#ETL策略" class="headerlink" title="ETL策略"></a>ETL策略</h3><p><strong>[全量同步]</strong></p>
<p>数据初始化装在一定使用全量同步的方式，因为业务技术原因，使用全量同步的方式做周期数据更新，直接覆盖原有数据即可。</p>
<p><strong>[增量同步]</strong></p>
<p>传统数据整合方案中，大多采用merge方式，主流大数据平台不支持update操作，可采用全外连接覆盖方式，如果担心数据更新出错，可采用分区方式，每天保证最小的全量版本，保存较短周期。</p>
<h3 id="任务调度"><a href="#任务调度" class="headerlink" title="任务调度"></a>任务调度</h3><p>为什么需要任务调度</p>
<ul>
<li>解决任务单元间的依赖关系</li>
<li>自动化完成任务的定时执行</li>
</ul>
<h4 id="常见任务类型"><a href="#常见任务类型" class="headerlink" title="常见任务类型"></a>常见任务类型</h4><p>shell， Java程序，MapReduce程序，sql脚本</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://laoshiren1207.github.io/2020/08/01/ElasticSearch/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Laoshiren">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LaoShiRen1207">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/08/01/ElasticSearch/" class="post-title-link" itemprop="url">高效搜索 Elastic Search 7.6.2</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-08-01 18:45:48" itemprop="dateCreated datePublished" datetime="2020-08-01T18:45:48+08:00">2020-08-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-04-13 15:00:19" itemprop="dateModified" datetime="2022-04-13T15:00:19+08:00">2022-04-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Java/" itemprop="url" rel="index"><span itemprop="name">Java</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Java/SpringBoot/" itemprop="url" rel="index"><span itemprop="name">SpringBoot</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="微服务解决方案-–-高效搜索-Elastic-Search-7-6-2"><a href="#微服务解决方案-–-高效搜索-Elastic-Search-7-6-2" class="headerlink" title="微服务解决方案 – 高效搜索 Elastic Search  7.6.2"></a>微服务解决方案 – 高效搜索 <code>Elastic Search</code>  7.6.2</h1><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>为什么要写这篇，首先写这个的技术的肯定不止我一个，我将其视为我自己学习的一个路程，自己如果在工作中使用到了，也可以拿来直接上手。我认为在工作中，以最少知识原则去构建项目，当这些最少知识不足以满足需求的时候，就得学习。</p>
<h3 id="Elastic-Search-是什么"><a href="#Elastic-Search-是什么" class="headerlink" title="Elastic Search 是什么"></a><code>Elastic Search</code> 是什么</h3><p><code>Elastic Search</code> （以下简称<code>ES</code>）,<code>ES</code> 是一个基于<code>Lucene</code>的搜索服务器。它提供了一个<strong>分布式</strong>多用户能力的<strong>全文搜索</strong>引擎，基于<code>RESTful web</code>接口，使用<code>Java</code>语言开发。</p>
<p><code>Lucene</code>是<code>Apache</code>软件基金会<code>Jakarta</code>项目组的一个子项目，是一个开放源代码的全文检索引擎工具包，但它不是一个完整的全文检索引擎，而是一个全文检索引擎的架构。</p>
<h3 id="为什么使用Elastic-Search"><a href="#为什么使用Elastic-Search" class="headerlink" title="为什么使用Elastic Search"></a>为什么使用<code>Elastic Search</code></h3><p>相对于以前我们需要模糊查询一个字段通常直接访问数据库，使用<code>like %%</code>，才能做到。这样的查询很慢，而且数据量一单上来了以后，效率很低。</p>
<p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/b50d7fdbe544"><code>Elastic Search</code>为啥这么快</a></p>
<h4 id="谁在使用"><a href="#谁在使用" class="headerlink" title="谁在使用"></a>谁在使用</h4><ol>
<li>维基百科</li>
<li><code>Stack Overflow</code></li>
<li><code>Github</code></li>
<li><code>Alibaba</code></li>
</ol>
<p>等许多公司或平台都使用了<code>ES</code>，这么多公司都在用，足以证明这个产品的好。相同类型的产品也有一个叫<code>Solr</code> （读作<code>Solar</code>）也是一款搜索引擎。</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/jameshadoop/article/details/44905643"><code>Elastic Search</code>与<code>Solr</code>选型</a></p>
<h3 id="Elastic-Search-使用"><a href="#Elastic-Search-使用" class="headerlink" title="Elastic Search 使用"></a><code>Elastic Search</code> 使用</h3><h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h4><p>我们继续采用<code>docker compose</code>的方式来安装。实际上生产的时候可以考虑传统安装或者<code>docker</code>或者<code>k8s</code>的方式，具体看公司，生产<strong>不推荐</strong>本次<code>docker compose</code>的配置方式进行安装。编写<code>docker-compose.yml</code></p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">&#x27;3.1&#x27;</span>                          </span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">elasticsearch:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">daocloud.io/library/elasticsearch:7.6.2</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">elasticsearch</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">9200</span><span class="string">:9200</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="attr">discovery.type:</span> <span class="string">single-node</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># kibana图形化插件</span></span><br><span class="line">  <span class="attr">kibana:</span></span><br><span class="line">    <span class="attr">image:</span>  <span class="string">daocloud.io/library/kibana:7.6.2</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="attr">SERVER_NAME:</span> <span class="string">kibana</span></span><br><span class="line">      <span class="attr">ELASTICSEARCH_URL:</span> <span class="string">http://192.168.8.4:9200</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">5601</span><span class="string">:5601</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span>  <span class="string">elasticsearch</span></span><br></pre></td></tr></table></figure>

<p>启动<code>docker-compose up -d</code>，测试（这里切换到我阿里云的学生机器）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">curl http://120.26.114.23:9200</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 输出</span></span></span><br><span class="line">&#123;</span><br><span class="line">  &quot;name&quot; : &quot;82877e7f04ad&quot;,</span><br><span class="line">  &quot;cluster_name&quot; : &quot;docker-cluster&quot;,</span><br><span class="line">  &quot;cluster_uuid&quot; : &quot;x-bP78brST-9y8kpLUtrxw&quot;,</span><br><span class="line">  &quot;version&quot; : &#123;</span><br><span class="line">    &quot;number&quot; : &quot;7.6.2&quot;,</span><br><span class="line">    &quot;build_flavor&quot; : &quot;default&quot;,</span><br><span class="line">    &quot;build_type&quot; : &quot;docker&quot;,</span><br><span class="line">    &quot;build_hash&quot; : &quot;ef48eb35cf30adf4db14086e8aabd07ef6fb113f&quot;,</span><br><span class="line">    &quot;build_date&quot; : &quot;2020-03-26T06:34:37.794943Z&quot;,</span><br><span class="line">    &quot;build_snapshot&quot; : false,</span><br><span class="line">    &quot;lucene_version&quot; : &quot;8.4.0&quot;,</span><br><span class="line">    &quot;minimum_wire_compatibility_version&quot; : &quot;6.8.0&quot;,</span><br><span class="line">    &quot;minimum_index_compatibility_version&quot; : &quot;6.0.0-beta1&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;tagline&quot; : &quot;You Know, for Search&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>浏览器访问5601端口</p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9sYW9zaGlyZW4ub3NzLWNuLXNoYW5naGFpLmFsaXl1bmNzLmNvbS8xOTlkNmJhYi00MDg3LTQ1N2ItOGE2OS01NjFlNmJiMmFmMTkucG5n?x-oss-process=image/format,png"></p>
<h4 id="Elastic-Search-api简介"><a href="#Elastic-Search-api简介" class="headerlink" title="Elastic Search api简介"></a><code>Elastic Search api</code>简介</h4><p>上面说了<code>ES</code>是使用了<code>RESTFul Web</code>接口，也就是说我们可以通过<code>http</code>请求的方式来查询修改删除我们的数据。</p>
<table>
<thead>
<tr>
<th align="center">method</th>
<th align="center"><code>url</code>地址</th>
<th align="center">描述</th>
<th align="center">补充</th>
</tr>
</thead>
<tbody><tr>
<td align="center">PUT</td>
<td align="center">:9200&#x2F;索引名称&#x2F;类型名称&#x2F;文档ID</td>
<td align="center">创建文档(指定文档)</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">POST</td>
<td align="center">:9200&#x2F;索引名称&#x2F;类型名称</td>
<td align="center">创建文档随机ID</td>
<td align="center">最好将唯一ID写入文档ID</td>
</tr>
<tr>
<td align="center">POST</td>
<td align="center">:9200&#x2F;索引名称&#x2F;类型名称&#x2F;文档ID&#x2F;_update</td>
<td align="center">修改文档</td>
<td align="center">常用更新</td>
</tr>
<tr>
<td align="center">DELETE</td>
<td align="center">:9200&#x2F;索引名称&#x2F;类型名称&#x2F;文档ID</td>
<td align="center">删除文档</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">GET</td>
<td align="center">:9200&#x2F;索引名称&#x2F;类型名称&#x2F;文档ID</td>
<td align="center">查询文档</td>
<td align="center">指定ID</td>
</tr>
<tr>
<td align="center">POST</td>
<td align="center">:9200&#x2F;索引名称&#x2F;类型名称&#x2F;_search</td>
<td align="center">查询对应数据</td>
<td align="center">模糊查询</td>
</tr>
</tbody></table>
<h4 id="api使用"><a href="#api使用" class="headerlink" title="api使用"></a><code>api</code>使用</h4><p>我们既然安装了<code>kibana</code>就使用它的图像界面去请求对应的<code>api</code>。</p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9sYW9zaGlyZW4ub3NzLWNuLXNoYW5naGFpLmFsaXl1bmNzLmNvbS85Y2RiZDU5Ni1jMWY4LTRkYTktYWU0My1mZjZkNjI4MmZmYzMucG5n?x-oss-process=image/format,png"></p>
<p>点击<code>Dev Tools</code>就是我们写<code>api</code>的地方</p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9sYW9zaGlyZW4ub3NzLWNuLXNoYW5naGFpLmFsaXl1bmNzLmNvbS81M2QzM2Q4YS0zNmI0LTQzZGItODljOC0zOGQzYTM1Mjk4OTcucG5n?x-oss-process=image/format,png"></p>
<p>获取<code>ES</code>基本信息</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">GET /</span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;name&quot;</span> : <span class="string">&quot;82877e7f04ad&quot;</span>,</span><br><span class="line">  <span class="string">&quot;cluster_name&quot;</span> : <span class="string">&quot;docker-cluster&quot;</span>,</span><br><span class="line">  <span class="string">&quot;cluster_uuid&quot;</span> : <span class="string">&quot;x-bP78brST-9y8kpLUtrxw&quot;</span>,</span><br><span class="line">  <span class="string">&quot;version&quot;</span> : &#123;</span><br><span class="line">    <span class="string">&quot;number&quot;</span> : <span class="string">&quot;7.6.2&quot;</span>,</span><br><span class="line">    <span class="string">&quot;build_flavor&quot;</span> : <span class="string">&quot;default&quot;</span>,</span><br><span class="line">    <span class="string">&quot;build_type&quot;</span> : <span class="string">&quot;docker&quot;</span>,</span><br><span class="line">    <span class="string">&quot;build_hash&quot;</span> : <span class="string">&quot;ef48eb35cf30adf4db14086e8aabd07ef6fb113f&quot;</span>,</span><br><span class="line">    <span class="string">&quot;build_date&quot;</span> : <span class="string">&quot;2020-03-26T06:34:37.794943Z&quot;</span>,</span><br><span class="line">    <span class="string">&quot;build_snapshot&quot;</span> : <span class="literal">false</span>,</span><br><span class="line">    <span class="string">&quot;lucene_version&quot;</span> : <span class="string">&quot;8.4.0&quot;</span>,</span><br><span class="line">    <span class="string">&quot;minimum_wire_compatibility_version&quot;</span> : <span class="string">&quot;6.8.0&quot;</span>,</span><br><span class="line">    <span class="string">&quot;minimum_index_compatibility_version&quot;</span> : <span class="string">&quot;6.0.0-beta1&quot;</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">&quot;tagline&quot;</span> : <span class="string">&quot;You Know, for Search&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>创建索引 – 仅解构</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">PUT /test2</span><br><span class="line">&#123;</span><br><span class="line">	&quot;mappings&quot;: &#123;</span><br><span class="line">		&quot;properties&quot;: &#123;</span><br><span class="line">			&quot;name&quot;: &#123;</span><br><span class="line">				&quot;type&quot;: &quot;text&quot;</span><br><span class="line">			&#125;,</span><br><span class="line">			&quot;age&quot;: &#123;</span><br><span class="line">				&quot;type&quot;: &quot;long&quot;</span><br><span class="line">			&#125;,</span><br><span class="line">			&quot;birthday&quot;: &#123;</span><br><span class="line">				&quot;type&quot;: &quot;date&quot;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 输出</span></span></span><br><span class="line">&#123;</span><br><span class="line">  &quot;acknowledged&quot; : true,</span><br><span class="line">  &quot;shards_acknowledged&quot; : true,</span><br><span class="line">  &quot;index&quot; : &quot;test2&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>获取索引解构信息</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">GET /test2</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 输出</span></span></span><br><span class="line">&#123;</span><br><span class="line">  &quot;test2&quot; : &#123;</span><br><span class="line">    &quot;aliases&quot; : &#123; &#125;,</span><br><span class="line">    &quot;mappings&quot; : &#123;</span><br><span class="line">      &quot;properties&quot; : &#123;</span><br><span class="line">        &quot;age&quot; : &#123;</span><br><span class="line">          &quot;type&quot; : &quot;long&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;birthday&quot; : &#123;</span><br><span class="line">          &quot;type&quot; : &quot;date&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;name&quot; : &#123;</span><br><span class="line">          &quot;type&quot; : &quot;text&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;settings&quot; : &#123;</span><br><span class="line">      &quot;index&quot; : &#123;</span><br><span class="line">        &quot;creation_date&quot; : &quot;1594478433505&quot;,</span><br><span class="line">        &quot;number_of_shards&quot; : &quot;1&quot;,</span><br><span class="line">        &quot;number_of_replicas&quot; : &quot;1&quot;,</span><br><span class="line">        &quot;uuid&quot; : &quot;ZcECl47_SPWdWSh-xifv5w&quot;,</span><br><span class="line">        &quot;version&quot; : &#123;</span><br><span class="line">          &quot;created&quot; : &quot;7060299&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;provided_name&quot; : &quot;test2&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>创建文档 – 指定文档<code>Id</code> ，<code>_doc</code>表示默认类型(后续<code>ES</code>会在某个版本舍弃)</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">PUT /test2/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">  &quot;name&quot;:&quot;laoshiren&quot;,</span><br><span class="line">  &quot;age&quot;:1,</span><br><span class="line">  &quot;birthday&quot;:&quot;2020-07-10&quot;</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 输出</span></span></span><br><span class="line">&#123;</span><br><span class="line">  &quot;_index&quot; : &quot;test2&quot;,</span><br><span class="line">  &quot;_type&quot; : &quot;_doc&quot;,</span><br><span class="line">  &quot;_id&quot; : &quot;1&quot;,</span><br><span class="line">  &quot;_version&quot; : 1,</span><br><span class="line">  &quot;result&quot; : &quot;created&quot;,</span><br><span class="line">  &quot;_shards&quot; : &#123;</span><br><span class="line">    &quot;total&quot; : 2,</span><br><span class="line">    &quot;successful&quot; : 1,</span><br><span class="line">    &quot;failed&quot; : 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;_seq_no&quot; : 0,</span><br><span class="line">  &quot;_primary_term&quot; : 1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>获取指定文档</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">GET /test2/_doc/1</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 输出</span></span></span><br><span class="line">&#123;</span><br><span class="line">  &quot;_index&quot; : &quot;test2&quot;,</span><br><span class="line">  &quot;_type&quot; : &quot;_doc&quot;,</span><br><span class="line">  &quot;_id&quot; : &quot;1&quot;,</span><br><span class="line">  &quot;_version&quot; : 1,</span><br><span class="line">  &quot;_seq_no&quot; : 0,</span><br><span class="line">  &quot;_primary_term&quot; : 1,</span><br><span class="line">  &quot;found&quot; : true,</span><br><span class="line">  &quot;_source&quot; : &#123;</span><br><span class="line">    &quot;name&quot; : &quot;laoshiren&quot;,</span><br><span class="line">    &quot;age&quot; : 1,</span><br><span class="line">    &quot;birthday&quot; : &quot;2020-07-10&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>修改文档（部分属性更新）<code>_update</code>必须跟上，不然属性会有属性为<code>null</code>，现在已经更新语法</p>
<p><code>POST /&#123;index&#125;/_update/&#123;id&#125;</code>，<code>_version</code>表示我们更新的版本。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">POST /test2/_doc/1/_update</span><br><span class="line">&#123;</span><br><span class="line">	&quot;doc&quot;: &#123;</span><br><span class="line">		&quot;name&quot;: &quot;Kakarotto&quot;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 输出</span></span></span><br><span class="line">&#123;</span><br><span class="line">  &quot;_index&quot; : &quot;test2&quot;,</span><br><span class="line">  &quot;_type&quot; : &quot;_doc&quot;,</span><br><span class="line">  &quot;_id&quot; : &quot;1&quot;,</span><br><span class="line">  &quot;_version&quot; : 2,</span><br><span class="line">  &quot;result&quot; : &quot;noop&quot;,</span><br><span class="line">  &quot;_shards&quot; : &#123;</span><br><span class="line">    &quot;total&quot; : 0,</span><br><span class="line">    &quot;successful&quot; : 0,</span><br><span class="line">    &quot;failed&quot; : 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;_seq_no&quot; : 2,</span><br><span class="line">  &quot;_primary_term&quot; : 1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>删除文档，必须指定<code>Id</code>，再次获取就会返回<code>found: false</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">DELETE /test2/_doc/2</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 输出</span></span></span><br><span class="line">&#123;</span><br><span class="line">  &quot;_index&quot; : &quot;test2&quot;,</span><br><span class="line">  &quot;_type&quot; : &quot;_doc&quot;,</span><br><span class="line">  &quot;_id&quot; : &quot;2&quot;,</span><br><span class="line">  &quot;_version&quot; : 2,</span><br><span class="line">  &quot;result&quot; : &quot;deleted&quot;,</span><br><span class="line">  &quot;_shards&quot; : &#123;</span><br><span class="line">    &quot;total&quot; : 2,</span><br><span class="line">    &quot;successful&quot; : 1,</span><br><span class="line">    &quot;failed&quot; : 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;_seq_no&quot; : 3,</span><br><span class="line">  &quot;_primary_term&quot; : 1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>简单查询 <code>_score</code>表示文档对应查询条件的匹配程度</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">GET /test2/_doc/_search</span><br><span class="line">&#123;</span><br><span class="line">	&quot;query&quot;: &#123;</span><br><span class="line">		&quot;match&quot;: &#123;</span><br><span class="line">			&quot;name&quot;: &quot;laoshiren&quot;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 输出</span></span></span><br><span class="line">&#123;</span><br><span class="line">  &quot;took&quot; : 849,</span><br><span class="line">  &quot;timed_out&quot; : false,</span><br><span class="line">  &quot;_shards&quot; : &#123;</span><br><span class="line">    &quot;total&quot; : 1,</span><br><span class="line">    &quot;successful&quot; : 1,</span><br><span class="line">    &quot;skipped&quot; : 0,</span><br><span class="line">    &quot;failed&quot; : 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;hits&quot; : &#123;</span><br><span class="line">    &quot;total&quot; : &#123;</span><br><span class="line">      &quot;value&quot; : 2,</span><br><span class="line">      &quot;relation&quot; : &quot;eq&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;max_score&quot; : 0.8713851,</span><br><span class="line">    &quot;hits&quot; : [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;_index&quot; : &quot;test2&quot;,</span><br><span class="line">        &quot;_type&quot; : &quot;_doc&quot;,</span><br><span class="line">        &quot;_id&quot; : &quot;2&quot;,</span><br><span class="line">        &quot;_score&quot; : 0.8713851,</span><br><span class="line">        &quot;_source&quot; : &#123;</span><br><span class="line">          &quot;name&quot; : &quot;laoshiren&quot;,</span><br><span class="line">          &quot;age&quot; : 1,</span><br><span class="line">          &quot;birthday&quot; : &quot;2020-07-10&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;_index&quot; : &quot;test2&quot;,</span><br><span class="line">        &quot;_type&quot; : &quot;_doc&quot;,</span><br><span class="line">        &quot;_id&quot; : &quot;4&quot;,</span><br><span class="line">        &quot;_score&quot; : 0.429556,</span><br><span class="line">        &quot;_source&quot; : &#123;</span><br><span class="line">          &quot;name&quot; : &quot;laoshiren is a good boy&quot;,</span><br><span class="line">          &quot;age&quot; : 1,</span><br><span class="line">          &quot;birthday&quot; : &quot;2020-07-10&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>限制查询字段</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	&quot;query&quot;: &#123;</span><br><span class="line">		&quot;match&quot;: &#123;</span><br><span class="line">			&quot;name&quot;: &quot;laoshiren&quot;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;,</span><br><span class="line">	&quot;_source&quot;:[ &quot;name&quot;,&quot;birthday&quot; ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>分页查询</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	&quot;query&quot;: &#123;</span><br><span class="line">		&quot;match&quot;: &#123;</span><br><span class="line">			&quot;name&quot;: &quot;laoshiren&quot;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;,</span><br><span class="line">	&quot;from&quot;: 0,</span><br><span class="line">	&quot;size&quot;: 2</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>更多<code>api</code>操作可以看下其他人的文档，这里只举了常用的。</p>
<p>先说一下为什么我们公司要使用<code>ES</code>，因为我们公司有一个表大概在20W+，我们希望能够快速的查找相似数据，进行对比。<code>MySQL</code>虽然能使用<code>like</code>进行查找，但是分词等技术还得想办法解决。于是我们本来是打算使用<code>MySQL</code>+<code>Drools</code>，进行查询使用规则引擎给每一个查询结果进行打分去实现（不过我一直觉得加上<code>Drools</code>好像没什么意义）。</p>
<p>然后经过一段时间的讨论，最终决定还是使用<code>ES</code>去 实现这种查找，20W 虽然不多，但相对于<code>MySQL</code>的模糊查找来说，<code>ES</code>显得更加合适。</p>
<h3 id="SpringBoot"><a href="#SpringBoot" class="headerlink" title="SpringBoot"></a>SpringBoot</h3><p>首先创建一个<code>springboot</code>项目，查看一下我们的版本，因为我们公司的小伙伴使用的是<code>2.1.8.RELEASE</code>，所以我得和他们保持统一。<br>点开<code>parent</code> 项目<br><img src="https://img-blog.csdnimg.cn/20200725115251747.png" alt="在这里插入图片描述"><br>然后点开<code>spring-boot-start-parent</code>的<code>parent</code>项目（葫芦娃找爷爷）<br><img src="https://img-blog.csdnimg.cn/20200725115322195.png" alt="在这里插入图片描述"><br>最后我们查找一下<code>elasticsearch</code>的依赖<br><img src="https://img-blog.csdnimg.cn/20200725115516463.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjEyNjQ2OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>到时候得手动修改他的版本号，因为我们装的<code>ES</code>是<code>7.6.2</code>的版本。</p>
<p>我们只需要在自己的项目里的<code>&lt;properties&gt;&lt;/properties&gt;</code>加上和他一样的标签就行。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- springboot 2.1.8.RELEASE 默认是6.4.3 手动修改版本--&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">elasticsearch.version</span>&gt;</span>7.6.2<span class="tag">&lt;/<span class="name">elasticsearch.version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- springboot start  --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-data-elasticsearch<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.elasticsearch.client<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>elasticsearch-rest-high-level-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>这样我们的版本就被替换成正确的了<br><img src="https://img-blog.csdnimg.cn/20200725120146601.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjEyNjQ2OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>接下来就是配置<code>springboot</code>，这里只贴关键代码<br>首先得配置<code>es search</code>的配置类，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.laoshiren.hello.elasticsearch.provider.configure;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.http.HttpHost;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.client.RestClient;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.client.RestHighLevelClient;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Value;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Bean;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Configuration;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ProjectName:     hello-elasticsearch</span></span><br><span class="line"><span class="comment"> * Package:         com.laoshiren.hello.elasticsearch.provider.configure</span></span><br><span class="line"><span class="comment"> * ClassName:       ElasticSearchClientConfiguration</span></span><br><span class="line"><span class="comment"> * Author:          laoshiren</span></span><br><span class="line"><span class="comment"> * Date:            2020/7/9 16:21</span></span><br><span class="line"><span class="comment"> * Version:         1.0.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ElasticSearchClientConfiguration</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Value(&quot;$&#123;laoshiren.elastic.hostname&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> String hostname;</span><br><span class="line">    <span class="meta">@Value(&quot;$&#123;laoshiren.elastic.port&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> port;</span><br><span class="line">    <span class="meta">@Value(&quot;$&#123;laoshiren.elastic.scheme&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> String scheme;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> RestHighLevelClient <span class="title function_">restHighLevelClient</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">RestHighLevelClient</span>(</span><br><span class="line">                RestClient.builder(</span><br><span class="line">                        <span class="keyword">new</span> <span class="title class_">HttpHost</span>(hostname, port, scheme)));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>包名叫<code>configure</code>吧，类名应该叫<code>XXXConfiguration</code>吧，配置就配置了一个<code>RestHighLeveClient</code>，就相当于有了<code>xxxTemplate</code>的感觉，我们拿这个东西去访问我们的<code>ES</code>，这里需要3个参数<code>scheme</code>,<code>hostname</code>,<code>port</code>，分别是协议，地址，端口。写在配置文件里。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">laoshiren:</span></span><br><span class="line">  <span class="attr">elastic:</span></span><br><span class="line">    <span class="attr">hostname:</span> <span class="number">120.79</span><span class="number">.0</span><span class="number">.210</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">9200</span></span><br><span class="line">    <span class="attr">scheme:</span> <span class="string">http</span></span><br></pre></td></tr></table></figure>
<p>然后去测试类获取<code>Client</code>去写一个空方法调用吧（<code>TDD</code>编程嘛）</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@SpringBootTest</span></span><br><span class="line"><span class="meta">@RunWith(SpringRunner.class)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ESClient</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">runEmpty</span><span class="params">()</span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Resource</span></span><br><span class="line">    <span class="keyword">private</span> RestHighLevelClient client;</span><br><span class="line">    <span class="meta">@Resource</span></span><br><span class="line">    <span class="keyword">private</span> ObjectMapper objectMapper;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">initClient</span><span class="params">()</span>&#123;</span><br><span class="line">        System.out.println(client);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>等这2个方法都不报错，我们就可以继续学习了。</p>
<h3 id="API"><a href="#API" class="headerlink" title="API"></a>API</h3><p><strong>希望大家可以使用debug的方式查看每次请求完成后的response</strong><br>创建索引</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">createIndex</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    <span class="comment">// 索引请求</span></span><br><span class="line">    <span class="type">CreateIndexRequest</span> <span class="variable">request</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">CreateIndexRequest</span>(<span class="string">&quot;organization&quot;</span>);</span><br><span class="line">    <span class="comment">// 执行</span></span><br><span class="line">    <span class="type">CreateIndexResponse</span> <span class="variable">response</span> <span class="operator">=</span> client.indices()</span><br><span class="line">            .create(request, RequestOptions.DEFAULT);</span><br><span class="line">    System.out.println(response.index());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>判断索引存不存在</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">existsIndex</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    <span class="type">GetIndexRequest</span> <span class="variable">request</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">GetIndexRequest</span>(<span class="string">&quot;organization&quot;</span>);</span><br><span class="line">    <span class="type">boolean</span> <span class="variable">exists</span> <span class="operator">=</span> client.indices()</span><br><span class="line">            .exists(request, RequestOptions.DEFAULT);</span><br><span class="line">    System.out.println(exists);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>删除索引</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">deleteIndex</span><span class="params">()</span> <span class="keyword">throws</span> IOException&#123;</span><br><span class="line">    <span class="type">DeleteIndexRequest</span> <span class="variable">request</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DeleteIndexRequest</span>(<span class="string">&quot;tb_user&quot;</span>);</span><br><span class="line">    <span class="type">AcknowledgedResponse</span> <span class="variable">delete</span> <span class="operator">=</span> client.indices()</span><br><span class="line">            .delete(request, RequestOptions.DEFAULT);</span><br><span class="line">    System.out.println(delete.isAcknowledged());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>创建文档</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">createDoc</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">    <span class="type">TbUser</span> <span class="variable">tbUser</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TbUser</span>();</span><br><span class="line">    tbUser.setCustomerNo(<span class="string">&quot;0001&quot;</span>)</span><br><span class="line">            .setGrpContNo(<span class="string">&quot;2020&quot;</span>)</span><br><span class="line">            .setFirstName(<span class="string">&quot;laoshiren1207&quot;</span>)</span><br><span class="line">            .setTransAmt(<span class="number">900</span>)</span><br><span class="line">            .setCreateDate(<span class="keyword">new</span> <span class="title class_">Date</span>());</span><br><span class="line">    <span class="comment">// 指定索引</span></span><br><span class="line">    <span class="type">IndexRequest</span> <span class="variable">request</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IndexRequest</span>(<span class="string">&quot;tb_user&quot;</span>);</span><br><span class="line">    <span class="comment">// 设置规则</span></span><br><span class="line">    request.id(<span class="string">&quot;1&quot;</span>)</span><br><span class="line">            .timeout(TimeValue.timeValueSeconds(<span class="number">5</span>));</span><br><span class="line">    <span class="comment">// 对象转换json</span></span><br><span class="line">    request.source(objectMapper.writeValueAsString(tbUser), XContentType.JSON);</span><br><span class="line">    <span class="comment">// 发送请求</span></span><br><span class="line">    <span class="type">IndexResponse</span> <span class="variable">index</span> <span class="operator">=</span> client.index(request, RequestOptions.DEFAULT);</span><br><span class="line">    System.out.println(index.toString());</span><br><span class="line">    <span class="comment">// 命令返回的状态</span></span><br><span class="line">    System.out.println(index.status());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>文档存不存在</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">existsDoc</span><span class="params">()</span><span class="keyword">throws</span> Exception&#123;</span><br><span class="line">    <span class="type">GetRequest</span> <span class="variable">request</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">GetRequest</span>(<span class="string">&quot;tb_user&quot;</span>,<span class="string">&quot;1&quot;</span>);</span><br><span class="line">    <span class="type">boolean</span> <span class="variable">exists</span> <span class="operator">=</span> client.exists(request, RequestOptions.DEFAULT);</span><br><span class="line">    System.out.println(exists);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>获取文档</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">getDoc</span><span class="params">()</span> <span class="keyword">throws</span> Exception&#123;</span><br><span class="line">    <span class="type">GetRequest</span> <span class="variable">request</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">GetRequest</span>(<span class="string">&quot;tb_user&quot;</span>,<span class="string">&quot;1&quot;</span>);</span><br><span class="line">    <span class="type">GetResponse</span> <span class="variable">response</span> <span class="operator">=</span> client.get(request, RequestOptions.DEFAULT);</span><br><span class="line">    <span class="comment">// 所有信息</span></span><br><span class="line">    System.out.println(response.toString());</span><br><span class="line">    <span class="comment">// 获取doc</span></span><br><span class="line">    System.out.println(response.getSourceAsString());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>更新文档</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">postDocForUpdate</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">    <span class="type">UpdateRequest</span> <span class="variable">request</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">UpdateRequest</span>(<span class="string">&quot;tb_user&quot;</span>,<span class="string">&quot;1&quot;</span>);</span><br><span class="line">    request.timeout(TimeValue.timeValueSeconds(<span class="number">5</span>));</span><br><span class="line">    <span class="comment">// 新对象</span></span><br><span class="line">    <span class="type">TbUser</span> <span class="variable">tbUser</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TbUser</span>();</span><br><span class="line">    <span class="comment">// 202007111030</span></span><br><span class="line">    tbUser.setCreateDate(<span class="keyword">new</span> <span class="title class_">Date</span>());</span><br><span class="line">    <span class="comment">// 文档类型 XContentType</span></span><br><span class="line">    request.doc(objectMapper.writeValueAsString(tbUser),XContentType.JSON);</span><br><span class="line">    <span class="type">UpdateResponse</span> <span class="variable">update</span> <span class="operator">=</span> client.update(request, RequestOptions.DEFAULT);</span><br><span class="line">    System.out.println(update.status());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>删除文档</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">deleteDoc</span><span class="params">()</span> <span class="keyword">throws</span> Exception&#123;</span><br><span class="line">    <span class="type">DeleteRequest</span> <span class="variable">request</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DeleteRequest</span>(<span class="string">&quot;tb_user&quot;</span>,<span class="string">&quot;1&quot;</span>);</span><br><span class="line">    request.timeout(TimeValue.timeValueSeconds(<span class="number">5</span>));</span><br><span class="line">    <span class="type">DeleteResponse</span> <span class="variable">delete</span> <span class="operator">=</span> client.delete(request,RequestOptions.DEFAULT);</span><br><span class="line">    System.out.println(delete.status());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>批量<code>insert</code>操作</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">bulkInsert</span><span class="params">()</span><span class="keyword">throws</span> Exception&#123;</span><br><span class="line">    <span class="type">BulkRequest</span> <span class="variable">bulkRequest</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">BulkRequest</span>();</span><br><span class="line">    <span class="comment">// 批量操作</span></span><br><span class="line">    bulkRequest.timeout(TimeValue.timeValueSeconds(<span class="number">30</span>));</span><br><span class="line">    List&lt;TbUser&gt; list = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">    <span class="type">TbUser</span> <span class="variable">tbUser</span> <span class="operator">=</span><span class="keyword">new</span> <span class="title class_">TbUser</span>();</span><br><span class="line">    tbUser.setCreateDate(<span class="keyword">new</span> <span class="title class_">Date</span>())</span><br><span class="line">            .setTransAmt(<span class="number">23</span>)</span><br><span class="line">            .setFirstName(<span class="string">&quot;laoshiren&quot;</span>)</span><br><span class="line">            .setGrpContNo(<span class="string">&quot;00001&quot;</span>)</span><br><span class="line">            .setCustomerNo(<span class="string">&quot;00003&quot;</span>);</span><br><span class="line">    list.add(tbUser);</span><br><span class="line">    <span class="type">TbUser</span> <span class="variable">tbUser2</span> <span class="operator">=</span><span class="keyword">new</span> <span class="title class_">TbUser</span>();</span><br><span class="line">    tbUser2.setCreateDate(<span class="keyword">new</span> <span class="title class_">Date</span>())</span><br><span class="line">            .setTransAmt(<span class="number">23</span>)</span><br><span class="line">            .setFirstName(<span class="string">&quot;周杰伦&quot;</span>)</span><br><span class="line">            .setGrpContNo(<span class="string">&quot;00001&quot;</span>)</span><br><span class="line">            .setCustomerNo(<span class="string">&quot;00003&quot;</span>);</span><br><span class="line">    list.add(tbUser2);</span><br><span class="line">    <span class="comment">// 获取索引</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i&lt; list.size(); i++) &#123;</span><br><span class="line">        <span class="comment">//批处理请求</span></span><br><span class="line">        <span class="type">IndexRequest</span> <span class="variable">index</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IndexRequest</span>(<span class="string">&quot;tb_user&quot;</span>)</span><br><span class="line">                .id(<span class="string">&quot;&quot;</span> + (i + <span class="number">2</span>))</span><br><span class="line">                <span class="comment">// 转换json string</span></span><br><span class="line">                .source(objectMapper.writeValueAsString(list.get(i)), XContentType.JSON);</span><br><span class="line">        bulkRequest.add(index);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">BulkResponse</span> <span class="variable">bulk</span> <span class="operator">=</span> client.bulk(bulkRequest, RequestOptions.DEFAULT);</span><br><span class="line">    System.out.println(bulk.status());</span><br><span class="line">    System.out.println(bulk.hasFailures());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>搜索</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">search</span><span class="params">()</span> <span class="keyword">throws</span> Exception&#123;</span><br><span class="line">    <span class="type">SearchRequest</span> <span class="variable">request</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SearchRequest</span>(<span class="string">&quot;tb_user&quot;</span>);</span><br><span class="line">    <span class="comment">// 构造</span></span><br><span class="line">    <span class="type">SearchSourceBuilder</span> <span class="variable">builder</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SearchSourceBuilder</span>();</span><br><span class="line">    <span class="comment">// 中文或者自定义字符串就要加上 field.keyword</span></span><br><span class="line">    MatchQueryBuilder query= QueryBuilders.MatchQuery(<span class="string">&quot;firstName&quot;</span>, <span class="string">&quot;a&quot;</span>);</span><br><span class="line">    <span class="comment">// 构建所需查询</span></span><br><span class="line">    builder.query(query);</span><br><span class="line">    builder.from(<span class="number">0</span>);</span><br><span class="line">    builder.size(<span class="number">5</span>);</span><br><span class="line">    builder.timeout(<span class="keyword">new</span> <span class="title class_">TimeValue</span>(<span class="number">60</span>,TimeUnit.SECONDS));</span><br><span class="line">    request.source(builder);</span><br><span class="line">    <span class="type">SearchResponse</span> <span class="variable">search</span> <span class="operator">=</span> client.search(request, RequestOptions.DEFAULT);</span><br><span class="line">    System.out.println(search.toString());</span><br><span class="line">    <span class="comment">// 所需数据</span></span><br><span class="line">    System.out.println(search.getHits());</span><br><span class="line">    <span class="keyword">for</span> (SearchHit hit : search.getHits().getHits()) &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">s</span> <span class="operator">=</span> objectMapper.writeValueAsString(hit);</span><br><span class="line">        System.out.println(s);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>搜索不仅仅只有这一个他的<code>QueryBuilders</code>提供了大量的条件查询比如<code>boolQuery</code>，<code>termQuery</code>等。像我在工作中我就会用<code>MatchQuery</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">BoolQueryBuilder</span> <span class="variable">boolQuery</span> <span class="operator">=</span> QueryBuilders.boolQuery();</span><br><span class="line">map.keySet().forEach(it -&gt; &#123;</span><br><span class="line">    <span class="keyword">if</span> (!StringUtils.isBlank(map.get(it).toString())) &#123;</span><br><span class="line">        boolQuery.must(</span><br><span class="line">                QueryBuilders.matchQuery(it, map.get(it).toString())</span><br><span class="line">                        <span class="comment">// 指定分词</span></span><br><span class="line">                        .analyzer(analyzer));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>更多的<code>API</code>可以参考其他的博主或者<code>B站</code>的一些<code>up</code>主，比如三太子敖丙，狂神说，<code>lusifer</code>（撸帝）还有什么很多的培训机构的一些文章视频都可以看看，一些新技术他们肯定会知道了解。<br><strong>熟读唐诗三百首，不会吟诗也会吟嘛</strong> </p>
<h3 id="Bug"><a href="#Bug" class="headerlink" title="Bug"></a>Bug</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">java.io.IOException: 远程主机强迫关闭了一个现有的连接。</span><br><span class="line">	at org.elasticsearch.client.RestClient.extractAndWrapCause(RestClient.java:828) ~[elasticsearch-rest-client-7.6.2.jar:7.6.2]</span><br></pre></td></tr></table></figure>
<p>最近两天在准备测试，发现这个<code>client</code>长时间连接不使用会报异常，第一次请求报错，再一次请求就恢复正常了。所以修改了一下代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"> <span class="meta">@Bean(name = &quot;restSearchClient&quot;)</span></span><br><span class="line"><span class="keyword">public</span> RestHighLevelClient <span class="title function_">restHighLevelClient</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">RestHighLevelClient</span>(</span><br><span class="line">            RestClient.builder(<span class="keyword">new</span> <span class="title class_">HttpHost</span>(host,port,scheme))</span><br><span class="line">                    .setRequestConfigCallback(requestConfigBuilder -&gt; &#123;</span><br><span class="line">                        requestConfigBuilder.setConnectTimeout(-<span class="number">1</span>);</span><br><span class="line">                        requestConfigBuilder.setSocketTimeout(<span class="number">30000</span>);</span><br><span class="line">                        requestConfigBuilder.setConnectionRequestTimeout(<span class="number">30000</span>);</span><br><span class="line">                        <span class="keyword">return</span> requestConfigBuilder;</span><br><span class="line">                    &#125;)</span><br><span class="line">    );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>隔了一晚，发现加上了好像也没什么用处，所以我就打算既然连接会死，那就每个一段时间请求一下<code>ES</code>服务器的的信息，即使死了，那再下次一请求这个客户端一定是可以。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Scheduled(cron = &quot;0 0 * * * ? &quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">restClientKeepAlive</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        log.info(<span class="string">&quot;schedule 保持ES客户端存活 start&quot;</span>);</span><br><span class="line">        <span class="type">MainResponse</span> <span class="variable">response</span> <span class="operator">=</span> restClient.info(RequestOptions.DEFAULT);</span><br><span class="line">        log.info(<span class="string">&quot;schedule 保持ES客户端存活 end&quot;</span>);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException ignore) &#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>不知道有没有大佬还有其他的解决方法没有，可以指点一下，</p>
<table>
<thead>
<tr>
<th>联系方式</th>
<th>联系方式</th>
</tr>
</thead>
<tbody><tr>
<td>QQ</td>
<td>1027575422</td>
</tr>
<tr>
<td>Email</td>
<td><a href="mailto:&#x31;&#x35;&#x32;&#48;&#x37;&#x30;&#51;&#52;&#x34;&#x37;&#51;&#64;&#x31;&#54;&#x33;&#x2e;&#99;&#x6f;&#x6d;">&#x31;&#x35;&#x32;&#48;&#x37;&#x30;&#51;&#52;&#x34;&#x37;&#51;&#64;&#x31;&#54;&#x33;&#x2e;&#99;&#x6f;&#x6d;</a></td>
</tr>
</tbody></table>
<h3 id="文档来源"><a href="#文档来源" class="headerlink" title="文档来源"></a>文档来源</h3><p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV17a4y1x7zq">【狂神说Java】ElasticSearch7.6.x最新完整教程通俗易懂 - 遇见狂神说</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/cjsblog/p/10120470.html">Elastic Search Api - 废物大师兄</a></p>
<p>特别推荐狂神说的视频简单清晰易懂而且免费。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://laoshiren1207.github.io/2020/07/11/Seata/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Laoshiren">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LaoShiRen1207">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/07/11/Seata/" class="post-title-link" itemprop="url">分布式事务 Seata</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-07-11 18:53:48" itemprop="dateCreated datePublished" datetime="2020-07-11T18:53:48+08:00">2020-07-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-04-13 14:51:51" itemprop="dateModified" datetime="2022-04-13T14:51:51+08:00">2022-04-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Java/" itemprop="url" rel="index"><span itemprop="name">Java</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Java/SpringBoot/" itemprop="url" rel="index"><span itemprop="name">SpringBoot</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Seata"><a href="#Seata" class="headerlink" title="Seata"></a>Seata</h2><h3 id="Seata-是什么？"><a href="#Seata-是什么？" class="headerlink" title="Seata 是什么？"></a>Seata 是什么？</h3><blockquote>
<p>Seata is an easy-to-use, high-performance, open source distributed transaction solution.</p>
<p>Seata 是一个简单易用的，高性能，开源的分布式事务解决方案。</p>
</blockquote>
<h3 id="AT模式"><a href="#AT模式" class="headerlink" title="AT模式"></a>AT模式</h3><p><code>AT</code> 模式是一种无侵入的分布式事务解决方案。在 <code>AT</code> 模式下，用户只需关注自己的“业务 <code>SQL</code>”，<br>用户的 “业务 <code>SQL</code>” 就是全局事务一阶段，<code>Seata</code> 框架会自动生成事务的二阶段提交和回滚操作。</p>
<p><code>AT</code> 模式如何做到对业务的无侵入 ：</p>
<ul>
<li><p>一阶段：<br>在一阶段，<code>Seata</code> 会拦截“业务 <code>SQL</code>”，首先解析 <code>SQL</code> 语义，找到“业务 <code>SQL</code>”要更新的业务数据，<br>在业务数据被更新前，将其保存成<code>before image</code>，然后执行“业务 <code>SQL</code>”更新业务数据，在业务数据更新之后，<br>再将其保存成<code>after image</code>，最后生成行锁。以上操作全部在一个数据库事务内完成，这样保证了一阶段操作的原子性。</p>
</li>
<li><p>二阶段提交：<br>二阶段如果是提交的话，因为“业务 <code>SQL</code>”在一阶段已经提交至数据库， 所以 <code>Seata</code> 框架只需将一阶段保存的快照数据和行锁删掉，完成数据清理即可。</p>
</li>
<li><p>二阶段回滚：<br>二阶段如果是回滚的话，<code>Seata</code> 就需要回滚一阶段已经执行的“业务 <code>SQL</code>”，还原业务数据。<br>回滚方式便是用<code>before image</code>还原业务数据；但在还原前要首先要校验脏写，对比“数据库当前业务数据”和 <code>after image</code>，<br>如果两份数据完全一致就说明没有脏写，可以还原业务数据，如果不一致就说明有脏写，出现脏写就需要转人工处理。</p>
</li>
</ul>
<p><code>AT</code> 模式的一阶段、二阶段提交和回滚均由 <code>Seata</code> 框架自动生成，用户只需编写“业务 <code>SQL</code>”，便能轻松接入分布式事务，<code>AT</code> 模式是一种对业务无任何侵入的分布式事务解决方案。<br>(以上选自知乎<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/78599954">分布式事务的4种模式</a>)</p>
<h3 id="nacos-dubbo"><a href="#nacos-dubbo" class="headerlink" title="nacos-dubbo"></a><code>nacos-dubbo</code></h3><p><code>nacos-dubbo</code>是一个简单的<code>Seata AT</code>模式的入门项目，使用<code>dubbo</code>去实现服务与服务之间的调用。</p>
<h4 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h4><p><code>provider</code> 项目中只有2种类型的项目一种是<code>api</code>,还有一种是<code>service</code><br>所谓<code>api</code>项目是项目只有接口和<code>domain</code>,没有实现。此项目会被该<code>api</code>的实现（<code>service</code>）和需要调用<code>service</code>的项目依赖。<br><code>service</code>项目是实现<code>api</code>项目的项目一般是去操作数据库或者其他业务的项目。</p>
<p><code>consumer</code> 项目也只有2种类型的项目一种是<code>api</code>,还有一种是<code>service</code><br>和上面一样，<code>service</code>项目会去调用对应的<code>provider</code>的接口，使用的是<code>dubbo rpc</code>的通讯</p>
<p><code>business</code> 项目是指业务层的代码项目，他会去依赖<code>consumer</code>的<code>api</code>项目。然后对外部提供<code>RESTFul</code>的接口</p>
<p>所以在这个项目中，先启动2个<code>provider</code>中的<code>service</code>，然后启动<code>consumer</code>的<code>service</code>，最后启动<code>business</code>项目。</p>
<h4 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h4><p>首先需要创建2个库，一个库存放<code>order</code>表，一个库存放<code>order_item</code>。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> tb_order (</span><br><span class="line">    id <span class="type">BIGINT</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> AUTO_INCREMENT <span class="keyword">PRIMARY</span> KEY, </span><br><span class="line">    order_id <span class="type">BIGINT</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>, </span><br><span class="line">    user_id <span class="type">BIGINT</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>);</span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> tb_order_item (</span><br><span class="line">    id <span class="type">BIGINT</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> AUTO_INCREMENT <span class="keyword">PRIMARY</span> KEY, </span><br><span class="line">    user_id <span class="type">BIGINT</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>, </span><br><span class="line">    order_id <span class="type">BIGINT</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>, </span><br><span class="line">    order_item_id <span class="type">BIGINT</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>);</span><br></pre></td></tr></table></figure>
<p>除此之外，还需要在每个库里都创建一个<code>undo_log</code></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">  `id` <span class="type">bigint</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> AUTO_INCREMENT,</span><br><span class="line">  `branch_id` <span class="type">bigint</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `xid` <span class="type">varchar</span>(<span class="number">100</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `context` <span class="type">varchar</span>(<span class="number">128</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `rollback_info` longblob <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `log_status` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `log_created` datetime <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `log_modified` datetime <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `ext` <span class="type">varchar</span>(<span class="number">100</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  <span class="keyword">PRIMARY</span> KEY (`id`),</span><br><span class="line">  <span class="keyword">UNIQUE</span> KEY `ux_undo_log` (`xid`,`branch_id`)</span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB AUTO_INCREMENT<span class="operator">=</span><span class="number">1</span> <span class="keyword">DEFAULT</span> CHARSET<span class="operator">=</span>utf8;</span><br></pre></td></tr></table></figure>

<h4 id="provider"><a href="#provider" class="headerlink" title="provider"></a>provider</h4><p>主要增加了 <code>Seata</code> 依赖</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>io.seata<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>seata-spring-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>配置文件</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">spring</span></span><br><span class="line">  <span class="attr">alibaba:</span></span><br><span class="line">      <span class="attr">seata:</span></span><br><span class="line">        <span class="comment"># 自定义事务组名称 tx_group，需要与服务端一致</span></span><br><span class="line">        <span class="attr">tx-service-group:</span> <span class="string">tx_group</span></span><br></pre></td></tr></table></figure>
<p>配置类,具体看项目的<code>SeataConfiguration</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> io.seata.rm.datasource.DataSourceProxy;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SeataConfiguration</span> &#123;</span><br><span class="line">    <span class="meta">@Primary</span></span><br><span class="line">    <span class="meta">@Bean(&quot;dataSource&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> DataSourceProxy <span class="title function_">dataSource</span><span class="params">(DataSource hikariDataSource)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">DataSourceProxy</span>(hikariDataSource);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> GlobalTransactionScanner <span class="title function_">globalTransactionScanner</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * applicationId：同服务名即可</span></span><br><span class="line"><span class="comment">         * txServiceGroup：自定义事务组名，需要与 Seata Server 配置一致</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">GlobalTransactionScanner</span>(<span class="string">&quot;provider-order-item&quot;</span>, <span class="string">&quot;tx_group&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>一定要在启动类上加上<code>@EnableTransactionManagement</code></p>
<h4 id="transaction"><a href="#transaction" class="headerlink" title="transaction"></a>transaction</h4><p>这里删除去了 <code>mybatis mysql hikari</code> 的依赖。<br>配置类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> io.seata.spring.annotation.GlobalTransactionScanner;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Bean;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Configuration;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SeataConfiguration</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> GlobalTransactionScanner <span class="title function_">globalTransactionScanner</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">GlobalTransactionScanner</span>(<span class="string">&quot;consumer-transaction&quot;</span>, <span class="string">&quot;tx_group&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>实现方法上加上注解<code>@GlobalTransactional</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Service(version = &quot;1.0.0&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TransactionServiceImpl</span> <span class="keyword">implements</span> <span class="title class_">TransactionService</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Reference(version = &quot;1.0.0&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> OrderService orderService;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Reference(version = &quot;1.0.0&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> OrderItemService orderItemService;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="meta">@GlobalTransactional</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">doTransaction</span><span class="params">(TbOrder tbOrder, TbOrderItem tbOrderItem)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;transaction 开始全局事务，XID = &quot;</span> + RootContext.getXID());</span><br><span class="line">        orderService.insert(tbOrder);</span><br><span class="line">        orderItemService.insert(tbOrderItem);</span><br><span class="line">        <span class="keyword">if</span> (tbOrderItem.getOrderId() == <span class="literal">null</span> ) &#123;</span><br><span class="line">            <span class="keyword">throw</span>  <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(<span class="string">&quot; null Exception &quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="business"><a href="#business" class="headerlink" title="business"></a>business</h4><p>这里就正常调用<code>consumer</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="meta">@RequestMapping(&quot;/v1/transaction&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TransactionController</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Reference(version = &quot;1.0.0&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> TransactionService transactionService;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping(&quot;&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> Map&lt;String,Object&gt; <span class="title function_">doTransaction</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">TbOrder</span> <span class="variable">order</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TbOrder</span>();</span><br><span class="line">        order.setOrderId(<span class="number">1L</span>);</span><br><span class="line">        order.setUserId(<span class="number">1L</span>);</span><br><span class="line">        <span class="type">TbOrderItem</span> <span class="variable">orderItem</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TbOrderItem</span>();</span><br><span class="line">        orderItem.setUserId(<span class="number">1L</span>);</span><br><span class="line">        transactionService.doTransaction(order,orderItem);</span><br><span class="line">		Map&lt;String,Object&gt; map = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">		map.put(<span class="string">&quot;code&quot;</span>,<span class="number">200</span>);</span><br><span class="line">		map.put(<span class="string">&quot;message&quot;</span>，<span class="string">&quot;服务调用成功&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> map;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>接下来就是浏览器访问<a target="_blank" rel="noopener" href="http://127.0.0.1:27010/v1/transaction">测试 http://127.0.0.1:27010/v1/transaction</a><br>再到<code>Seata</code>服务上看到回滚的日志，再查看数据库。成功回滚</p>
<h3 id="nacos-http-TBD"><a href="#nacos-http-TBD" class="headerlink" title="nacos-http(TBD)"></a><code>nacos-http</code>(TBD)</h3><p><code>nacos-http</code>是一个使用<code>Spring Cloud Alibaba</code> 实现<code>Seata AT</code>模式的入门项目。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Laoshiren</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">14</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">12</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">25</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Laoshiren</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
